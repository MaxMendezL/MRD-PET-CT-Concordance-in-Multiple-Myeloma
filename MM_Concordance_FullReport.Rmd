---
title: "MRD/PET-CT Concordance — Reproducible Analysis Pipeline"
author: "Max Mendez et al"
date: "`r format(Sys.Date())`"
output:
  html_document:
    theme: flatly
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
    fig_caption: true
    code_folding: hide
fontsize: 11pt
editor_options:
  chunk_output_type: console
header-includes: "<style>\n  h1.title {font-size: 28px; font-weight: 700;}\n  h1 {font-size:
  26px; font-weight: 700; margin-top: 1.2em;}\n  h2 {font-size: 22px; font-weight:
  700; margin-top: 1.0em;}\n  h3 {font-size: 18px; font-weight: 700; margin-top: 0.8em;}\n
  \ .tocify { font-size: 14px; }\n  .table caption {caption-side: top;}\n</style>\n"
---


# Overview & Summary

Transparent, fully reproducible rebuild of the MRD–PET/CT agreement and prognosis analysis using paired 2×2 data. All inputs are harmonised to canonical cell counts (a = MRD−/PET+, b = MRD−/PET−, c = MRD+/PET−, d = MRD+/PET+) with percentages back-calculated to counts by proportional allocation and reconciled to the reported cohort size (n).

Analysis sets: (i) Primary (MRD and PET/CT at the same time-point); (ii) Strict (Δ ≤ 30 days between MRD and PET/CT); (iii) Sensitivity (including reconstructed rows and prespecified exclusions).

Agreement metrics: Per study we report the concordant proportion (b+d)/n, Cohen’s κ (standard error and 95% confidence interval), McNemar mid-p, and Gwet’s AC1 and prevalence- and bias-adjusted κ (PABAK). Study-level κ is pooled using random-effects (restricted maximum likelihood) with Knapp–Hartung adjustment. Directional discordance is defined as log-odds(MRD−/PET+ vs MRD+/PET−) with Haldane–Anscombe correction and synthesised by random-effects meta-analysis; 95% prediction intervals are reported when estimable.

Fréchet–Hoeffding κ bounds: Identification regions are derived per study and for the pooled marginals, with bounds frequently crossing zero, indicating weak identifiability of κ and supporting cautious interpretation and a complementary view of MRD and PET/CT.

Survival (progression-free survival, PFS): Dual-negative (MRD−/PET−) versus all other response categories. Hazard ratios (HR) are pooled using random-effects (restricted maximum likelihood) with Knapp–Hartung, yielding a pooled HR of 0.33 (95% CI 0.24–0.45) for dual-negative versus others; small-study asymmetry tests are interpreted descriptively given the low number of cohorts.
Primary pooled matrix (same-time-point set): a = 435 (37.4%), b = 374 (32.1%), c = 304 (26.1%), d = 51 (4.4%); n = 1,164; pooled concordant proportion = 36.5% and pooled κ = −0.26 (95% CI −0.31 to −0.21).

Key outputs: Table 1 (study characteristics); Table 2 (concordance and directional discordance); Figure 2A (pooled κ forest plot); Figure 2B (directional discordance meta-analysis); Figure 3A (PFS meta-analysis); Supplementary Figure SF1 (pooled 2×2 matrix); Supplementary Tables ST1–ST2 (Fréchet–Hoeffding bounds and risk-of-bias).


```{r setup-boot, include=FALSE}
# Repro & friendly defaults
set.seed(1234)
options(
  dplyr.summarise.inform = FALSE,
  width = 120,
  ROB_FROM_BIAS = FALSE,
  stringsAsFactors = FALSE,
  htmlwidgets.TOJSON_ARGS = modifyList(
    getOption("htmlwidgets.TOJSON_ARGS", list()),
    list(na = "null", auto_unbox = TRUE)
  )
)
try(suppressWarnings(Sys.setlocale("LC_CTYPE", "en_US.UTF-8")), silent = TRUE)

# knitr defaults
dev <- if (requireNamespace("ragg", quietly = TRUE)) "ragg_png" else "png"

knitr::opts_chunk$set(
  echo = FALSE, message = FALSE, warning = FALSE, comment = NA,
  dev = dev, dpi = 200, fig.retina = 2,
  fig.align = "center", out.width = "95%", fig.path = "figs/", cache=FALSE
)

# Packages (idempotent)
load_or_install <- function(pkgs, quietly = TRUE) {
  pkgs <- unique(pkgs)
  need <- setdiff(pkgs, rownames(installed.packages()))
  if (length(need)) install.packages(need, quiet = TRUE)
  invisible(vapply(pkgs, function(p) suppressPackageStartupMessages(require(p, character.only = TRUE)), logical(1)))
}
core_libs <- c(
  "tidyverse","readxl","metafor","meta","irr","janitor","broom", "cowplot", "png",
  "ggrepel","readr","dplyr","stringr","scales","glue","writexl",
  "DescTools","htmlwidgets","zip","DT","htmltools","RColorBrewer","ggforce","here"
)
diag_libs <- c("DiagrammeR","DiagrammeRsvg","rsvg")
load_or_install(core_libs)
invisible(load_or_install(intersect(diag_libs, diag_libs)))

# Root + theme
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(here))
try({
  inp <- knitr::current_input()
  if (!is.null(inp) && nzchar(inp)) here::i_am(basename(inp))
}, silent = TRUE)
knitr::opts_knit$set(root.dir = here::here())
theme_set(theme_minimal(base_size = 11, base_family = "Helvetica"))

# ---------- Utilities (defined BEFORE use) ----------
`%||%` <- function(a, b) if (is.null(a) || length(a) == 0) b else a

note <- function(txt) {
  knitr::asis_output(
    sprintf("<div class='note'><em>%s</em></div>", htmltools::htmlEscape(txt %||% ""))
  )
}

# ---- Hard reset of DT helpers & options (avoid extensions=NULL bug) ----
if (exists("dt_compact", inherits = TRUE)) rm(dt_compact)
if (exists("show_table", inherits = TRUE)) rm(show_table)
if (!is.null(getOption("DT.options", NULL))) options(DT.options = NULL)

dt_compact <- function(df, caption = NULL, escape = FALSE, ...) {
  x <- if (is.data.frame(df)) df else data.frame()
  n <- NROW(x); if (!is.finite(n)) n <- 0L
  has_buttons <- (n >= 10L)

  opts <- list(
    dom        = if (has_buttons) "Bfrtip" else "tip",
    pageLength = if (n <= 0) 5L else min(10L, max(5L, n)),
    buttons    = if (has_buttons) c("copy","csv","excel") else NULL
  )
  args <- list(
    data     = x,
    caption  = if (is.null(caption)) NULL else htmltools::tags$span(caption, class = "caption"),
    options  = opts,
    class    = "compact stripe hover",
    rownames = FALSE,
    escape   = escape
  )
  if (has_buttons) args$extensions <- "Buttons"
  do.call(DT::datatable, args)
}

# Wrapper accepts both 'cap' and 'caption'
show_table <- function(df, cap = NULL, caption = NULL, escape = FALSE, ...) {
  cap <- if (!is.null(caption)) caption else cap
  dt_compact(df, caption = cap, escape = escape, ...)
}

# Image include helper
show_png <- function(dir, file, caption = NULL, width = "90%") {
  rel <- file.path(dir, file)
  p   <- if (file.exists(rel)) rel else here::here(dir, file)

  # If PNG missing, try an .html sibling and embed via <iframe>
  if (!file.exists(p)) {
    html_rel <- file.path(dir, sub("\\.png$", ".html", basename(file)))
    html_p   <- if (file.exists(html_rel)) html_rel else here::here(dir, basename(html_rel))
    if (file.exists(html_p) && knitr::is_html_output()) {
      cap_html <- if (!is.null(caption) && nzchar(caption))
        sprintf("<figcaption style='text-align:center'><em>%s</em></figcaption>", htmltools::htmlEscape(caption)) else ""
      iframe <- sprintf(
        "<iframe src='%s' style='width:%s; height:640px; border:0'></iframe>",
        html_rel, width
      )
      return(knitr::asis_output(
        sprintf("<figure style='margin:0 auto; text-align:center'>%s%s</figure>", iframe, cap_html)
      ))
    }
    return(knitr::asis_output(
      sprintf("<p style='color:#a00'><em>Missing image: %s</em></p>", file.path(dir, file))
    ))
  }

  # PNG path exists → embed normally
  if (knitr::is_html_output()) {
    cap_html <- if (!is.null(caption) && nzchar(caption))
      sprintf("<figcaption style='text-align:center'><em>%s</em></figcaption>", htmltools::htmlEscape(caption)) else ""
    html <- sprintf(
      "<figure style='margin:0 auto; text-align:center'>
         <img src='%s' style='max-width:%s; height:auto;'/>%s
       </figure>", rel, width, cap_html
    )
    return(knitr::asis_output(html))
  } else {
    knitr::opts_current$set(out.width = width)
    return(knitr::include_graphics(p))
  }
}


# One-time source helper
source_once <- local({
  seen <- new.env(parent = emptyenv())
  function(...) {
    for (p in list(...)) {
      if (is.null(p) || !nzchar(p) || !file.exists(p)) next
      key <- normalizePath(p, winslash = "/", mustWork = FALSE)
      if (is.null(seen[[key]])) { source(p, chdir = TRUE); seen[[key]] <- TRUE }
    }
  }
})

# Ensure standard folders
invisible(lapply(c("data","figs","tables","outputs","docs","docs/figs"), function(d) {
  dir.create(here::here(d), showWarnings = FALSE, recursive = TRUE)
}))

# Shared palette
if (!exists("FIG_SHARED_PALETTE", inherits = FALSE)) {
  FIG_SHARED_PALETTE <- list(
    dualneg      = "#10b981",
    mrdnegpetpos = "#6366f1",
    mrdpospetneg = "#f59e0b",
    dualpos      = "#ef4444",
    border       = "#334155",
    text         = "#0f172a",
    link         = "#0891b2",
    bg           = "#ffffff"
  )
}

# Misc helpers
strip_titles <- function(p) p + ggplot2::labs(title = NULL, subtitle = NULL, caption = NULL)
.mm_to_in <- function(mm) mm / 25.4
lan_dim <- function(layout = c("onecol","twocol"), height_mm = 120) {
  layout <- match.arg(layout); width_mm <- if (layout == "onecol") 85 else 175
  height_mm <- min(height_mm, 230)
  list(w = .mm_to_in(width_mm), h = .mm_to_in(height_mm))
}
safe_try <- function(expr) { out <- try(expr, silent = TRUE); if (inherits(out,"try-error")) NULL else out }

# Optional objects (placeholders) + safe checker
if (!exists("fh_tbl",  inherits = TRUE)) fh_tbl  <- NULL
if (!exists("sim_tbl", inherits = TRUE)) sim_tbl <- NULL
if (!exists("dca_tbl", inherits = TRUE)) dca_tbl <- NULL

is_df <- function(sym) {
  nm <- if (is.character(sym)) sym else deparse(substitute(sym))
  x <- get0(nm, ifnotfound = NULL, inherits = TRUE)
  is.data.frame(x) && nrow(x) > 0
}

# Catch unbalanced fenced divs (:::) that cause blank space
check_fenced_divs <- function() {
  f <- knitr::current_input(); if (is.null(f) || !file.exists(f)) return(invisible(TRUE))
  lines <- readLines(f, warn = FALSE)
  opens  <- which(grepl("^:::[[:space:]]*(\\{.*\\})?$", lines))
  closes <- which(grepl("^:::[[:space:]]*$",        lines))
  bal <- 0L
  for (i in seq_along(lines)) {
    if (i %in% opens)  bal <- bal + 1L
    if (i %in% closes) bal <- bal - 1L
    if (bal < 0L) stop("Extra closing ':::' at line ", i, " in ", f)
  }
  if (bal != 0L) stop("Unclosed ':::' block. Start near line ", if (length(opens)) tail(opens,1L) else 1L, " in ", f)
  invisible(TRUE)
}
check_fenced_divs()


prep_discordance <- function(df) {
  stopifnot(all(c("a","c") %in% names(df)))
  df <- df %>%
    dplyr::mutate(
      a_ = a + 0.5, c_ = c + 0.5,
      yi = log(a_ / c_),                  # log-odds (MRD−/PET+ vs MRD+/PET−)
      se = sqrt(1/a_ + 1/c_),
      vi = se^2,
      N  = dplyr::coalesce(
              suppressWarnings(as.numeric(.data$n)),
              if (all(c("a","b","c","d") %in% names(.))) a + b + c + d else NA_real_
            ),
      StudyShort = dplyr::coalesce(.data$StudyShort, shorten_study(.data$Study))
    )
  df
}

fit_rma <- function(d) metafor::rma(yi = d$yi, vi = d$vi, method = "REML", test = "knha")


```


```{r echo=FALSE}
# Optional helper sourcing
source_once(here::here("R","utils_io.R"))
source_once(here::here("R","lancet_upgrades.R"))
source_once(here::here("R","utils_filters.R"))
source_once(here::here("R","utils_concordance.R"))
source_once(here::here("R","survival_utils.R"))
source_once(here::here("R","figures.R"))
source_once(here::here("R","tables.R"))
source_once(here::here("R","meta_diagnostics.R"))
source_once(here::here("R","prisma.R"))
#source_once(here::here("R","make_journal_outputs.R"))
#source_once(here::here("R", "post-hoc-sensitivity.R"))


# Legends (single source of truth)
if (!exists("LEGENDS")) LEGENDS <- c(
  "Figure_1_PRISMA_Diagram.png"             = "PRISMA 2020 flow diagram of study selection.",
  "Figure_2A_Concordance_Forest.png"        = "Study-level Cohen’s κ with 95% CIs; dotted line = pooled κ.",
  "Figure_2B_Directional_Discordance.png"   = "Directional discordance (log-odds of MRD−/PET+ vs MRD+/PET−) with pooled REML (KnHa), τ², I², and 95% PI.",
  "Supplementary_Figure_SF1_Concordance_Matrix.png" = "Pooled MRD×PET agreement matrix with cell counts and percentages.",
  "Figure_3A_Forest_DualNeg.png"            = "PFS Hazard Ratios (dual-negative vs others); pooled REML (KnHa) with 95% prediction interval.",
  "Figure_3B_Funnel.png"                    = "Funnel plot of log(HR) vs SE with Egger’s p.",
  "Figure_4_Clinical_Pathway.png"           = "Clinical pathway schematic mapping 2×2 states to suggested actions.",
  "Figure_5_Conceptual.png"                 = "Conceptual overview linking MRD/PET concordance to outcomes."
)
legend_for <- function(filename, default = NULL) {
  val <- tryCatch(unname(LEGENDS[filename]), error = function(e) NULL)
  if (is.null(val) || length(val) == 0 || is.na(val)) default else val
}

# PRISMA exporter (once)
if (!exists("render_grviz")) {
  render_grviz <- function(gr, out_png, out_pdf = sub("\\.png$", ".pdf", out_png),
                           width_px = 1800, height_px = 1100) {
    is_pdf <- knitr::is_latex_output()
    ok_png <- FALSE
    ok_pdf <- FALSE

    # Prefer vector pipeline: DiagrammeRsvg -> rsvg
    if (requireNamespace("DiagrammeRsvg", quietly = TRUE) &&
        requireNamespace("rsvg", quietly = TRUE)) {
      svg <- DiagrammeRsvg::export_svg(gr)
      # Write PNG (for HTML)
      try({
        rsvg::rsvg_png(charToRaw(svg), file = out_png,
                       width = width_px, height = height_px)
        ok_png <- file.exists(out_png)
      }, silent = TRUE)
      # Write PDF (for LaTeX/PDF)
      try({
        rsvg::rsvg_pdf(charToRaw(svg), file = out_pdf,
                       width = width_px, height = height_px)
        ok_pdf <- file.exists(out_pdf)
      }, silent = TRUE)
    }

    if (is_pdf) {
      # In LaTeX/PDF builds, include the PDF if we made it; else fall back to PNG; else a note
      if (ok_pdf && file.exists(out_pdf)) {
        knitr::include_graphics(out_pdf)
      } else if (ok_png && file.exists(out_png)) {
        knitr::include_graphics(out_png)
      } else {
        warning("PRISMA: could not create PDF/PNG (need DiagrammeRsvg + rsvg). Suppressing widget in LaTeX.")
        knitr::asis_output("\\emph{PRISMA diagram unavailable in this build.}")
      }
    } else {
      # HTML builds: show PNG if available; otherwise the live widget
      if (ok_png && file.exists(out_png)) knitr::include_graphics(out_png) else print(gr)
    }
    invisible(ok_pdf || ok_png)
  }
}


if (!exists("render_prisma")) {
  render_prisma <- function(ct,
                            out = here::here("figs","Figure_1_PRISMA_Diagram.png"),
                            width_px = 3000, height_px = 5200,   # ← portrait orientation
                            fontsize = 28, box_width = 5.5) {    # ← narrower boxes

    `%||%` <- function(x, y) if (is.null(x) || length(x) == 0) y else x
    as_scalar_int <- function(x, default = 0L) {
      x <- `%||%`(x, default); as.integer(if (length(x)) x[[1]] else default)
    }
    lbl <- function(title, n) {
      n <- if (length(n) == 0) NA_integer_ else n[[1]]
      paste0(title, if (is.na(n)) "" else sprintf("\n(n = %s)", format(n, big.mark=",")))
    }

    # sanitize
    ct$identified      <- as_scalar_int(ct$identified)
    ct$auto_excluded   <- as_scalar_int(ct$auto_excluded)
    ct$screened        <- as_scalar_int(ct$screened)
    ct$excl_title_abs  <- as_scalar_int(ct$excl_title_abs)
    ct$sought          <- as_scalar_int(ct$sought)
    ct$not_retrieved   <- as_scalar_int(ct$not_retrieved)
    ct$full_text       <- as_scalar_int(ct$full_text)
    ct$included        <- as_scalar_int(ct$included)
    ct$manual          <- as_scalar_int(ct$manual)
    if (is.null(ct$duplicates) || length(ct$duplicates) == 0) {
      ct$duplicates <- max(0L, ct$identified - ct$auto_excluded - ct$screened)
    }
    ct$duplicates <- as_scalar_int(ct$duplicates)
    if (is.null(ct$excl_full_text) || length(ct$excl_full_text) == 0) {
      ct$excl_full_text <- max(0L, ct$full_text - ct$included)
    }
    ct$excl_full_text <- as_scalar_int(ct$excl_full_text)

    # legend
    reasons_obj <- ct$reasons_fulltext %||% ct$reasons
    if (is.list(reasons_obj) && length(reasons_obj) == 1) reasons_obj <- reasons_obj[[1]]
    build_legend <- function(obj) {
      if (is.null(obj)) return("")
      if (!all(c("Reason","Count") %in% names(obj))) return("")
      df <- obj[order(-obj$Count), ]
      items <- sprintf("%s (%d)", df$Reason, df$Count)
      paste0(
        '<FONT POINT-SIZE="22" COLOR="#666666">',
        'Full-text exclusions:<BR ALIGN="LEFT"/>',
        paste(sprintf("• %s", items), collapse="<BR ALIGN='LEFT'/>"),
        '</FONT>'
      )
    }
    legend_html <- build_legend(reasons_obj)

    # ---- VERTICAL GRAPHVIZ TEMPLATE ----
    dot <- sprintf('
      digraph prisma {
        graph [rankdir=TB, nodesep=0.25, ranksep=1.0, splines=ortho]   # ← Tighter horizontal, larger vertical spacing
        node  [shape=box, fontname=Helvetica, fontsize=%d, width=%.2f, height=0.9, fixedsize=false, margin="0.15,0.10"]

        A [label="%s"];
        B [label="%s"];
        C [label="%s"];
        D [label="%s"];
        E [label="%s"];

        M    [label="%s", style="dashed", color="#777777", fontcolor="#555555"];
        Rdup [label="%s",  color="#888888", fontcolor="#444444"];
        Raut [label="%s",  color="#888888", fontcolor="#444444"];
        Xscr [label="%s",  color="#888888", fontcolor="#444444"];
        NR   [label="%s",  color="#888888", fontcolor="#444444"];
        Xfull[label="%s",  color="#888888", fontcolor="#444444"];

        F [label=<%s>, shape=plaintext];

        # Main vertical flow
        A -> B -> C -> D -> E;

        # Side nodes (kept vertical-align friendly)
        A -> Rdup  [constraint=false];
        A -> Raut  [constraint=false];
        B -> Xscr  [constraint=false];
        C -> NR    [constraint=false];
        D -> Xfull [constraint=false];
        M -> D     [constraint=false];

        # Invisible ranks to align vertically
        {rank=same; A; Rdup; Raut; M} 
        {rank=same; B; Xscr}
        {rank=same; C; NR}
        {rank=same; D; Xfull}
        {rank=sink; E; F}
      }',
      fontsize, box_width,
      lbl("Records identified",                            ct$identified),
      lbl("Records screened",                              ct$screened),
      lbl("Reports sought for retrieval",                  ct$sought),
      lbl("Reports assessed for eligibility",              ct$full_text),
      lbl("Studies included in analysis",                  ct$included),
      lbl("Manual additions",                               ct$manual),
      lbl("Duplicate records removed",                     ct$duplicates),
      lbl("Records removed by automation tools",           ct$auto_excluded),
      lbl("Records excluded",                              ct$excl_title_abs),
      lbl("Reports not retrieved",                         ct$not_retrieved),
      lbl("Reports excluded",                              ct$excl_full_text),
      legend_html
    )

    gr <- DiagrammeR::grViz(dot)
    dir.create(dirname(out), recursive=TRUE, showWarnings=FALSE)
    render_grviz(
      gr,
      out_png = out,
      out_pdf = sub("\\.png$", ".pdf", out),
      width_px = width_px,
      height_px = height_px
    )
  }
}


```



```{r setup-packages, message=FALSE, warning=FALSE, include=FALSE}
# Packages and project bootstrap (kept; minor guards/renames to avoid duplicates later)
library(tidyverse)
library(readxl)
library(metafor)
library(meta)
library(irr) # kappa2
library(janitor)
library(broom)

suppressMessages(library(here))
suppressMessages(library(knitr))

suppressPackageStartupMessages({
libs <- c("tidyverse","meta","metafor","ggrepel","readr","dplyr","stringr","scales","glue","readxl","janitor","here","writexl","DescTools","DiagrammeR","DiagrammeRsvg","rsvg","htmlwidgets","zip","DT","htmltools","RColorBrewer","ggforce")


  to_install <- libs[!libs %in% rownames(installed.packages())]
  if (length(to_install)) install.packages(to_install, quiet = TRUE)
  invisible(lapply(libs, require, character.only = TRUE))
})

if (!exists("source_if")) {
  source_if <- function(p) if (file.exists(p)) source(p, chdir = TRUE)
}

source_if("R/utils_io.R") 
source_if(here::here("R","utils_io.R"))

# utils first
source_if("R/utils_io.R")
source_if(here::here("R","utils_io.R"))

source_if("patch_mrd_pipeline.R")
source_if(here::here("patch_mrd_pipeline.R"))
source_if("R/patch_mrd_pipeline.R")
source_if(here::here("R","patch_mrd_pipeline.R"))

source_if("R/compat_harmonize_mrd.R")
source_if(here::here("R","compat_harmonize_mrd.R"))

source_if("R/utils_concordance.R")
source_if(here::here("R","utils_concordance.R"))

source_if("R/figures.R")
source_if(here::here("R","figures.R"))

source_if("R/tables.R")
source_if(here::here("R","tables.R"))

#source_if("R/make_journal_outputs.R")
#source_if(here::here("R","make_journal_outputs.R"))


#source_if("post-hoc-sensitivity.R")
#source_once(here::here("R", "post-hoc-sensitivity.R"))

# Ensure standard folders
invisible(lapply(c("data","figs","tables","outputs"), function(d) {
  dir.create(here::here(d), showWarnings = FALSE, recursive = TRUE)
}))

# Legends (init once)
if (!exists("LEGENDS")) LEGENDS <- c(
  "Figure_1_PRISMA_Diagram.png"             = "PRISMA 2020 flow diagram of study selection.",
  "Figure_2A_Concordance_Forest.png"        = "Study-level Cohen’s κ with 95% CIs; dotted line = pooled κ.",
  "Figure_2B_Directional_Discordance.png"   = "Directional discordance (log-odds of MRD−/PET+ vs MRD+/PET−) with pooled REML (KnHa), τ², I², and 95% PI.",
  "Supplementary_Figure_SF1_Concordance_Matrix.png" = "Pooled MRD×PET agreement matrix with cell counts and percentages.",
  "Figure_3A_Forest_DualNeg.png" = "PFS Hazard Ratios (dual‑negative vs others); pooled REML (KnHa) with 95% prediction interval.",
  "Figure_3B_Funnel.png"                    = "Funnel plot of log(HR) vs SE with Egger’s p.",
  "Figure_4_Clinical_Pathway.png"           = "Clinical pathway schematic mapping 2×2 states to suggested actions.",
  "Figure_5_Conceptual.png"                 = "Conceptual overview linking MRD/PET concordance to outcomes."
)

legend_for <- function(filename, default = NULL) {
  val <- tryCatch(unname(LEGENDS[filename]), error = function(e) NULL)
  if (is.null(val) || length(val) == 0 || is.na(val)) default else val
}

table_legend_for <- function(filename, default = NULL) {
  val <- tryCatch(unname(TABLE_LEGENDS[filename]), error = function(e) NULL)
  if (is.null(val) || length(val) == 0 || is.na(val)) default else val
}

# Table helper (uses DT if available; otherwise kable)
if (!exists("show_table")) {
  show_table <- function(df, cap = NULL, caption = NULL, escape = FALSE, ...) {
  stopifnot(is.data.frame(df))
  cap <- if (!is.null(caption)) caption else cap
  df2 <- df

  # Coerce list-columns safely (DT can't render list-cols)
  df2[] <- lapply(df2, function(x) {
    if (is.list(x)) vapply(x, function(z) paste0(z, collapse = "; "), character(1)) else x
  })

  if (knitr::is_html_output() && requireNamespace("DT", quietly = TRUE)) {
    has_buttons <- NROW(df2) >= 10L
    opts <- list(
      dom        = if (has_buttons) "Bfrtip" else "tip",
      pageLength = if (NROW(df2) <= 0) 5L else min(10L, max(5L, NROW(df2))),
      buttons    = if (has_buttons) c("copy","csv","excel") else NULL
    )
    # DT fallback to kable on error
    out <- try(DT::datatable(
      df2,
      caption  = if (is.null(cap)) NULL else htmltools::tags$span(cap, class = "caption"),
      options  = opts,
      class    = "compact stripe hover",
      rownames = FALSE,
      escape   = escape,
      extensions = if (has_buttons) "Buttons" else NULL
    ), silent = TRUE)
    if (!inherits(out, "try-error")) return(out)
  }
  # Safe fallback everywhere
  knitr::kable(df2, caption = cap)
}

}



# ---------- Data IO helpers ---------------------------------------------------
if (!exists("safe_read_csv")) {
  safe_read_csv <- function(path, ...) {
    readr::read_csv(path, locale = readr::locale(encoding="UTF-8"), show_col_types = FALSE, ...) %>%
      janitor::clean_names()
  }
}
if (!exists("safe_read_xlsx")) {
  safe_read_xlsx <- function(path, sheet = NULL, ...) {
    df <- readxl::read_xlsx(path, sheet = sheet, ...)
    janitor::clean_names(as.data.frame(df, stringsAsFactors = FALSE))
  }
}
round_df3 <- function(df) if (is.data.frame(df)) dplyr::mutate(df, dplyr::across(where(is.numeric), ~round(.,3))) else df

# ---------- AC1 helper (Gwet) for 2×2 agreement ------------------------------
if (!exists("ac1_bin")) {
 ac1_bin <- function(a,b,c,d){
  a <- as.numeric(a); b <- as.numeric(b); c <- as.numeric(c); d <- as.numeric(d)
  n <- a+b+c+d
  if (!is.finite(n) || n <= 0) return(NA_real_)
  Po <- (b + d) / n
  # Rater A = MRD (neg/pos); Rater B = PET (neg/pos)
  p_neg_A <- (a + b)/n; p_pos_A <- 1 - p_neg_A
  p_neg_B <- (b + c)/n; p_pos_B <- 1 - p_neg_B  # <-- fixed
  p_neg <- (p_neg_A + p_neg_B)/2; p_pos <- (p_pos_A + p_pos_B)/2
  Pe <- p_neg*(1-p_neg) + p_pos*(1-p_pos)
  den <- 1 - Pe
  if (den <= 0) return(NA_real_)
  (Po - Pe) / den
}
}


# ---------- Enhanced Table 1 builder -----------------------------------------
if (!exists("table1_characteristics_plus")) {
  table1_characteristics_plus <- function(mrd_df){
    df <- janitor::clean_names(mrd_df)
    n_rows <- nrow(df)
    pick <- function(pat) { 
      nm <- names(df)
      h <- nm[grepl(pat, nm, ignore.case=TRUE)]
      if (length(h)) df[[h[1]]] else rep(NA, n_rows) }
    to_chr <- function(x) { if (is.null(x)) rep(NA_character_, n_rows) else as.character(x) }
    to_num <- function(x) { suppressWarnings(as.numeric(x)) }

    out <- tibble::tibble(
      study_id        = to_chr(df$study_id %||% pick("^study(_|)id$|^id$|^authors$|title")),
      setting         = to_chr(df$setting %||% pick("post.*induct|asct|transplant|car\\s*t|line|therapy|treatment")),
      timepoint       = to_chr(df$timepoint %||% pick("time.?point|assessment|align|follow[-_ ]?up|after")),
      mrd_platform    = to_chr(df$mrd_method %||% df$mrd_assay %||% pick("mrd.*(ngf|ngs|flow|seq|assay|platform)")),
      mrd_lod         = to_chr(df$mrd_sensitivity %||% df$mrd_neg_pct %||% pick("(lod|sensitiv|10\\^^-?[56])")),
      pet_rule        = to_chr(df$pet_interpretation %||% df$pet_deauville_below_4 %||% df$pet_reported %||% pick("pet.*(visual|deauville|criteria|negativ)")),
      n               = to_num(df$n %||% pick("^(n(_(total|cohort|patients))?|patients|sample(_?size)?|cohort(_?size)?)$")),
      survival_hr_avail = to_chr(df$pfs_dual %||% pick("pfs|os|hazard|hr"))
    ) %>%
    dplyr::mutate(
      survival_hr_avail = ifelse(is.na(survival_hr_avail) | survival_hr_avail=="", "No/NA", "Yes")
    )

    # Write pretty Excel + CSV
    writexl::write_xlsx(list("Table 1" = out), here::here("tables","Table_1_Study_Characteristics.xlsx"))
    readr::write_csv(out, here::here("tables","Table_1_Study_Characteristics.csv"))
    out
  }
}

# ---------- Clinical pathway schematic (basic ggplot version) -----------------
# Renamed to avoid clashing with the DiagrammeR version defined later
if (!exists("fig_clinical_pathway_basic")) {
  fig_clinical_pathway_basic <- function(file = "Figure_4_Clinical_Pathway.png",
                                   width = 8, height = 5, dpi = 300) {
    require(ggplot2); require(ggforce)

    nodes <- tibble::tribble(
      ~id,         ~x,   ~y,   ~w,  ~h,   ~fill,     ~label,
      "discordant", 0.25, 0.75, 0.42, 0.18, "#EDEBFE",
        "Discordant pairs
(MRD+/PET- or MRD-/PET+)",
      "concordant", 0.75, 0.75, 0.42, 0.18, "#E7F5ED",
        "Concordant dual-negative
(MRD-/PET-)",
      "escalate",   0.25, 0.30, 0.42, 0.18, "#FFF4E6",
        "Consider escalation / additional imaging
or alternative therapy",
      "deescalate", 0.75, 0.30, 0.42, 0.18, "#E8F7FF",
        "Consider de-escalation / watchful waiting"
    )

    arrows <- tibble::tribble(
      ~x,   ~y,   ~xend, ~yend,
       0.25, 0.66, 0.25, 0.39,
       0.75, 0.66, 0.75, 0.39
    )

    p <- ggplot() +
      ggforce::geom_roundrect(
        data = nodes,
        aes(xmin = x - w/2, xmax = x + w/2, ymin = y - h/2, ymax = y + h/2),
        radius = grid::unit(12, "pt"),
        fill = nodes$fill, color = "#455A64", linewidth = 0.6
      ) +
      geom_text(data = nodes, aes(x = x, y = y, label = label),
                lineheight = 0.98, fontface = "bold", size = 3.2) +
      geom_segment(data = arrows, aes(x = x, y = y, xend = xend, yend = yend),
                   arrow = arrow(length = grid::unit(7, "pt")),
                   linewidth = 0.6, color = "#455A64") +
      coord_fixed(xlim = c(0, 1), ylim = c(0, 1), clip = "off") +
      theme_void() +
      theme(plot.margin = margin(10, 10, 10, 10),
            plot.title = element_text(hjust = 0.5, face = "bold")) +
      labs(title = "Figure 4. Clinical pathway (concordance vs discordance)")

    dir.create(here::here("figs"), showWarnings = FALSE, recursive = TRUE)
    out <- here::here("figs", file)
    ggsave(out, p, width = width, height = height, dpi = dpi)
    invisible(out)
  }
}

# ---------- PRISMA params -----------------------------------------------------
reasons_screening_tbl <- tibble::tibble(
  Reason = c(
    "Review / guideline / consensus / editorial (no original data)",
    "Case report / small case series",
    "Methods / technical imaging / radiomics-only (no MRD or outcomes)",
    "Wrong population (plasmacytoma / precursor states)",
    "No MRD assessment",
    "No PET/CT assessment",
    "Outside prespecified timeframe"
  ),
  Count  = c(27, 4, 5, 1, 2, 2, 1)
)


reasons_fulltext_tbl <- tibble::tibble(
  Reason = c(
    "Trial registration or ongoing study with no published results",
    "Duplicate cohort / duplicate publication",
    "Insufficient data for MRD–PET concordance or prognostic analysis",
    "Wrong population (smouldering-only)",
    "Outside prespecified timeframe"
  ),
  Count = c(4, 3, 4, 1, 1)
)


PRISMA_OVERRIDE <- list(
  identified       = 112,
  auto_excluded    = 51,
  screened         = 61,
  excl_title_abs   = 42,
  sought           = 19,
  not_retrieved    = 0,
  full_text        = 23,
  excl_full_text   = 13,
  included         = 10,
  manual           = 4,
  reasons_screening = reasons_screening_tbl,
  reasons_fulltext  = reasons_fulltext_tbl
)




# Render with legend
render_prisma(PRISMA_OVERRIDE)


if (!exists("get_prisma_counts_2020")) {
  get_prisma_counts_2020 <- function(override) {
    tibble::tibble(
      identified     = override$identified,
      auto_excluded  = override$auto_excluded,
      screened       = override$screened,
      excl_title_abs = override$excl_title_abs,
      sought         = override$sought,
      not_retrieved  = override$not_retrieved,
      full_text      = override$full_text,
      excl_full_text = override$excl_full_text,
      included       = override$included,
      manual         = override$manual
    )
  }
}



# ---- UTF-8 hardening helpers -------------------------------------------------
clean_utf8_df <- function(df) {
  stopifnot(is.data.frame(df))
  names(df) <- iconv(names(df), from = "", to = "UTF-8", sub = "byte")
  for (nm in names(df)) {
    x <- df[[nm]]
    if (is.list(x)) {
      x <- vapply(x, function(z) if (length(z) == 0) "" else paste0(z, collapse = "; "), character(1))
    }
    if (is.factor(x)) x <- as.character(x)
    if (is.character(x)) x <- iconv(x, from = "", to = "UTF-8", sub = "byte")
    df[[nm]] <- x
  }
  df
}

to_utf8 <- function(x) {
  if (is.null(x)) return(x)
  if (is.data.frame(x)) return(clean_utf8_df(x))
  if (is.list(x))       return(lapply(x, to_utf8))
  if (is.character(x))  return(iconv(x, from = "", to = "UTF-8", sub = "byte"))
  x
}

opts0 <- getOption("htmlwidgets.TOJSON_ARGS")
tojson_args <- if (is.null(opts0)) list() else opts0
if (is.null(tojson_args$na))         tojson_args$na <- "null"
if (is.null(tojson_args$auto_unbox)) tojson_args$auto_unbox <- TRUE
options(htmlwidgets.TOJSON_ARGS = tojson_args)

# ----- Shared palette ---------------------------------------------------------
FIG_SHARED_PALETTE <- list(
  dualneg      = "#10b981",
  mrdnegpetpos = "#6366f1",
  mrdpospetneg = "#f59e0b",
  dualpos      = "#ef4444",
  border       = "#334155",
  text         = "#0f172a",
  link         = "#0891b2",
  bg           = "#ffffff"
)

# Small util to safely export DiagrammeR to PNG with HTML fallback
.export_grviz <- function(g, out_png, width_px = 1800, height_px = 1100) {
  out_dir <- here::here("figs")
  dir.create(out_dir, showWarnings = FALSE, recursive = TRUE)
  out_png <- file.path(out_dir, out_png)
  ok <- FALSE

  # Preferred: SVG → PNG
  if (requireNamespace("DiagrammeRsvg", quietly = TRUE) &&
      requireNamespace("rsvg", quietly = TRUE)) {
    svg <- DiagrammeRsvg::export_svg(g)
    rsvg::rsvg_png(charToRaw(svg), file = out_png, width = width_px, height = height_px)
    ok <- file.exists(out_png)
  }

  # Fallback 1: widget → HTML (viewable via show_png() iframe)
  if (!ok && requireNamespace("htmlwidgets", quietly = TRUE)) {
    htmlwidgets::saveWidget(g,
      file = file.path(out_dir, sub("\\.png$", ".html", basename(out_png))),
      selfcontained = TRUE
    )
  }

  # Optional Fallback 2 (if you want forced PNG without rsvg): webshot2
  if (!ok && requireNamespace("webshot2", quietly = TRUE)) {
    tmp_html <- file.path(out_dir, sub("\\.png$", ".html", basename(out_png)))
    if (!file.exists(tmp_html)) {
      htmlwidgets::saveWidget(g, file = tmp_html, selfcontained = TRUE)
    }
    try(webshot2::webshot(tmp_html, out_png, vwidth = width_px, vheight = height_px), silent = TRUE)
    ok <- file.exists(out_png)
  }

  invisible(ok)
}


# ----- Conceptual figure (DiagrammeR) ----------------------------------------
fig_conceptual_mm <- function(out_png = "Figure_5_Conceptual.png", pal = FIG_SHARED_PALETTE) {
  dot <- sprintf('
  digraph mm {
    graph [rankdir=LR, bgcolor="%s", splines=true]
    node  [shape=box, style="rounded,filled", fontname=Helvetica, fontsize=11, color="%s", fontcolor="%s"]
    edge  [arrowsize=0.7, color="%s", fontname=Helvetica]

    mrd  [label="MRD assessment",         fillcolor="#E8F5F1"]
    pet  [label="PET/CT assessment",      fillcolor="#EBF1FF"]
    conc [label="Concordance / Discordance\n(MRD-/PET-, MRD-/PET+, MRD+/PET-, MRD+/PET+)", fillcolor="#F8FAFC"]
    risk [label="Risk stratification\n(Dual negative vs others)", fillcolor="#FDF6EC"]
    outc [label="Outcomes (PFS / OS)",    fillcolor="#FFF1F2"]

    mrd -> conc; pet -> conc; conc -> risk; risk -> outc;

    dn [label="MRD-/PET-", fillcolor="%s"]; 
    mp [label="MRD-/PET+", fillcolor="%s"];
    pm [label="MRD+/PET-", fillcolor="%s"];
    pp [label="MRD+/PET+", fillcolor="%s"];
    {rank=same; dn; mp; pm; pp}
  }',
    pal$bg, pal$border, pal$text, pal$border,
    pal$dualneg, pal$mrdnegpetpos, pal$mrdpospetneg, pal$dualpos
  )
  g <- DiagrammeR::grViz(dot)
  .export_grviz(g, out_png, width_px = 1600, height_px = 720)
  return(here::here("figs", out_png))
}

```



```{r fig-utils, echo=FALSE, include=FALSE}
# One helper to handle: ggplot object, list with $plot, or a path string
emit_png <- function(obj, default_png, caption = NULL, width = 7, height = 5, dpi = 600) {
  dir.create(here::here("figs"), recursive = TRUE, showWarnings = FALSE)
  img <- here::here("figs", default_png)
  gp  <- NULL

  if (inherits(obj, "ggplot")) {
    gp <- obj
  } else if (is.list(obj) && !is.null(obj$plot) && inherits(obj$plot, "ggplot")) {
    gp <- obj$plot
    cand <- c(obj$out, obj$file)
    cand <- cand[vapply(cand, function(x) is.character(x) && length(x)==1 && file.exists(x), logical(1))]
    if (length(cand)) img <- cand[[1]]
  } else if (is.character(obj) && length(obj) == 1) {
    if (file.exists(obj)) img <- obj else {
      alt <- here::here("figs", basename(obj))
      if (file.exists(alt)) img <- alt
    }
  }

  if (!is.null(gp)) {
    if (!grepl("\\.png$", img, ignore.case = TRUE)) img <- sub("\\.[^.]*$", ".png", img)
    ok <- TRUE
    tryCatch(ggplot2::ggsave(filename = img, plot = gp, width = width, height = height, dpi = dpi),
             error = function(e) ok <<- FALSE)
    if (!ok) return(knitr::asis_output(sprintf("<em>Could not save figure to %s.</em>", htmltools::htmlEscape(img))))
  }

  if (file.exists(img)) show_png("figs", basename(img), caption = caption)
  else knitr::asis_output(sprintf("<em>Figure not generated (no PNG found for %s).</em>", default_png))
}

```


```{r data-import, message=FALSE, warning=FALSE, include=FALSE}
# Null-coalescing (ensure available)
`%||%` <- get("%||%", inherits = TRUE)
if (is.null(`%||%`)) `%||%` <- function(a, b) if (is.null(a) || !length(a) || all(is.na(a)) || identical(a, "")) b else a

# 1) Path resolution
mrd_path_candidates <- c(
  here::here("data","mrd_petct_data.csv"),
  here::here("mrd_petct_data.csv"),
  Sys.getenv("MRDPET_CSV",""),
  "/mnt/data/mrd_petct_data.csv"
)
mrd_path_candidates <- mrd_path_candidates[nzchar(mrd_path_candidates)]
exists_vec <- vapply(mrd_path_candidates, file.exists, logical(1))
if (!any(exists_vec)) {
  knitr::asis_output("<em>mrd_petct_data.csv not found in expected locations. Set env <code>MRDPET_CSV</code> or place file in <code>data/</code>.</em>")
  
  knitr::knit_exit()
}
mrd_path <- mrd_path_candidates[which(exists_vec)[1]]

# 2) Robust CSV reader with encoding fallback (why: user file may be latin-1)
read_csv_flex <- function(path, ...) {
  encs <- c("UTF-8","latin1","cp1252")
  last <- NULL
  for (e in encs) {
    res <- try(readr::read_csv(path,
                               locale = readr::locale(encoding = e),
                               show_col_types = FALSE, ...),
               silent = TRUE)
    if (!inherits(res, "try-error")) return(janitor::clean_names(res))
    last <- res
  }
  stop("Could not read CSV with encodings ", paste(encs, collapse = "/"), call. = FALSE)
}

# 3) Load and harmonize
mrd <- if (exists("safe_read_csv")) try(safe_read_csv(mrd_path), silent = TRUE) else NULL
if (inherits(mrd, "try-error") || is.null(mrd)) mrd <- read_csv_flex(mrd_path)
if (exists("harmonize_mrd_schema")) {
  mrd <- tryCatch(harmonize_mrd_schema(mrd), error = function(e) mrd)
}
mrd <- janitor::clean_names(mrd)

# 4) Ensure core columns exist and are numeric
need_cols <- c("a","b","c","d","n")
for (nm in need_cols) if (!nm %in% names(mrd)) mrd[[nm]] <- NA_real_
mrd <- dplyr::mutate(mrd, dplyr::across(dplyr::all_of(need_cols), ~ suppressWarnings(as.numeric(.x))))
attr(mrd, "abcd_definition") <- "a=MRD-/PET+, b=MRD-/PET-, c=MRD+/PET-, d=MRD+/PET+"

# 5) Sanitize pct_* columns (no renorm)
pct_cols <- grep("^pct_", names(mrd), value = TRUE)
if (length(pct_cols)) {
  for (nm in pct_cols) {
    x <- as.character(mrd[[nm]])
    x <- gsub(",", ".", x, fixed = TRUE)
    x <- gsub("\\s+", "", x)
    x <- gsub("\\.{2,}", ".", x)
    mrd[[nm]] <- suppressWarnings(as.numeric(x))
  }
}

# 6) Minimal schema validation
has_n  <- is.finite(suppressWarnings(as.numeric(mrd$n)))
has_abcd_row <- with(mrd, is.finite(a) | is.finite(b) | is.finite(c) | is.finite(d))
has_pct_row  <- if (length(pct_cols)) rowSums(sapply(mrd[pct_cols], is.finite)) >= 3 else rep(FALSE, nrow(mrd))

if (!any(has_n)) {
  knitr::asis_output("<em>No valid <code>n</code> values found in the dataset. Please add a column named <code>n</code>.</em>")
  knitr::knit_exit()
}
if (!any(has_abcd_row | has_pct_row)) {
  knitr::asis_output("<em>No usable count cells (<code>a,b,c,d</code>) or ≥3 of the four <code>pct_*</code> columns per row. Provide counts or percentages.</em>")
  knitr::knit_exit()
}

# 7) Study labels
pick_col <- function(df, patterns) {
  nm <- names(df)
  hit <- unlist(lapply(patterns, function(p) nm[grepl(p, nm, ignore.case=TRUE)]))
  if (length(hit)) hit[[1]] else NULL
}
first_chr <- function(x) { x <- as.character(x); x[!is.na(x) & nzchar(x)][1] %||% NA_character_ }
first_num <- function(x) { x <- suppressWarnings(as.numeric(x)); x[is.finite(x)][1] %||% NA_real_ }

sid_col <- pick_col(mrd, c("^study_id$","^study$","^authors?$","^title$"))
Study <- if (!is.null(sid_col)) as.character(mrd[[sid_col]]) else rep(NA_character_, nrow(mrd))
Study[!nzchar(Study) | is.na(Study)] <- sprintf("row_%d", which(!nzchar(Study) | is.na(Study)))
mrd$Study <- Study

# 8) Details panel (idempotent)
if (!exists("kv_table")) {
  kv_table <- function(named_vec) {
    th1 <- htmltools::tags$th(style="padding:4px 8px;border:1px solid #eee;vertical-align:top;width:34%;", "Field")
    th2 <- htmltools::tags$th(style="padding:4px 8px;border:1px solid #eee;vertical-align:top;", "Value")
    rows <- mapply(function(k, v) {
      htmltools::tags$tr(
        htmltools::tags$td(style="padding:4px 8px;border:1px solid #eee;font-weight:600;vertical-align:top;", htmltools::htmlEscape(k)),
        htmltools::tags$td(style="padding:4px 8px;border:1px solid #eee;vertical-align:top;", htmltools::HTML(htmltools::htmlEscape(v)))
      )
    }, names(named_vec), unname(named_vec), SIMPLIFY = FALSE)
    htmltools::tags$table(
      style="width:100%; border-collapse:collapse; font-size:12px; table-layout:auto;",
      htmltools::tags$thead(htmltools::tags$tr(th1, th2)),
      htmltools::tags$tbody(rows)
    )
  }
}
if (!exists("mk_html_details")) {
  mk_html_details <- function(df_study) {
    keep <- vapply(df_study, function(x) any(nzchar(as.character(na.omit(x)))), logical(1))
    df_study <- df_study[, keep, drop = FALSE]
    prefer <- c(
      "study_id","Study","authors","title","year","journal",
      "timepoint","timepoint_norm","mrd_method","mrd_assay","mrd_platform",
      "pet_interpretation","pet_deauville_below_4","pet_rule",
      "n_total","n_available_for_analysis","n","a","b","c","d",
      "pct_mrdneg_petpos","pct_mrdneg_petneg","pct_mrdpos_petneg","pct_mrdpos_petpos"
    )
    cols <- unique(c(intersect(prefer, names(df_study)), setdiff(names(df_study), prefer)))
    df_study <- df_study[, cols, drop = FALSE]
    sections <- lapply(seq_len(nrow(df_study)), function(i){
      row <- df_study[i, , drop = FALSE]
      val <- vapply(row, function(x){
        x <- as.character(x); x <- x[nzchar(x)]
        if (!length(x)) "" else paste(unique(x), collapse = "; ")
      }, character(1))
      htmltools::div(
        htmltools::tags$div(style="font-weight:700;margin:6px 0 4px 0;", sprintf("Row %d", i)),
        kv_table(val)
      )
    })
    as.character(
      htmltools::div(
        style = "max-height:480px; overflow:auto; padding:6px; background:#fafafa; border:1px solid #eee; border-radius:8px; white-space:normal; overflow-wrap:anywhere; word-break:normal;",
        sections
      )
    )
  }
}

details_tbl <- mrd %>%
  dplyr::group_by(Study) %>%
  dplyr::summarise(details_html = mk_html_details(dplyr::cur_data_all()), .groups = "drop")

# 9) Per-study summary with expandable details
col_ntotal <- pick_col(mrd, c("^n_total$","n\\s*total","^n_cohort$","^patients$","sample(_?size)?"))
col_navail <- pick_col(mrd, c("^n_available_for_analysis$","available.*analysis","^n_?available$","^n_usable$"))

mrd$N_total_src <- if (!is.null(col_ntotal)) suppressWarnings(as.numeric(mrd[[col_ntotal]])) else NA_real_
mrd$N_avail_src <- if (!is.null(col_navail)) suppressWarnings(as.numeric(mrd[[col_navail]])) else NA_real_
mrd$N_harmonized <- suppressWarnings(as.numeric(mrd$n %||% NA_real_))

summary_df <- mrd %>%
  dplyr::group_by(Study) %>%
  dplyr::summarise(
    `N Total` = first_num(dplyr::coalesce(N_total_src, N_harmonized)),
    `N Available for Analysis` = first_num(dplyr::coalesce(N_avail_src, N_harmonized)),
    .groups = "drop"
  ) %>%
  dplyr::left_join(details_tbl, by = "Study") %>%
  dplyr::mutate(`Details` = "&oplus;") %>%
  dplyr::select(`Details`, Study, `N Total`, `N Available for Analysis`, details_html)

# 10) DT rendering (HTML only)
knitr::asis_output(as.character(htmltools::tags$style(htmltools::HTML("
  td.details-control { cursor:pointer; text-align:center; width:28px; font-weight:700; }
  table.dataTable td, table.dataTable th { white-space: normal; word-break: normal; }
"))))

idx_details <- match("details_html", names(summary_df)) - 1L
cb_js <- sprintf(
"var idxDetails=%d;
function getDetails(d){ return (idxDetails >= 0 && d[idxDetails] !== null && d[idxDetails] !== undefined) ? d[idxDetails] : ''; }
table.on('click', 'td.details-control', function(){
  var tr = $(this).closest('tr');
  var row = table.row(tr);
  if (row.child.isShown()) { row.child.hide(); tr.removeClass('shown'); }
  else { row.child(getDetails(row.data())).show(); tr.addClass('shown'); }
});", idx_details)

DT::datatable(
  summary_df,
  caption = "Data Import — per-study summary (click “+” to expand details)",
  escape = FALSE, rownames = FALSE, filter = "top",
  extensions = c("Buttons","Scroller"),
  options = list(
    dom = "Bfrtip",
    buttons = c("copy","csv","excel"),
    pageLength = 25, lengthMenu = c(10,25,50,100),
    deferRender = TRUE, scrollX = TRUE, autoWidth = TRUE,
    columnDefs = list(
      list(targets = 0, className = "details-control", orderable = FALSE, width = "28px"),
      list(targets = idx_details, visible = FALSE),
      list(targets = 1, width = "380px"),
      list(targets = 2, width = "120px"),
      list(targets = 3, width = "200px")
    )
  ),
  callback = DT::JS(cb_js)
)

```


```{r build-cells-from-percents, include=FALSE}
# --- Build 2×2 counts from percentages (only when counts are all missing) ----

pct_cols <- c("pct_mrdneg_petpos","pct_mrdneg_petneg","pct_mrdpos_petneg","pct_mrdpos_petpos")
have_pct <- intersect(pct_cols, names(mrd))
if ("n" %in% names(mrd)) mrd$n <- suppressWarnings(as.numeric(mrd$n))

# Largest-remainder allocation to make integer counts that sum exactly to n
.lr_counts <- function(pcts, n){
  if (!is.finite(n) || n <= 0) return(rep(NA_real_, 4))
  pc <- as.numeric(pcts)
  k  <- sum(is.finite(pc))
  if (k < 3) return(rep(NA_real_, 4))

  s <- sum(pc, na.rm = TRUE)
  if (k == 4) {
    if      (is.finite(s) && abs(s - 100) <= 1) { }       # already percentages
    else if (is.finite(s) && abs(s -   1) <= .01) pc <- pc * 100
    else return(rep(NA_real_, 4))                         # reject incoherent input
  } else if (k == 3) {
    if      (is.finite(s) && abs(s - 100) <= 1) { pc[!is.finite(pc)] <- 100 - s }
    else if (is.finite(s) && abs(s -   1) <= .01) { pc <- pc * 100; pc[!is.finite(pc)] <- 100 - sum(pc, na.rm=TRUE) }
    else return(rep(NA_real_, 4))
  }

  raw  <- n * (pc/100)
  base <- floor(raw)
  left <- as.integer(round(n - sum(base)))
  if (left > 0) {
    frac <- raw - base
    ord  <- order(frac, decreasing = TRUE, na.last = NA)
    for (i in seq_len(left)) { j <- ord[((i-1) %% length(ord)) + 1]; base[j] <- base[j] + 1L }
  }
  as.numeric(base)
}

# Initialize provenance columns once
if (!"cells_source" %in% names(mrd)) mrd$cells_source <- NA_character_
if (!"imputed" %in% names(mrd))      mrd$imputed      <- NA

det <- 0L; ok4 <- 0L
if (length(have_pct) >= 3 && "n" %in% names(mrd)) {
  for (nm in have_pct) mrd[[nm]] <- suppressWarnings(as.numeric(mrd[[nm]]))
  for (nm in c("a","b","c","d")) if (!nm %in% names(mrd)) mrd[[nm]] <- NA_real_

  for (i in seq_len(nrow(mrd))) {
    if (all(!is.finite(mrd$a[i]), !is.finite(mrd$b[i]), !is.finite(mrd$c[i]), !is.finite(mrd$d[i]))) {
      pcts <- c(mrd$pct_mrdneg_petpos[i], mrd$pct_mrdneg_petneg[i], mrd$pct_mrdpos_petneg[i], mrd$pct_mrdpos_petpos[i])
      cnts <- .lr_counts(pcts, mrd$n[i])
      if (all(is.finite(cnts))) {
        mrd$a[i] <- cnts[1]; mrd$b[i] <- cnts[2]; mrd$c[i] <- cnts[3]; mrd$d[i] <- cnts[4]
        s <- sum(as.numeric(pcts), na.rm = TRUE)
        if (sum(is.finite(pcts)) == 3 && is.finite(s) && (abs(s - 100) <= 1 || abs(s - 1) <= .01)) {
          mrd$cells_source[i] <- "deterministic_pct_missing_one"; mrd$imputed[i] <- FALSE; det <- det + 1L
        } else {
          mrd$cells_source[i] <- "pct_to_counts_exact";          mrd$imputed[i] <- TRUE;  ok4 <- ok4 + 1L
        }
      }
    }
  }
  cat(sprintf("2×2 built from percentages: %d (3-of-4 → filled), %d (4-of-4 exact).\n", det, ok4))
} else {
  cat("*No usable percentage columns (>=3) with n to reconstruct a/b/c/d.*\n")
}

```


```{r reconcile_counts_n, include=FALSE}
if (!exists("mrd") || !is.data.frame(mrd) || nrow(mrd) == 0) {
  note("mrd data frame not available; skipping count–n reconciliation.")
} else {

  nr <- nrow(mrd)
  for (nm in c("a","b","c","d","n")) {
    if (!nm %in% names(mrd)) mrd[[nm]] <- rep(NA_real_, nr)
    mrd[[nm]] <- suppressWarnings(as.numeric(mrd[[nm]]))
  }

  # Keep originals for audit
  mrd$A0 <- mrd$a; mrd$B0 <- mrd$b; mrd$C0 <- mrd$c; mrd$D0 <- mrd$d

  # Largest-remainder scaling to target n (no reordering)
  .adjust_to_target <- function(x, target){
    x <- as.numeric(x)
    if (any(!is.finite(x)) || !is.finite(target) || target < 0) return(rep(NA_real_, length(x)))
    s <- sum(x)
    if (s == target) return(pmax(x, 0))
    if (s == 0) return(rep(NA_real_, length(x)))
    scaled <- x * target / s
    base   <- floor(scaled)
    left   <- as.integer(round(target - sum(base)))
    if (left > 0) {
      frac <- scaled - base
      ord  <- order(frac, decreasing = TRUE, method = "radix")
      L <- length(base)
      for (k in seq_len(left)) { j <- ord[((k-1) %% L) + 1L]; base[j] <- base[j] + 1L }
    }
    pmax(as.numeric(base), 0)
  }

  # Repair one row
  .repair_row <- function(a,b,c,d,n){
    v <- c(a,b,c,d); fin <- is.finite(v)
    if (!is.finite(n) || n < 0) return(list(a=a,b=b,c=c,d=d,n=n, ok=FALSE, reason="bad_n"))
    k <- sum(fin)
    if (k == 0) return(list(a=a,b=b,c=c,d=d,n=n, ok=FALSE, reason="no_counts"))

    if (k == 3) {  # fill the missing cell as remainder
      miss <- which(!fin); rem  <- n - sum(v[fin])
      if (!is.finite(rem) || rem < 0) return(list(a=a,b=b,c=c,d=d,n=n, ok=FALSE, reason="neg_remainder"))
      v[miss] <- rem
      ok <- sum(v) == n && all(v >= 0)
      return(list(a=v[1],b=v[2],c=v[3],d=v[4], n=n, ok=ok, reason=if (ok) "filled_1" else "sum_mismatch"))
    }

    if (k < 3) return(list(a=a,b=b,c=c,d=d,n=n, ok=FALSE, reason="too_few_counts"))

    v2 <- .adjust_to_target(v, n)
    ok <- all(is.finite(v2)) && sum(v2) == n && all(v2 >= 0)
    list(a=v2[1], b=v2[2], c=v2[3], d=v2[4], n=n, ok=ok,
         reason = if (ok) "rebalanced" else "rebalance_fail_or_zero")
  }

  # Apply repair
  out <- purrr::pmap_dfr(
    list(mrd$a, mrd$b, mrd$c, mrd$d, mrd$n),
    ~{ z <- .repair_row(..1, ..2, ..3, ..4, ..5)
       tibble::tibble(a=z$a,b=z$b,c=z$c,d=z$d,n=z$n, ok=z$ok, reason=z$reason) }
  )

  # Update repaired counts and flags
  mrd$a  <- out$a;  mrd$b <- out$b;  mrd$c <- out$c;  mrd$d <- out$d
  mrd$ok <- out$ok; mrd$repair_reason <- out$reason

  # If n missing but all four counts exist, set n = sum(counts)
  have4 <- is.finite(mrd$a) & is.finite(mrd$b) & is.finite(mrd$c) & is.finite(mrd$d)
  n2 <- suppressWarnings(as.numeric(mrd$n))
  n2[!is.finite(n2) & have4] <- mrd$a[have4] + mrd$b[have4] + mrd$c[have4] + mrd$d[have4]
  mrd$n <- n2

  # Concordance-ready subset (no row drops from mrd)
  mrd_conc <- dplyr::filter(
    mrd,
    is.finite(n), n > 0,
    is.finite(a) & is.finite(b) & is.finite(c) & is.finite(d),
    (a + b + c + d) == n
  )

  # Audit table
  audit <- dplyr::count(tibble::tibble(reason = mrd$repair_reason, ok = mrd$ok),
                        reason, ok, name = "rows")

  # Local DT renderer (never passes extensions = NULL); fallback to kable on error
  .local_dt <- function(df, caption = NULL, escape = FALSE) {
    n <- if (is.data.frame(df)) nrow(df) else 0L
    has_buttons <- (n >= 10L)
    opts <- list(
      dom        = if (has_buttons) "Bfrtip" else "tip",
      pageLength = if (n <= 0) 5L else min(10L, max(5L, n)),
      buttons    = if (has_buttons) c("copy","csv","excel") else NULL
    )
    args <- list(
      data     = if (is.data.frame(df)) df else data.frame(),
      caption  = if (is.null(caption)) NULL else htmltools::tags$span(caption, class="caption"),
      options  = opts,
      class    = "compact stripe hover",
      rownames = FALSE,
      escape   = escape
    )
    if (has_buttons) args$extensions <- "Buttons"
    do.call(DT::datatable, args)
  }

  # Emit audit (this chunk is include=FALSE; this still ensures the call can't crash)
  if (is_df(audit)) {
    try(.local_dt(audit, caption = "Count–n reconciliation audit"), silent = TRUE)
  } else {
    note("Count–n reconciliation audit not available at this stage.")
  }

  # Persist audit table for supplement
  try(readr::write_csv(audit, here::here("tables","audit_reconcile_counts.csv")), silent = TRUE)

  # Knit log
  cat(sprintf("Concordance-ready rows: %d / %d\n", nrow(mrd_conc), nrow(mrd)))
}
```



```{r primary-sensitivity, include=FALSE}
# ------------------ Primary & sensitivity analysis sets ----------------------
is_true <- function(x) {
  # tolerant TRUE detection
  if (is.null(x)) return(rep(FALSE, 0))
  if (is.character(x)) x <- trimws(tolower(x))
  if (is.character(x)) x <- ifelse(x %in% c("yes","true","t","1"), TRUE,
                                   ifelse(x %in% c("no","false","f","0",""), FALSE, NA))
  if (is.numeric(x))   x <- x != 0
  x <- suppressWarnings(as.logical(x))
  ifelse(is.na(x), FALSE, x)
}

.m <- if (exists("mrd_conc") && is.data.frame(mrd_conc)) {
  mrd_conc
} else {
  dplyr::filter(
    mrd,
    is.finite(n), n > 0,
    is.finite(a) & is.finite(b) & is.finite(c) & is.finite(d),
    (a + b + c + d) == n
  )
}

# normalize imputed to logical, if present
if ("imputed" %in% names(.m)) {
  .m$imputed <- is_true(.m$imputed)
} else {
  .m$imputed <- FALSE
}

mrd_primary     <- dplyr::filter(.m, !imputed)
mrd_sensitivity <- .m

cat(sprintf("Primary rows: %d | Sensitivity rows: %d | Total coherent: %d\n",
            nrow(mrd_primary), nrow(mrd_sensitivity), nrow(.m)))


```


```{r normalize-survival, include=FALSE}
# ------------------ Survival inputs standardization --------------------------
normalize_survival_inputs <- function(df,
                                      conf.level = 0.95,
                                      ref_flag_col = "dual_negative_is_reference",
                                      hr_preferred  = NULL,
                                      lcl_preferred = NULL,
                                      ucl_preferred = NULL,
                                      verbose = TRUE) {
  stopifnot(is.data.frame(df))
  to_num <- function(x) suppressWarnings(as.numeric(x))
  nz_n   <- function(x) sum(is.finite(x), na.rm = TRUE)

  pick_best <- function(df, patterns, preferred = NULL) {
    nx <- names(df)
    if (!is.null(preferred)) {
      for (nm in preferred) if (nm %in% nx) return(nm)
    }
    for (pat in patterns) {
      hit <- which(tolower(nx) == tolower(pat))
      if (length(hit) == 1L) return(nx[hit])
    }
    hits <- integer(0)
    for (pat in patterns) hits <- union(hits, grep(pat, nx, ignore.case = TRUE, perl = TRUE))
    if (length(hits)) {
      cand <- nx[hits]
      sc <- sapply(cand, function(nm) nz_n(to_num(df[[nm]])))
      cand[order(sc, decreasing = TRUE)][1]
    } else NA_character_
  }

  # FIXED: robust CI parser ("x - y" or "x to y"); handles unicode dashes/comma decimals
  parse_ci_pair <- function(v) {
    v <- as.character(v)
    v <- gsub(",", ".", v, fixed = TRUE)
    v <- gsub("−|–|—", "-", v)
    m <- regexec("([0-9]+\\.?[0-9]*(?:[eE][+-]?[0-9]+)?)\\s*(?:-|\\s+to\\s+)\\s*([0-9]+\\.?[0-9]*(?:[eE][+-]?[0-9]+)?)",
                 v, perl = TRUE)
    reg <- regmatches(v, m)
    L <- U <- rep(NA_real_, length(v))
    has <- lengths(reg) == 3L
    if (any(has)) {
      for (i in which(has)) {
        lo <- suppressWarnings(as.numeric(reg[[i]][2]))
        hi <- suppressWarnings(as.numeric(reg[[i]][3]))
        if (is.finite(lo) && is.finite(hi) && lo > hi) { tmp <- lo; lo <- hi; hi <- tmp }
        L[i] <- lo; U[i] <- hi
      }
    }
    list(LCL = L, UCL = U)
  }

  # ---------- fast path: yi/sei already present ----------
  loghr_cands <- c("^loghr$", "log[_ ]?hr", "\\byi\\b")
  se_cands    <- c("^se$", "^sei$", "std[_ ]?error")
  have_log <- any(grepl(paste(loghr_cands, collapse="|"), names(df), ignore.case=TRUE)) &&
              any(grepl(paste(se_cands,    collapse="|"), names(df), ignore.case=TRUE))

  if (have_log) {
    loghr_col <- pick_best(df, loghr_cands)
    se_col    <- pick_best(df, se_cands)
    out <- df
    out$logHR <- to_num(out[[loghr_col]])
    out$SE    <- to_num(out[[se_col]])
    # fill hr/lcl/ucl only where missing to avoid clobbering partial good rows
    need_hr  <- !"hr"  %in% tolower(names(out))
    need_lcl <- !"lcl" %in% tolower(names(out))
    need_ucl <- !"ucl" %in% tolower(names(out))
    if (need_hr)  out$hr  <- exp(out$logHR)
    if (need_lcl) out$lcl <- exp(out$logHR - 1.96*out$SE)
    if (need_ucl) out$ucl <- exp(out$logHR + 1.96*out$SE)
    if (verbose) message("normalize_survival_inputs(): using existing logHR/SE -> ",
                         loghr_col, " / ", se_col)
    return(out)
  }

  # ---------- locate HR / LCL / UCL by any naming ----------
  hr_col  <- pick_best(df, c("^hr$", "hazard[_ ]?ratio", "pfs[_ ]?hr", "hr\\b.*pfs", "pfs\\b.*hr", "\\bhr\\b"),
                       preferred = hr_preferred)
  lcl_col <- pick_best(df, c("^lcl$", "lower", "lower[_ ]?ci", "ci[_\\.]?low", "lower95", "lcl95", "\\blcl\\b"),
                       preferred = lcl_preferred)
  ucl_col <- pick_best(df, c("^ucl$", "upper", "upper[_ ]?ci", "ci[_\\.]?high", "upper95", "ucl95", "\\bucl\\b"),
                       preferred = ucl_preferred)
  ci_text_col <- pick_best(df, c("^ci$", "95[%]?[ ]?ci", "confidence[_ ]?interval", "pfs.*ci", "ci.*pfs"))

  hr  <- if (!is.na(hr_col))  to_num(df[[hr_col]])  else rep(NA_real_, nrow(df))
  lcl <- if (!is.na(lcl_col)) to_num(df[[lcl_col]]) else rep(NA_real_, nrow(df))
  ucl <- if (!is.na(ucl_col)) to_num(df[[ucl_col]]) else rep(NA_real_, nrow(df))

  if ((all(is.na(lcl)) || all(is.na(ucl))) && !is.na(ci_text_col)) {
    pair <- parse_ci_pair(df[[ci_text_col]])
    if (all(is.na(lcl))) lcl <- pair$LCL
    if (all(is.na(ucl))) ucl <- pair$UCL
  }

  if (all(is.na(hr))) {
    est_col  <- pick_best(df, c("^estimate$", "effect", "value"))
    type_col <- pick_best(df, c("^type$", "measure", "effect[_ ]?measure", "scale"))
    if (!is.na(est_col) && !is.na(type_col)) {
      is_hr <- grepl("hr|hazard", df[[type_col]], ignore.case = TRUE)
      if (any(is_hr, na.rm = TRUE)) {
        tmp <- to_num(df[[est_col]]); hr[is_hr] <- tmp[is_hr]
      }
    }
  }

  out <- df
  out$hr  <- if ("hr"  %in% tolower(names(out))) out$hr  else hr
  out$lcl <- if ("lcl" %in% tolower(names(out))) out$lcl else lcl
  out$ucl <- if ("ucl" %in% tolower(names(out))) out$ucl else ucl

  if (all(is.na(out$hr)) || all(is.na(out$lcl)) || all(is.na(out$ucl))) {
    warning("normalize_survival_inputs(): could not confidently locate HR/LCL/UCL; returning NA columns.")
    out$logHR <- NA_real_; out$SE <- NA_real_
    out$yi    <- NA_real_; out$sei <- NA_real_
    if (verbose) message("Tried HR around hr/hazard/pfs_hr; CI around lower/lcl/upper/ucl or a CI text field.")
    return(out)
  }

  out <- prepare_survival_meta(out,
                               hr_col = "hr", lcl_col = "lcl", ucl_col = "ucl",
                               ref_flag_col = ref_flag_col, conf.level = conf.level)

  if (verbose) {
    message("normalize_survival_inputs(): mapped HR/LCL/UCL (row-wise tolerant).")
  }
  out
}



```


```{r surv-builder, include=FALSE}
# Produces: surv_df with columns (study, logHR, SE)
# Also writes: tables/surv_column_mapping.csv and tables/surv_df_dualneg.csv

stopifnot(exists("mrd"), is.data.frame(mrd))

# ---------- helpers ----------
.pick <- function(df, candidates) {
  cn <- names(df); if (!length(cn)) return(NULL)
  ix <- which(tolower(cn) %in% tolower(candidates))
  if (length(ix)) return(cn[ix[1]])
  for (cand in candidates) {
    w <- which(grepl(cand, cn, ignore.case = TRUE))
    if (length(w)) return(cn[w[1]])
  }
  NULL
}
.num <- function(x) suppressWarnings(as.numeric(x))

# Robust parser for CI strings like "0.23–0.88", "0.23 - 0.88", or "95% CI 0.23 to 0.88"
.parse_ci <- function(s) {
  if (is.null(s) || !length(s)) return(c(NA_real_, NA_real_))
  s <- enc2utf8(as.character(s))

  # Clean text safely (PCRE), escaping all bracket chars
  s <- gsub("\\s*\\(.*?\\)", " ", s, perl = TRUE)                            
  s <- gsub("95%\\s*ci", " ", s, ignore.case = TRUE, perl = TRUE)
  s <- gsub("[\\[\\]\\(\\)\\{\\}]", " ", s, perl = TRUE)                     
  s <- gsub("[\u2013\u2014]", "-", s, perl = TRUE)                           
  s <- gsub(",", ".", s, fixed = TRUE)                                       
  s <- gsub("\\s+", " ", s, perl = TRUE); s <- trimws(s)

  # Extract two numbers separated by '-' or ' to '
  m <- regexec("([0-9]+(?:\\.[0-9]+)?)\\s*(?:-|\\s+to\\s+)\\s*([0-9]+(?:\\.[0-9]+)?)", s, perl = TRUE)
  g <- regmatches(s, m)
  if (!length(g) || !length(g[[1]]) || length(g[[1]]) < 3) return(c(NA_real_, NA_real_))
  lo <- suppressWarnings(as.numeric(g[[1]][2]))
  hi <- suppressWarnings(as.numeric(g[[1]][3]))
  if (is.finite(lo) && is.finite(hi) && lo > hi) { tmp <- lo; lo <- hi; hi <- tmp }
  c(lo, hi)
}

.short_label <- function(x) {
  x <- as.character(x)
  x <- gsub("\\(.*?\\)", "", x); x <- gsub("(?i)et\\s+al\\.?", "", x)
  x <- gsub("\\s+", " ", x); x <- trimws(x)
  yr <- stringr::str_extract(x, "(19|20)\\d{2}")
  lead <- gsub(",.*$", "", x); surname <- sub("\\s+.*$", "", lead)
  ifelse(is.na(yr), surname, paste0(surname, " ", yr))
}

# ---------- column detection ----------
study_col <- .pick(mrd, c("study","study_id","short_id","id","author","authors",
                          "first_author_year","title","citation","ref"))
loghr_col <- .pick(mrd, c("logHR","log_hr","log_hazard_ratio","logHR_PFS_dualneg","logHR_PFS_dual_neg"))
se_col    <- .pick(mrd, c("SE","se","SE_logHR","se_logHR","SE_logHR_PFS_dualneg","SE_logHR_PFS_dual_neg"))
hr_col    <- .pick(mrd, c("HR","hr","hazard_ratio","pfs_dual_neg","HR_dualneg","HR_dual_neg","pfs_dual_neg_HR"))
lo_col    <- .pick(mrd, c("CI_low","CI.L","CI_lo","LCL","lower","ci_lower","ci_lo","lo"))
hi_col    <- .pick(mrd, c("CI_high","CI.U","CI_hi","UCL","upper","ci_upper","ci_hi","hi"))
ci_col    <- .pick(mrd, c("pfs_dual_neg_ci","HR_CI","CI","ci","ci95","ci_95","HR (95% CI)","hr_ci_text"))

tmp <- tibble::tibble(
  Study   = if (!is.null(study_col)) as.character(mrd[[study_col]]) else sprintf("Study_%02d", seq_len(nrow(mrd))),
  logHR_d = if (!is.null(loghr_col)) .num(mrd[[loghr_col]]) else NA_real_,
  SE_d    = if (!is.null(se_col))    .num(mrd[[se_col]])    else NA_real_,
  HR_n    = if (!is.null(hr_col))    .num(mrd[[hr_col]])    else NA_real_,
  LO_n    = if (!is.null(lo_col))    .num(mrd[[lo_col]])    else NA_real_,
  HI_n    = if (!is.null(hi_col))    .num(mrd[[hi_col]])    else NA_real_,
  CI_s    = if (!is.null(ci_col))    as.character(mrd[[ci_col]]) else NA_character_
)

# Parse the CI string **row-wise** (even if logHR/SE columns exist but are mostly empty)
ci_parsed <- t(vapply(tmp$CI_s, .parse_ci, numeric(2)))
colnames(ci_parsed) <- c("LO_s","HI_s")
tmp <- cbind(tmp, as.data.frame(ci_parsed))

# Prefer direct logHR/SE; else derive from numeric CI; else from text CI
with_num_rng <- is.finite(tmp$LO_n) & is.finite(tmp$HI_n)
with_str_rng <- is.finite(tmp$LO_s) & is.finite(tmp$HI_s)

logHR_from_num <- ifelse(with_num_rng & is.finite(tmp$HR_n),
                         log(tmp$HR_n),
                         ifelse(with_num_rng, (log(tmp$LO_n)+log(tmp$HI_n))/2, NA_real_))
SE_from_num    <- ifelse(with_num_rng, (log(tmp$HI_n)-log(tmp$LO_n))/(2*1.96), NA_real_)

logHR_from_str <- ifelse(with_str_rng, (log(tmp$LO_s)+log(tmp$HI_s))/2, NA_real_)
SE_from_str    <- ifelse(with_str_rng, (log(tmp$HI_s)-log(tmp$LO_s))/(2*1.96), NA_real_)

surv_df <- tibble::tibble(
  Study = tmp$Study,
  logHR = dplyr::coalesce(tmp$logHR_d, logHR_from_num, logHR_from_str),
  SE    = dplyr::coalesce(tmp$SE_d,    SE_from_num,    SE_from_str)
) %>%
  dplyr::filter(is.finite(logHR), is.finite(SE)) %>%
  dplyr::distinct(Study, .keep_all = TRUE) %>%
  dplyr::mutate(
    StudyShort = .short_label(Study),
    vi    = SE^2,
    HR    = exp(logHR),
    HR_lo = exp(logHR - 1.96*SE),
    HR_hi = exp(logHR + 1.96*SE)
  )

# Persist for audit
try(readr::write_csv(surv_df, here::here("tables","surv_df_dualneg.csv")), silent = TRUE)

hr_ids <- if (exists("surv_df") && is.data.frame(surv_df)) {
unique(na.omit(as.character(surv_df$StudyShort)))
} else character(0)

```


```{r surv-harmonize-labels, include=FALSE}
# Ensure surv_df has the exact columns expected downstream, safely & once.

.has <- function(df, nm) (!is.null(df)) && is.data.frame(df) && (nm %in% names(df))
.is_ok <- function(x) is.finite(x) & !is.na(x)

if (exists("surv_df") && is.data.frame(surv_df) && nrow(surv_df) > 0) {

  # Standardize Study column
  if (!"Study" %in% names(surv_df) && "study" %in% names(surv_df)) {
    surv_df <- dplyr::rename(surv_df, Study = study)
  }
  if (!"Study" %in% names(surv_df)) {
    surv_df$Study <- sprintf("Study_%02d", seq_len(nrow(surv_df)))
  }
  surv_df$Study <- as.character(surv_df$Study)

  # Coerce numeric for meta fields
  for (nm in c("logHR","SE","yi","sei","HR","HR_lo","HR_hi")) {
    if (nm %in% names(surv_df)) {
      surv_df[[nm]] <- suppressWarnings(as.numeric(surv_df[[nm]]))
    }
  }

  # Drop non-estimable rows
  surv_df <- dplyr::filter(surv_df, .is_ok(logHR), .is_ok(SE))

  # Add derived columns only if missing
  if (!"vi" %in% names(surv_df))   surv_df$vi <- surv_df$SE^2
  if (!"HR" %in% names(surv_df))   surv_df$HR <- exp(surv_df$logHR)
  if (!"HR_lo" %in% names(surv_df)) surv_df$HR_lo <- exp(surv_df$logHR - 1.96*surv_df$SE)
  if (!"HR_hi" %in% names(surv_df)) surv_df$HR_hi <- exp(surv_df$logHR + 1.96*surv_df$SE)

  # Short label "Surname Year" (robust to punctuation/UTF-8)
  if (!"StudyShort" %in% names(surv_df)) {
    short_label <- function(x) {
      x <- as.character(x)
      x <- gsub("\\(.*?\\)", "", x)                      # drop (n=...), etc.
      x <- gsub("(?i)et\\s+al\\.?", "", x, perl = TRUE)  # drop 'et al.'
      x <- gsub("\\s+", " ", x); x <- trimws(x)
      yr <- stringr::str_extract(x, "(19|20)\\d{2}")
      lead <- sub(",.*$", "", x)                         # take first author token
      surname <- sub("\\s+.*$", "", lead)
      ifelse(is.na(yr), surname, paste0(surname, " ", yr))
    }
    surv_df$StudyShort <- short_label(surv_df$Study)
  }

  # Persist harmonized table for audit/supplement
  dir.create(here::here("tables"), showWarnings = FALSE, recursive = TRUE)
  try(readr::write_csv(surv_df, here::here("tables","surv_df_dualneg_harmonized.csv")), silent = TRUE)

} else {
  note("surv_df not available or empty after builder; skipping harmonization/labels.")
}


```



```{r family-dedup, message=FALSE, warning=FALSE, include=FALSE}
# ========== Family de-duplication with audit (Supplementary Table S2) =========
allow_postwindow <- TRUE                 # set FALSE for protocol-strict build
window_end       <- as.Date("2025-06-30")

if (!exists("mrd") || !is.data.frame(mrd) || !nrow(mrd)) {
  knitr::asis_output("*No rows in 'mrd' — skipping family de-duplication.*")
} else {
  mrd_raw <- mrd
  mrd     <- janitor::clean_names(mrd)

  nrows   <- nrow(mrd)
  get_chr <- function(nm) if (nm %in% names(mrd)) as.character(mrd[[nm]]) else rep(NA_character_, nrows)
  get_num <- function(nm) if (nm %in% names(mrd)) suppressWarnings(as.numeric(mrd[[nm]])) else rep(NA_real_, nrows)

  # --- DOI & dates -------------------------------------------------------------
  norm_doi <- function(x){
    x <- tolower(trimws(as.character(x)))
    x <- gsub("^https?://(dx\\.)?doi\\.org/", "", x)
    x <- gsub("\\s+", "", x)
    ifelse(nzchar(x), x, NA_character_)
  }
  mrd$doi      <- if ("doi"  %in% names(mrd)) norm_doi(mrd$doi) else NA_character_
  mrd$year     <- if ("year" %in% names(mrd)) get_num("year") else NA_real_
  pub_date_raw <- if ("pub_date" %in% names(mrd)) suppressWarnings(as.Date(mrd$pub_date)) else as.Date(NA)
  mrd$pub_date <- ifelse(is.na(pub_date_raw), as.Date(paste0(mrd$year, "-12-31")), pub_date_raw)

  # --- n and completeness ------------------------------------------------------
  mrd$n <- dplyr::coalesce(get_num("n"), get_num("n_available_for_analysis"),
                           get_num("n_total"), get_num("sample_size"), get_num("patients"))

  for (nm in intersect(c("a","b","c","d"), names(mrd))) {
    mrd[[nm]] <- suppressWarnings(as.numeric(mrd[[nm]]))
  }
  for (nm in intersect(c("pct_mrdneg_petpos","pct_mrdneg_petneg","pct_mrdpos_petneg","pct_mrdpos_petpos"), names(mrd))) {
    mrd[[nm]] <- suppressWarnings(as.numeric(mrd[[nm]]))
  }

  has_abcd <- rowSums(cbind(is.finite(mrd$a), is.finite(mrd$b), is.finite(mrd$c), is.finite(mrd$d)), na.rm = TRUE) >= 4
  has_pct3 <- rowSums(cbind(
    is.finite(mrd$pct_mrdneg_petpos),
    is.finite(mrd$pct_mrdneg_petneg),
    is.finite(mrd$pct_mrdpos_petneg),
    is.finite(mrd$pct_mrdpos_petpos)
  ), na.rm = TRUE) >= 3

  # --- Outcome typing ----------------------------------------------------------
  tp_raw      <- dplyr::coalesce(get_chr("pet_timing"), get_chr("timepoint"), get_chr("landmark"))
  is_baseline <- grepl("base", tp_raw, ignore.case = TRUE)
  pfs_any     <- is.finite(get_num("pfs_pet")) | is.finite(get_num("hr")) | ("loghr" %in% names(mrd))

  mrd$outcome_type <- dplyr::case_when(
    has_abcd | has_pct3       ~ "concordance",
    is_baseline & pfs_any     ~ "baseline_PET_prognosis",
    TRUE                      ~ NA_character_
  )
  mrd$timepoint_norm <- ifelse(is.na(tp_raw) | tp_raw == "", NA_character_, tp_raw)

  # --- Family label (CASSIOPET + fallback) ------------------------------------
  cassio_dois <- c("10.1182/blood-2019-123143", "10.3324/haematol.2021.280051")
  txt <- paste(get_chr("title"), get_chr("authors"), get_chr("study_id"))
  is_cass <- grepl("cassio(peia|pet)", txt, ignore.case = TRUE) | (!is.na(mrd$doi) & mrd$doi %in% cassio_dois)
  fallback_lab <- dplyr::coalesce(get_chr("cohort_id"), get_chr("study_id"),
                                  get_chr("trial"), get_chr("authors"),
                                  paste0("row_", seq_len(nrows)))
  mrd$study_family <- ifelse(is_cass, "CASSIOPET", fallback_lab)

  # normalise missing timepoints for CASSIOPET
  miss_tp <- is.na(mrd$timepoint_norm) | mrd$timepoint_norm == ""
  mrd$timepoint_norm[is_cass & mrd$outcome_type == "concordance"            & miss_tp] <- "post-ASCT"
  mrd$timepoint_norm[is_cass & mrd$outcome_type == "baseline_PET_prognosis" & miss_tp] <- "baseline"

  # --- Priority score (lower = better) ----------------------------------------
  postwindow <- mrd$pub_date > window_end
  win_rank   <- ifelse(isTRUE(allow_postwindow), 0L, ifelse(postwindow, 2L, 0L))

  src_txt    <- tolower(paste(get_chr("source_type"), get_chr("journal"), get_chr("venue")))
  peer_rank  <- ifelse(grepl("abstract|supplement", src_txt), 1L, 0L)

  comp_rank  <- ifelse(has_abcd, 0L, ifelse(has_pct3, 1L, 2L))
  n_rank     <- rank(-dplyr::coalesce(mrd$n, 0), ties.method = "average")

  mrd$priority <- win_rank*1000 + peer_rank*100 + comp_rank*10 + n_rank

  # --- Choose one per family × outcome × landmark -----------------------------
  mrd$study_name <- dplyr::coalesce(get_chr("short_cite"), get_chr("authors"), get_chr("title"))
  mrd$trial_name <- dplyr::coalesce(get_chr("trial"), get_chr("study_family"))

  kept <- mrd %>%
    dplyr::group_by(study_family, outcome_type, timepoint_norm) %>%
    dplyr::slice_min(order_by = priority, n = 1, with_ties = FALSE) %>%
    dplyr::ungroup()

  # --- Audit table (S2) --------------------------------------------------------
  keys_all  <- paste(mrd$study_family,  mrd$outcome_type,  mrd$timepoint_norm)
  keys_keep <- paste(kept$study_family, kept$outcome_type, kept$timepoint_norm)
  mrd$keep_flag <- keys_all %in% keys_keep

  reason <- rep("", nrows)
  reason[mrd$keep_flag] <- "retained (best within family × outcome × landmark)"
  reason[!mrd$keep_flag & !isTRUE(allow_postwindow) & postwindow] <- "excluded: post-window (pre-amendment build)"
  reason[!mrd$keep_flag & grepl("abstract|supplement", src_txt) & reason=="" ] <- "excluded: abstract (lower priority)"
  reason[!mrd$keep_flag & !(has_abcd | has_pct3) & reason=="" ]               <- "excluded: no paired MRD/PET data"

  kept_key <- paste(kept$study_family, kept$outcome_type, kept$timepoint_norm)
  keep_map <- setNames(kept$study_name %||% kept$trial_name, kept_key)
  dup_of   <- keep_map[keys_all]
  dup_of[mrd$keep_flag] <- "—"

  audit <- tibble::tibble(
    `Study name`               = mrd$study_name,
    `Trial / cohort`           = mrd$trial_name,
    `Landmark`                 = dplyr::coalesce(mrd$timepoint_norm, ""),
    `Outcome type`             = dplyr::coalesce(mrd$outcome_type, ""),
    `Duplicate of`             = dplyr::coalesce(dup_of, ""),
    `Reason retained/excluded` = ifelse(reason=="", "excluded (lower priority within family)", reason),
    `DOI`                      = mrd$doi,
    `Year`                     = mrd$year,
    `N (reported)`             = mrd$n,
    `Post-window`              = ifelse(isTRUE(postwindow), "yes", "no")
  ) %>%
    dplyr::arrange(`Trial / cohort`, `Outcome type`, `Landmark`,
                   dplyr::desc(`Reason retained/excluded` == "retained (best within family × outcome × landmark)"))

  # keep only the retained rows for downstream
  mrd <- kept

  # --- Write outputs -----------------------------------------------------------
  dir.create("tables", showWarnings = FALSE, recursive = TRUE)
  readr::write_csv(audit,       "tables/dedup_audit_S2.csv")
  readr::write_csv(
    mrd %>% dplyr::count(study_family, outcome_type, timepoint_norm, name = "rows_kept") %>%
      dplyr::arrange(study_family, outcome_type, timepoint_norm),
    "tables/dedup_groups_retained.csv"
  )

  knitr::kable(utils::head(audit, 25), caption = "Supplementary Table S2 (excerpt) — Study selection & deduplication audit")
}

```


# Study Selection

## Figure 1. PRISMA Diagram

```{r prisma, echo=FALSE, fig.align="center", out.width="100%", fig.retina=2}
# Single, robust render of Figure 1 with optional trim and HTML fallback.

dir.create(here::here("figs"), showWarnings = FALSE, recursive = TRUE)

# Get counts (override-aware)
ct <- if (exists("get_prisma_counts_2020")) {
  tryCatch(get_prisma_counts_2020(override = PRISMA_OVERRIDE), error = function(e) NULL)
} else NULL

# Fallback: coerce list → tibble row if needed
if (is.null(ct) && exists("PRISMA_OVERRIDE") && is.list(PRISMA_OVERRIDE)) {
  ct <- tryCatch(tibble::as_tibble_row(PRISMA_OVERRIDE), error = function(e) NULL)
}

fig_png  <- here::here("figs","Figure_1_PRISMA_Diagram.png")
fig_html <- here::here("figs","Figure_1_PRISMA_Diagram.html") 
fig_pdf <- here::here("figs","Figure_1_PRISMA_Diagram.pdf")  


ok <- FALSE
if (!is.null(ct) && NROW(ct) == 1 && exists("render_prisma")) {
  ok <- isTRUE(tryCatch(
    render_prisma(
      ct,
      out       = fig_png,
      width_px  = 1800,
      height_px = 900,
      fontsize  = 28,
      box_width = 9
    ),
    error = function(e) { message("render_prisma() failed: ", e$message); FALSE }
  ))
}

# Optional trim (no hard dep on magick)
if (ok && file.exists(fig_png) && requireNamespace("magick", quietly = TRUE)) {
  try({
    img  <- magick::image_read(fig_png)
    img2 <- magick::image_trim(img, fuzz = 8) %>%
            magick::image_border(color = "white", geometry = "12x12")
    magick::image_write(img2, fig_png)
  }, silent = TRUE)
}

# Display priority: PDF → PNG widget → html
if (file.exists(fig_pdf)) {
  knitr::include_graphics(fig_pdf)
} else if (file.exists(fig_png)) {
  knitr::include_graphics(fig_png)
} else if (file.exists(fig_html) && knitr::is_html_output()) {
  htmltools::htmlDependency("") # noop to ensure htmltools loaded
  cat(htmltools::renderTags(htmltools::includeHTML(fig_html))$html)
} else {
  knitr::asis_output("<em>PRISMA counts unavailable — figure skipped.</em>")
}


```



## Table 1. Study Characteristics

```{r t1, echo=FALSE, message=FALSE, warning=FALSE}
# ---- helpers ----
safe_chr <- function(x) if (is.null(x)) NA_character_ else as.character(x)
safe_num <- function(x) suppressWarnings(as.numeric(x))

pick1_vec <- function(..., .n){
  xs <- list(...)
  for (i in seq_along(xs)) {
    if (is.null(xs[[i]])) xs[[i]] <- rep(NA_character_, .n)
    xs[[i]] <- as.character(xs[[i]])
    if (length(xs[[i]]) == 0) xs[[i]] <- rep(NA_character_, .n)
    if (length(xs[[i]]) == 1) xs[[i]] <- rep(xs[[i]][1], .n)
  }
  out <- xs[[1]]
  if (length(xs) > 1) for (i in 2:length(xs)) {
    idx <- is.na(out) | !nzchar(out)
    out[idx] <- xs[[i]][idx]
  }
  out
}

norm_yesno <- function(x){
  v  <- tolower(trimws(as.character(x)))
  out <- ifelse(v %in% c("1","y","yes","true","t","simultaneous","concurrent","same day","same-day","same_day"), "Yes",
         ifelse(v %in% c("0","n","no","false","f"), "No/NA", NA_character_))
  if (all(is.na(out))) {
    xn <- suppressWarnings(as.numeric(v))
    out <- ifelse(is.finite(xn) & xn > 0, "Yes",
           ifelse(is.finite(xn) & xn == 0, "No/NA", out))
  }
  out
}

# robust key: first author token + 4-digit year
.author_year_key <- function(x){
  x <- as.character(x)
  auth <- tolower(sub("^\\s*([^[:space:][:punct:]]+).*", "\\1", x))  # first token
  yr   <- stringr::str_extract(x, "(19|20)\\d{2}")
  ifelse(nzchar(auth) & nzchar(yr), paste0(auth, "_", yr), NA_character_)
}

# ----------------- build Table 1 fields -----------------
df <- janitor::clean_names(mrd)
nr <- nrow(df)
if (is.null(nr) || nr == 0) {
  knitr::asis_output("<em>No rows available for Table 1.</em>")
} else {
  # Study label (priority)
  study <- pick1_vec(df$study_id, df$study, df$authors, df$title, .n = nr)
  study[is.na(study) | !nzchar(study)] <- paste0("row_", seq_len(nr))

  # Year
  year <- if ("year" %in% names(df)) safe_num(df$year) else {
    safe_num(stringr::str_extract(study, "(19|20)\\d{2}"))
  }

  # N total
  n_total <- safe_num(pick1_vec(df$n, df$n_total, df$patients, df$sample_size, .n = nr))

  # MRD platform (method + threshold)
  mrd_method    <- pick1_vec(df$mrd_method, df$mrd_assay, df$mrd_platform, df$mrd_technique, .n = nr)
  mrd_threshold <- pick1_vec(df$mrd_sensitivity, df$mrd_neg_pct, df$mrd_threshold, df$mrd_limit, .n = nr)
  mrd_platform  <- dplyr::case_when(
    !is.na(mrd_method) & nzchar(mrd_method) & !is.na(mrd_threshold) & nzchar(mrd_threshold) ~ paste0(mrd_method, " (", mrd_threshold, ")"),
    !is.na(mrd_method) & nzchar(mrd_method) ~ mrd_method,
    TRUE ~ mrd_threshold
  )

  # PET criteria (normalize Deauville)
  pet_criteria <- pick1_vec(df$pet_interpretation, df$pet_deauville_below_4, df$pet_rule, df$pet_criteria, df$pet_reporting, .n = nr)
  pet_criteria <- dplyr::case_when(
    is.na(pet_criteria) ~ NA_character_,
    stringr::str_detect(pet_criteria, "(?i)deauville") &
      stringr::str_detect(pet_criteria, "(?i)\\b<\\s*4\\b|\\bscore\\s*<\\s*4\\b|\\b0\\s*-\\s*3\\b") ~ "Deauville < 4",
    TRUE ~ as.character(pet_criteria)
  )

  # Simultaneous MRD/PET flag
  sim_candidates <- c(
    "simultaneous_mrd_pet_measurement","simultaneous_mrd_pet","simultaneous_mrd_and_pet",
    "simultaneous_pet_mrd","mrd_pet_simultaneous","mrdpet_simultaneous",
    "concurrent_mrd_pet","concurrent_pet_mrd","concurrent_assessment",
    "same_day_mrd_pet","same_day_assessment","same_day"
  )
  sim_raw <- rep(NA_character_, nr)
  for (nm in sim_candidates) if (nm %in% names(df)) { sim_raw <- df[[nm]]; break }
  if (all(is.na(sim_raw)) && "time_diff_days" %in% names(df)) {
    td <- safe_num(df$time_diff_days)
    sim_raw <- ifelse(is.finite(td) & abs(td) <= 30, "Yes", "No/NA")
  }
  sim_flag <- norm_yesno(sim_raw)

  # ----------------- HR available (from survival meta-analysis input) -----------------
# ----------------- HR available (directly from mrd) -----------------
# accepts any of these: pfs_dual_neg (HR), pfs_dual_neg_ci (CI string), pfs_hr, hr
get1 <- function(...) {
  xs <- list(...)
  out <- NULL
  for (x in xs) if (!is.null(x)) { out <- x; break }
  out
}

hr_num <- suppressWarnings(as.numeric(get1(df$pfs_dual_neg, df$pfs_hr, df$hr)))
hr_ci  <- pick1_vec(get1(df$pfs_dual_neg_ci, df$pfs_ci, df$ci), .n = nr)

has_ci_digits <- ifelse(is.na(hr_ci), FALSE, grepl("[0-9]", hr_ci))
hr_available  <- ifelse(is.finite(hr_num) | has_ci_digits, "Yes", "No/NA")


  # ----------------- Assemble Table 1 -----------------
t1 <- tibble::tibble(
  Study = safe_chr(study),
  Year  = year,
  N     = n_total,
  `MRD platform` = safe_chr(mrd_platform),
  `PET criteria` = safe_chr(pet_criteria),
  `Simultaneous MRD and PET/CT Assessments` = sim_flag,
  `HR available` = hr_available
) %>%
  dplyr::arrange(dplyr::desc(!is.na(Year)), Year, Study)

# --- Save Table 1 to /tables as CSV + Excel ---
tables_dir <- if (requireNamespace("here", quietly = TRUE)) here::here("tables") else "tables"
if (!dir.exists(tables_dir)) dir.create(tables_dir, recursive = TRUE, showWarnings = FALSE)

readr::write_csv(t1, file.path(tables_dir, "Table_1_Characteristics.csv"))
if (requireNamespace("writexl", quietly = TRUE)) {
  writexl::write_xlsx(t1, file.path(tables_dir, "Table_1_Characteristics.xlsx"))
} else {
  warning("writexl not installed; Excel export skipped.")
}

  # ----------------- Render -----------------
  caption_txt <- "Table 1. Study characteristics"
  if (knitr::is_html_output() && requireNamespace("DT", quietly = TRUE)) {
    DT::datatable(
      t1,
      caption = htmltools::tags$caption(style = "caption-side: top; text-align: left;", caption_txt),
      class = "compact stripe hover",
      options = list(dom = 't', paging = FALSE, searching = FALSE, lengthChange = FALSE, info = FALSE, ordering = TRUE, autoWidth = TRUE),
      escape = TRUE
    )
  } else {
    print(knitr::kable(t1, caption = caption_txt))
  }


}


```




## Supplementary Table ST1. Complete Log-Screen

```{r ST1, echo=FALSE, message=FALSE, warning=FALSE}
need_load <- !exists("screen_all") || !is.data.frame(screen_all) || nrow(screen_all) == 0

if (need_load) {
  candidates <- c(
    here::here("data","Screening_Log.xlsx"),
    here::here("data","Screening Log.xlsx"),
    here::here("data","screening_log.xlsx"),
    here::here("data","Screening_Log.csv"),
    here::here("tables","Screening_Log.xlsx"),
    Sys.getenv("SCREENING_LOG",""),
    "/mnt/data/Screening_Log.xlsx"
  )
  candidates <- candidates[nzchar(candidates)]
  candidates <- candidates[file.exists(candidates)]

  if (length(candidates)) {
    f <- candidates[1]
    if (grepl("\\.xlsx$", f, ignore.case = TRUE)) {
      sh <- readxl::excel_sheets(f)
      lst <- lapply(sh, function(s){
        df <- readxl::read_xlsx(f, sheet = s)
        df$Sheet <- s
        as.data.frame(df, stringsAsFactors = FALSE)
      })
      screen_all <- dplyr::bind_rows(lst)  # <-- namespace to avoid missing function
    } else {
      screen_all <- readr::read_csv(f, show_col_types = FALSE)
    }
    screen_all <- janitor::clean_names(screen_all)
    message(sprintf("Loaded screening log: %s (%d rows).", basename(f), nrow(screen_all)))
  }
}

if (!exists("screen_all") || is.null(screen_all) || !is.data.frame(screen_all) || nrow(screen_all) == 0) {
  knitr::asis_output("*No `Screening_Log.xlsx` found in `data/` — skipping screening log viewer.*")
} else {
  # Load libs BEFORE any htmltools::tags/HTML references
  suppressPackageStartupMessages({
    library(htmltools)
    library(dplyr)
    library(tidyr)
    library(janitor)
    if (requireNamespace("DT", quietly = TRUE)) library(DT)
  })

  # ---------- CSS (wrap + clamp) ----------
  knitr::asis_output(as.character(tags$style(HTML("
    .clamp3 { display:-webkit-box; -webkit-box-orient:vertical; -webkit-line-clamp:3; overflow:hidden; white-space:normal; }
    .clamp2 { display:-webkit-box; -webkit-box-orient:vertical; -webkit-line-clamp:2; overflow:hidden; white-space:normal; }
    td.details-control { cursor:pointer; text-align:center; font-weight:700; width:28px; }
    .details-box { padding:0.6em 0.8em; line-height:1.3; }
    .details-box p { margin:0.2em 0; }
    table.dataTable td, table.dataTable th { white-space: normal; word-break: break-word; }
  "))))

  # ---------- helpers ----------
  find_col <- function(df, pattern) {
    hit <- names(df)[grepl(pattern, names(df), ignore.case = TRUE)]
    if (length(hit)) hit[[1]] else NULL
  }
  esc   <- function(x) htmlEscape(ifelse(is.na(x), "", as.character(x)))
  brify <- function(x) gsub("\n", "<br>", x, fixed = TRUE)
  linkify <- function(v) {
    v <- as.character(v); v[!nzchar(v)] <- NA
    href <- ifelse(is.na(v), NA, ifelse(grepl("^https?://", v, TRUE), v, paste0("https://", v)))
    ifelse(is.na(href), NA_character_, paste0('<a href="', href, '" target="_blank">', href, '</a>'))
  }
  trueish <- function(x) {
    if (is.logical(x)) return(x)
    x <- tolower(trimws(as.character(x)))
    x %in% c("1","y","yes","true","t","include","included","full text reviewed","reviewed")
  }

  # ---------- column finders ----------
  col_title    <- find_col(screen_all, "title|article_?title")
  col_auth     <- find_col(screen_all, "^authors?$|author|author_list")
  col_abstr    <- find_col(screen_all, "abstract|summary")
  col_year     <- find_col(screen_all, "year|publication_year|pub_year")
  col_jour     <- find_col(screen_all, "journal|source|venue")
  col_doi      <- find_col(screen_all, "(^|_)doi($|_)|^doi$")
  col_decision <- find_col(screen_all, "decision|include.?exclude.?maybe|eligibil|screen.*decision|final.*include")
  col_ftselect <- find_col(screen_all, "full.?text.*(assess|review|retriev)|ft_?review|ft_?assess|fulltext")
  col_finalinc <- find_col(screen_all, "final.*include|include.*final|^included$|^included_flag$|^include$")
  col_sheet    <- if ("Sheet" %in% names(screen_all)) "Sheet" else NULL

  # ---------- derived vectors ----------
  Title_raw     <- if (!is.null(col_title))  screen_all[[col_title]]  else NA_character_
  Authors_full  <- if (!is.null(col_auth))   esc(screen_all[[col_auth]])  else ""
  Abstract_full <- if (!is.null(col_abstr))  esc(screen_all[[col_abstr]]) else ""
  Title_disp    <- paste0("<div class='clamp3'>", esc(Title_raw), "</div>")
  Authors_disp  <- paste0("<div class='clamp3'>", Authors_full, "</div>")
  Year          <- if (!is.null(col_year))   screen_all[[col_year]]   else NA
  Journal       <- if (!is.null(col_jour))   screen_all[[col_jour]]   else NA_character_
  DOI           <- if (!is.null(col_doi))    linkify(screen_all[[col_doi]]) else NA_character_
  Source        <- if (!is.null(col_sheet))  screen_all[[col_sheet]]  else NA_character_

  derive_decision <- function(df) {
    v <- rep(NA_character_, nrow(df))
    if (!is.null(col_decision)) {
      raw <- tolower(trimws(as.character(df[[col_decision]])))
      v <- dplyr::case_when(
        grepl("inc", raw) ~ "Include",
        grepl("exc", raw) ~ "Exclude",
        grepl("may|uncertain|pend", raw) ~ "Maybe",
        TRUE ~ NA_character_
      )
    }
    factor(v, levels = c("Include","Exclude","Maybe"))
  }
  derive_ft_selected   <- function(df) if (is.null(col_ftselect)) rep(NA_character_, nrow(df)) else ifelse(trueish(df[[col_ftselect]]), "Yes", "No")
  derive_included_final<- function(df) if (is.null(col_finalinc)) rep(NA_character_, nrow(df)) else ifelse(trueish(df[[col_finalinc]]), "Yes", "No")

  Decision_first  <- derive_decision(screen_all)
  FT_selected     <- derive_ft_selected(screen_all)
  Included_final  <- derive_included_final(screen_all)
  Reason_full     <- if (!is.null(col_reason <- find_col(screen_all, "reason|exclusion_reason|why"))) esc(screen_all[[col_reason]]) else ""
  Decision_full   <- ifelse(is.na(FT_selected), "", FT_selected)

  # =========================
  # TOP: Full import (scrollable)
  # =========================
  full_df <- janitor::clean_names(screen_all)
  if (requireNamespace("DT", quietly = TRUE)) {
    DT::datatable(
      full_df,
      caption = "Supplementary Table 1. Complete screening log (full import — scroll to explore)",
      escape = FALSE, rownames = FALSE, filter = "top",
      extensions = c("Scroller","Buttons"),
      options = list(
        dom = "Bfrtip",
        buttons = c("copy","csv","excel"),
        deferRender = TRUE,
        scrollX = TRUE,
        scrollY = 520,
        scroller = TRUE
      )
    )
  } else {
    knitr::kable(utils::head(full_df, 25), caption = "Supplementary Table 1 (preview — install DT for full viewer)")
  }

  knitr::asis_output("<div style='height:16px'></div>")

  # =======================================
  # BOTTOM: Interactive viewer (Abstract hidden)
  # =======================================
  df_disp <- tibble::tibble(
    `Details: click to expand` = "&oplus;",
    Source  = Source,
    Title   = Title_disp,
    Authors = Authors_disp,
    Year, Journal, DOI,
    `Decision After First Scanning`   = Decision_first,
    `Selected for Full Text Review`   = FT_selected,
    `Included after Full Text Review` = Included_final,
    `Reason for First Decision`       = paste0("<div class='clamp2'>", brify(Reason_full), "</div>"),
    Authors_full, Abstract_full, Reason_full, Decision_full
  )

  # Hidden detail columns (0-based indices)
  idxAuth  <- (match("Authors_full",   names(df_disp)) - 1L); if (is.na(idxAuth))  idxAuth  <- -1L
  idxAbst  <- (match("Abstract_full",  names(df_disp)) - 1L); if (is.na(idxAbst))  idxAbst  <- -1L
  idxReas  <- (match("Reason_full",    names(df_disp)) - 1L); if (is.na(idxReas))  idxReas  <- -1L
  idxDecis <- (match("Decision_full",  names(df_disp)) - 1L); if (is.na(idxDecis)) idxDecis <- -1L
  hide_idx <- c(idxAuth, idxAbst, idxReas, idxDecis); hide_idx <- hide_idx[hide_idx >= 0]

  if (requireNamespace("DT", quietly = TRUE)) {
    cb_js <- sprintf(
"var idxAuth=%d, idxAbst=%d, idxReas=%d, idxDecis=%d;
function take(d, idx){ return (idx >= 0 && d[idx] !== null && d[idx] !== undefined) ? d[idx] : ''; }
table.on('click', 'td.details-control', function(){
  var tr = $(this).closest('tr');
  var row = table.row(tr);
  if (row.child.isShown()) { row.child.hide(); tr.removeClass('shown'); }
  else {
    var auth  = take(row.data(), idxAuth);
    var reas  = take(row.data(), idxReas);
    var decis = take(row.data(), idxDecis);
    var html = '<div class=\\'details-box\\'>' +
               (decis ? '<p><strong>Full-text selected:</strong> '+decis+'</p>' : '') +
               (reas  ? '<p><strong>Reason:</strong> '+reas+'</p>' : '') +
               (auth  ? '<p><strong>Authors:</strong> '+auth+'</p>' : '') +
               '</div>';
    row.child(html).show(); tr.addClass('shown');
  }
});", idxAuth, idxAbst, idxReas, idxDecis)

    opts <- list(
      dom = "Bfrtip",
      buttons = c("copy","csv","excel"),
      deferRender = TRUE, scrollX = TRUE, scrollY = 480, scroller = TRUE,
      pageLength = 25, lengthMenu = c(10,25,50,100),
      autoWidth = TRUE,
      columnDefs = list(
        list(targets = 0, className = "details-control", orderable = FALSE, width = "28px"),
        list(targets = 1, width = "80px"),
        list(targets = 2, width = "420px"),
        list(targets = 3, width = "360px")
      )
    )
    if (length(hide_idx)) {
      opts$initComplete <- DT::JS(sprintf(
        "function(){ this.api().columns([%s]).visible(false); }",
        paste(hide_idx, collapse = ",")
      ))
    }

    DT::datatable(
      df_disp,
      caption = "Screening log interactive viewer (row details; abstract hidden)",
      escape = FALSE, rownames = FALSE, filter = "top",
      extensions = c("Scroller","Buttons"),
      options = opts,
      callback = DT::JS(cb_js)
    )
  } else {
    knitr::kable(
      df_disp[, c("Source","Title","Year","Journal","DOI","Decision After First Scanning",
                  "Selected for Full Text Review","Included after Full Text Review")],
      caption = "Screening log (static preview — install DT for interactive viewer)"
    )
  }
}

```



# Concordance analysis

## Table 2. Concordance: κ and McNemar

```{r include=FALSE}
# Prefer counts over reported %'s to avoid assertion failures
pct_cols <- c("pct_mrdneg_petpos","pct_mrdneg_petneg","pct_mrdpos_petneg","pct_mrdpos_petpos")
for (nm in pct_cols) if (!nm %in% names(mrd)) mrd[[nm]] <- NA_real_
have_counts <- with(mrd, is.finite(a)&is.finite(b)&is.finite(c)&is.finite(d)&is.finite(n)&n>0)
mrd[have_counts, pct_cols] <- NA_real_
```


```{r table2_concordance_render, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
# Section 3.1 — Build/print Table 2 (Concordance) with HR flag, single table

`%||%` <- function(a,b) if (is.null(a) || length(a)==0) b else a
.author_year_key <- function(x) {
  x  <- as.character(x)
  auth <- tolower(sub("([A-Za-z]+).*", "\\1", x))  # first author token
  yr   <- stringr::str_extract(x, "(19|20)\\d{2}") # 4-digit year
  paste0(auth, "_", yr)
}

# choose concordance source and strip to required vars to avoid name clashes
src_raw <- if (exists("mrd_conc") && is.data.frame(mrd_conc) && nrow(mrd_conc)) mrd_conc else mrd
if (!is.data.frame(src_raw) || !nrow(src_raw)) {
  knitr::asis_output("<div><em>Table 2 cannot be built: missing or empty concordance data.</em></div>")
} else {
  # keep only the variables `table2_concordance()` expects; drop any existing `Study`/`StudyShort`
  src <- dplyr::select(
    src_raw,
    dplyr::any_of(c("study_id","a","b","c","d","n"))
  )

  if (!all(c("study_id","a","b","c","d","n") %in% names(src))) {
    knitr::asis_output("<div><em>Table 2 cannot be built: required columns (study_id,a,b,c,d,n) not all present.</em></div>")
  } else {

    # 1) Build the full augmented concordance table (adds SE/CI, AC1/PABAK, writes CSV/XLSX)
    tab2 <- table2_concordance(
      conc_per_study   = src,
      file_excel       = "Table_2_Concordance_Augmented.xlsx",
      file_csv         = "Table_2_Concordance_Augmented.csv",
      include_ac1_pabak = TRUE
    )

    # 2) Add robust HR flag (match by first-author+year)
    hr_keys <- character(0)
    if (exists("surv_df") && is.data.frame(surv_df) && nrow(surv_df)) {
      hr_keys <- .author_year_key(dplyr::coalesce(as.character(surv_df$Study), as.character(surv_df$StudyShort)))
      hr_keys <- unique(stats::na.omit(hr_keys))
    }
    tab2 <- dplyr::mutate(
      tab2,
      key = .author_year_key(Study) #,
      #`HR available` = ifelse(key %in% hr_keys, "Yes", "No/NA")
    )

    # 3) Select and order exactly the columns you want (no legacy HR column)
    want <- c(
      "Study","n",
      "MRD-/PET+","MRD-/PET-","MRD+/PET-","MRD+/PET+",
      "pct_agree","Kappa","SE","lower","upper",
      "McNemar_p","McNemar_midp",
      "AC1","AC1_se","AC1_lcl","AC1_ucl",
      "PABAK","PABAK_lcl","PABAK_ucl" #,
      #"HR available"
    )
    show_cols <- intersect(want, names(tab2))
    tab2 <- tab2[, show_cols, drop = FALSE]

    # 4) Print (last expression so knitr renders it)
    DT::datatable(
      tab2,
      caption = htmltools::tags$caption(
        style="caption-side: top; text-align:left;",
        "Table 3.1. Concordance (counts, %agree, κ (SE, 95% CI), McNemar p / mid-p, AC1, PABAK). ",
        htmltools::tags$small("Studies contributing to PFS HR meta-analysis (dual-negative vs others) are marked in ‘HR available’.")
      ),
      extensions = "Buttons",
      options = list(dom="Bfrtip", buttons=c("copy","csv","excel"),
                     paging=FALSE, scrollX=TRUE)
    )
  }
}

```


```{r tab-2-legend, echo=FALSE, results='asis'}
htmltools::tags$div(
  style = "margin-bottom: 24px;",   # <-- extra space below the legend
  htmltools::tags$details(
    htmltools::tags$summary("Legend: columns in Table 2 (click to expand)"),
    htmltools::tags$ul(
      htmltools::tags$li(htmltools::tags$b("Study"), " — Study identifier."),
      htmltools::tags$li(htmltools::tags$b("n"), " — Total paired MRD–PET assessments."),
      htmltools::tags$li(htmltools::tags$b("MRD-/PET+ (a)"), " — Discordant count."),
      htmltools::tags$li(htmltools::tags$b("MRD-/PET- (b)"), " — Concordant dual-negative count."),
      htmltools::tags$li(htmltools::tags$b("MRD+/PET- (c)"), " — Discordant count."),
      htmltools::tags$li(htmltools::tags$b("MRD+/PET+ (d)"), " — Concordant dual-positive count."),
      htmltools::tags$li(htmltools::tags$b("%agree / pct_agree"), " — Observed agreement (%) = 100 × (b + d) / n."),
      htmltools::tags$li(htmltools::tags$b("Kappa"), " — Cohen’s κ (unitless)."),
      htmltools::tags$li(htmltools::tags$b("SE, lower, upper"), " — Standard error and 95% CI for κ."),
      htmltools::tags$li(htmltools::tags$b("McNemar_p"), " — McNemar test p-value (a vs c)."),
      htmltools::tags$li(htmltools::tags$b("McNemar_midp / mid_p"), " — Mid-p McNemar p-value (if available)."),
      htmltools::tags$li(htmltools::tags$b("AC1, AC1_se, AC1_lcl/ucl (or AC1_lower/upper)"), " — Gwet’s AC1 and SE/95% CI."),
      htmltools::tags$li(htmltools::tags$b("PABAK, PABAK_lcl/ucl (or PABAK_lower/upper)"), " — PABAK and its 95% CI.")
    )
  )
)


```

## Fréchet–Hoeffding bounds
```{r frechet-bounds, echo=FALSE, message=FALSE, warning=FALSE, results='asis', eval=FALSE}
# 1) Pick a concordance-ready source (prefer mrd_conc; fallback to mrd)
src <- if (exists("mrd_conc") && is.data.frame(mrd_conc) && nrow(mrd_conc) > 0) mrd_conc else mrd
stopifnot(is.data.frame(src))

# 2) Safe helpers ---------------------------------------------------------------
`%||%` <- function(a, b) if (is.null(a) || length(a) == 0) b else a

# Coalesce over whichever label columns actually exist in df (vectorized)
safe_label <- function(df, candidates = c("Study","StudyShort","study_id","Authors","title")) {
  have <- candidates[candidates %in% names(df)]
  if (!length(have)) return(sprintf("Study_%02d", seq_len(nrow(df))))
  lab <- as.character(df[[have[1]]])
  if (length(have) > 1) {
    for (nm in have[-1]) lab <- dplyr::coalesce(lab, as.character(df[[nm]]))
  }
  ifelse(is.na(lab) | !nzchar(lab), sprintf("Study_%02d", seq_len(nrow(df))), lab)
}

# Kappa from full 2x2 counts
fh_from_marginals <- function(a,b,c,d,n) {
  if (!is.finite(n) || n <= 0) return(NA_real_)
  a <- as.numeric(a); b <- as.numeric(b); c <- as.numeric(c); d <- as.numeric(d); n <- as.numeric(n)
  if (any(!is.finite(c(a,b,c,d)))) return(NA_real_)
  p0 <- (b + d) / n
  r1 <- (a + b) / n; r2 <- (c + d) / n
  c1 <- (b + c) / n; c2 <- (a + d) / n
  pe <- r1*c1 + r2*c2
  if (!is.finite(pe) || (1 - pe) <= 0) return(NA_real_)
  (p0 - pe) / (1 - pe)
}

# FH bounds (best/worst κ) given fixed marginals (on count scale)
fh_bounds_one <- function(b, d, r1, c1, n) {
  b  <- as.numeric(b); d <- as.numeric(d); r1 <- as.numeric(r1); c1 <- as.numeric(c1); n <- as.numeric(n)
  r2 <- n - r1; c2 <- n - c1
  b_min <- max(0, r1 - c2, c1 - (n - r1))
  b_max <- min(r1, c1)
  build_k <- function(b_star) {
    d_star <- r2 - (c2 - b_star)
    a_star <- r1 - b_star
    c_star <- c1 - b_star
    fh_from_marginals(a_star, b_star, c_star, d_star, n)
  }
  c(lower = build_k(b_min), upper = build_k(b_max))
}

# 3) Build tidy input (robust to missing columns) --------------------------------
df0 <- src %>%
  dplyr::mutate(
    a = suppressWarnings(as.numeric(.data[["a"]] %||% NA_real_)),
    b = suppressWarnings(as.numeric(.data[["b"]] %||% NA_real_)),
    c = suppressWarnings(as.numeric(.data[["c"]] %||% NA_real_)),
    d = suppressWarnings(as.numeric(.data[["d"]] %||% NA_real_)),
    n = suppressWarnings(as.numeric(.data[["n"]] %||% NA_real_))
  ) %>%
  dplyr::filter(is.finite(a), is.finite(b), is.finite(c), is.finite(d), is.finite(n), n > 0)

if (!nrow(df0)) {
  knitr::asis_output("<div class='note'><em>FH bounds unavailable: no rows with complete a,b,c,d,n.</em></div>")
} else {
  labs <- safe_label(df0)
  df <- dplyr::mutate(df0,
                      Study = labs,
                      r1 = a + b,          # MRD− margin
                      c1 = b + c)          # PET− margin

  # 4) Compute point κ and FH bounds per study ----------------------------------
  K_point <- mapply(fh_from_marginals, df$a, df$b, df$c, df$d, df$n)
  BB <- mapply(fh_bounds_one, df$b, df$d, df$r1, df$c1, df$n)  # 2 x n matrix
  K_low  <- as.numeric(BB["lower", ])
  K_high <- as.numeric(BB["upper", ])
  Width  <- K_high - K_low

  fh_tbl <- tibble::tibble(
    Study  = df$Study,
    n      = as.integer(df$n),
    K_point= round(K_point, 3),
    K_low  = round(K_low, 3),
    K_high = round(K_high, 3),
    Width  = round(Width, 3)
  )

  # 5) Print + persist -----------------------------------------------------------
  if (exists("show_table")) {
    show_table(fh_tbl, caption = "Fréchet–Hoeffding bounds for κ (point estimate and bounds)")
  } else {
    knitr::kable(fh_tbl, caption = "Fréchet–Hoeffding bounds for κ (point estimate and bounds)")
  }
  dir.create(here::here("tables"), showWarnings = FALSE, recursive = TRUE)
  readr::write_csv(fh_tbl, here::here("tables","ST1_Frechet_Hoeffding_kappa_bounds.csv"))
}

cat(
"<em><strong>Fréchet–Hoeffding bounds. κ identification intervals with point estimate.</strong> ",
"Each horizontal segment shows, for a given study, the range of Cohen’s κ values that are <em>mathematically compatible</em> with the observed (MRD−/PET±) margins (the Fréchet–Hoeffding identification interval); the solid dot marks the usual plug-in κ estimate. ",
"The vertical dashed line at κ=0 denotes ‘no agreement beyond chance’. ",
"Intervals lying entirely to the right of 0 indicate agreement beyond chance; entirely left indicate systematic disagreement; intervals that cross 0 signal that the sign of κ is not identified from the observed margins (often due to sparse or highly imbalanced categories), so study-level κ should be interpreted with caution. ",
"Note that these bounds reflect <em>identifiability given the 2×2 margins</em>, not sampling variability, and thus differ from conventional confidence intervals.</em>"
)


```



```{r st1-diagnostic-builder, echo=FALSE, message=FALSE, warning=FALSE}
# ---------- 1) Choose a source (with explicit diagnostics) ----------
src_name <- NA_character_
if (exists("tab2") && is.data.frame(tab2) && nrow(tab2) > 0) {
  src <- tab2; src_name <- "tab2 (in-memory)"
} else if (file.exists(file.path("tables","Table_2_Concordance_Augmented.csv"))) {
  src <- try(readr::read_csv(file.path("tables","Table_2_Concordance_Augmented.csv"),
                             show_col_types = FALSE), silent = TRUE)
  if (!inherits(src, "try-error")) src_name <- "tables/Table_2_Concordance_Augmented.csv"
} else if (exists("mrd") && is.data.frame(mrd) && nrow(mrd) > 0) {
  src <- mrd; src_name <- "mrd (raw)"
} else {
  src <- data.frame()
}

# Print what we found
knitr::asis_output(paste0("<small><em>ST1 source: ", src_name,
                          "; n=", ifelse(is.data.frame(src), nrow(src), 0),
                          "; cols = ", paste(names(src), collapse=", "),
                          "</em></small>"))

# ---------- 2) Normalize column names (handle ASCII/Unicode minus) ----------
normalize_names <- function(nm) {
  nm <- gsub("−","-", nm, fixed = TRUE) # Unicode minus -> ASCII
  nm
}
names(src) <- normalize_names(names(src))

# ---------- 3) Map to a,b,c,d,n,Study ----------
pick <- function(nm, opts) nm[match(opts, nm, nomatch = 0L)][1]
nm <- names(src)

a_col <- pick(nm, c("a","MRD-/PET+","MRDneg_PETpos","MRDneg.PETpos","MRDneg_PET+","MRDneg.PET+"))
b_col <- pick(nm, c("b","MRD-/PET-","MRDneg_PETneg","MRDneg.PETneg","MRDneg_PET-","MRDneg.PET-"))
c_col <- pick(nm, c("c","MRD+/PET-","MRDpos_PETneg","MRDpos.PETneg","MRDpos_PET-","MRDpos.PET-"))
d_col <- pick(nm, c("d","MRD+/PET+","MRDpos_PETpos","MRDpos.PETpos","MRDpos_PET+","MRDpos.PET+"))
n_col <- pick(nm, c("n","N","total","Total"))
s_col <- pick(nm, c("Study","StudyShort","Authors","study","study_id","Title"))

needed <- c(s_col,a_col,b_col,c_col,d_col,n_col)
if (any(is.na(needed))) {
  knitr::asis_output(paste0(
    "<em>ST1 omitted: could not find columns. Missing = ",
    paste(c("Study","a","b","c","d","n")[is.na(needed)],
          collapse=", "),
    ".</em>"))
  knitr::knit_exit()
}

df2 <- data.frame(
  Study = as.character(src[[s_col]]),
  a = suppressWarnings(as.numeric(src[[a_col]])),
  b = suppressWarnings(as.numeric(src[[b_col]])),
  c = suppressWarnings(as.numeric(src[[c_col]])),
  d = suppressWarnings(as.numeric(src[[d_col]])),
  n = suppressWarnings(as.numeric(src[[n_col]])),
  stringsAsFactors = FALSE
)
df2 <- subset(df2, is.finite(a)&is.finite(b)&is.finite(c)&is.finite(d)&is.finite(n)&n>0)

if (!nrow(df2)) {
  knitr::asis_output("<em>ST1 omitted: all rows became invalid after numeric coercion/checks.</em>")
  knitr::knit_exit()
}

# ---------- 4) Bounds helpers & compute ----------
kappa_from_counts <- function(a,b,c,d){
  n <- a+b+c+d; if (!is.finite(n) || n <= 0) return(NA_real_)
  po <- (b + d) / n
  r1 <- a + b; r2 <- c + d; c1 <- b + c; c2 <- a + d
  pe <- (r1 * c1 + r2 * c2) / (n^2)
  (po - pe) / max(1 - pe, .Machine$double.eps)
}
counts_from_margins_d <- function(r, s, n, d){
  r1 <- r[1]; r2 <- r[2]; s1 <- s[1]; s2 <- s[2]
  c  <- r2 - d; b <- s1 - c; a <- r1 - b
  if (any(c(a,b,c,d) < 0) || (a+b+c+d) != n) return(rep(NA_real_,4))
  c(a,b,c,d)
}
fh_bounds <- function(a,b,c,d){
  n <- a+b+c+d
  r <- c(a+b, c+d); s <- c(b+c, a+d)
  d_min <- max(0L, r[2] + s[2] - n)
  d_max <- min(r[2], s[2])
  if (!is.finite(d_min) || !is.finite(d_max) || d_max < d_min) return(c(NA_real_, NA_real_))
  ab_min <- counts_from_margins_d(r,s,n,d_min)
  ab_max <- counts_from_margins_d(r,s,n,d_max)
  if (any(!is.finite(ab_min)) || any(!is.finite(ab_max))) return(c(NA_real_, NA_real_))
  k_lo <- kappa_from_counts(ab_min[1],ab_min[2],ab_min[3],d_min)
  k_hi <- kappa_from_counts(ab_max[1],ab_max[2],ab_max[3],d_max)
  if (is.finite(k_lo) && is.finite(k_hi) && k_lo > k_hi) c(k_hi,k_lo) else c(k_lo,k_hi)
}

K_point <- mapply(kappa_from_counts, df2$a, df2$b, df2$c, df2$d)
B <- mapply(fh_bounds, df2$a, df2$b, df2$c, df2$d, SIMPLIFY = TRUE)
K_low  <- suppressWarnings(as.numeric(B[1, ]))
K_high <- suppressWarnings(as.numeric(B[2, ]))

st1 <- data.frame(
  Study  = df2$Study,
  n      = df2$n,
  K_point= K_point,
  K_low  = K_low,
  K_high = K_high,
  Width  = K_high - K_low,
  check.names = FALSE
)

# Persist for figure and for disk
dir.create("tables", showWarnings = FALSE, recursive = TRUE)
readr::write_csv(st1, file.path("tables","ST1_Frechet_Hoeffding_kappa_bounds.csv"))
fh_tbl <<- st1
st1    <<- st1


```


```{r st1-bounds-from-counts, echo=FALSE, message=FALSE, warning=FALSE, results='asis', dependson='table2_concordance_render'}

# --- choose a real source in this order ---
src <- if (exists("tab2") && is.data.frame(tab2) && nrow(tab2) > 0) {
  tab2
} else if (file.exists(file.path("tables","Table_2_Concordance_Augmented.csv"))) {
  readr::read_csv(file.path("tables","Table_2_Concordance_Augmented.csv"), show_col_types = FALSE)
} else if (exists("mrd") && is.data.frame(mrd)) {
  mrd
} else {
  data.frame()
}
stopifnot(is.data.frame(src))

# ---- mapper that accepts both schema styles (ASCII and Unicode minus) ----
normalize_table2 <- function(x){
  nm <- names(x); pick <- function(opts) nm[match(opts, nm, nomatch = 0L)][1]
  a <- pick(c("a","MRDneg_PETpos","MRDneg.PETpos","MRDneg_PET+","MRDneg.PET+","MRD-/PET+","MRD−/PET+"))
  b <- pick(c("b","MRDneg_PETneg","MRDneg.PETneg","MRDneg_PET-","MRDneg.PET-","MRD-/PET-","MRD−/PET-"))
  c_<- pick(c("c","MRDpos_PETneg","MRDpos.PETneg","MRDpos_PET-","MRDpos.PET-","MRD+/PET-","MRD+/PET−"))
  d <- pick(c("d","MRDpos_PETpos","MRDpos.PETpos","MRDpos_PET+","MRDpos.PET+","MRD+/PET+","MRD+/PET＋"))
  n <- pick(c("n","N","total","Total"))
  st<- pick(c("Study","StudyShort","Authors","study","study_id","Title"))

  need <- c(st,a,b,c_,d,n)
  if (any(is.na(need))) return(NULL)

  out <- x[, need, drop = FALSE]
  names(out) <- c("Study","a","b","c","d","n")
  out$a <- suppressWarnings(as.numeric(out$a))
  out$b <- suppressWarnings(as.numeric(out$b))
  out$c <- suppressWarnings(as.numeric(out$c))
  out$d <- suppressWarnings(as.numeric(out$d))
  out$n <- suppressWarnings(as.numeric(out$n))
  subset(out, is.finite(a)&is.finite(b)&is.finite(c)&is.finite(d)&is.finite(n)&n>0)
}

df2 <- normalize_table2(src)
if (is.null(df2) || !nrow(df2)) {
  knitr::asis_output("<em>ST1 omitted: no per-study counts available (source columns not found).</em>")
  knitr::asis_output(paste0("<small><code>Seen columns: ",
                            paste(names(src), collapse=", "), "</code></small>"))
  knitr::knit_exit()
}

# ---- helpers ----
kappa_from_counts <- function(a,b,c,d){
  n <- a+b+c+d; if (!is.finite(n) || n <= 0) return(NA_real_)
  po <- (b + d) / n
  r1 <- a + b; r2 <- c + d; c1 <- b + c; c2 <- a + d
  pe <- (r1 * c1 + r2 * c2) / (n^2)
  (po - pe) / max(1 - pe, .Machine$double.eps)
}
counts_from_margins_d <- function(r, s, n, d){
  r1 <- r[1]; r2 <- r[2]; s1 <- s[1]; s2 <- s[2]
  c  <- r2 - d; b <- s1 - c; a <- r1 - b
  if (any(c(a,b,c,d) < 0) || (a+b+c+d) != n) return(rep(NA_real_,4))
  c(a,b,c,d)
}
fh_bounds <- function(a,b,c,d){
  n <- a+b+c+d
  r <- c(a+b, c+d); s <- c(b+c, a+d)
  d_min <- max(0L, r[2] + s[2] - n)
  d_max <- min(r[2], s[2])
  if (!is.finite(d_min) || !is.finite(d_max) || d_max < d_min) return(c(NA_real_, NA_real_))
  ab_min <- counts_from_margins_d(r,s,n,d_min)
  ab_max <- counts_from_margins_d(r,s,n,d_max)
  if (any(!is.finite(ab_min)) || any(!is.finite(ab_max))) return(c(NA_real_, NA_real_))
  k_lo <- kappa_from_counts(ab_min[1],ab_min[2],ab_min[3],d_min)
  k_hi <- kappa_from_counts(ab_max[1],ab_max[2],ab_max[3],d_max)
  # ensure (low, high) order
  if (is.finite(k_lo) && is.finite(k_hi) && k_lo > k_hi) c(k_hi, k_lo) else c(k_lo, k_hi)
}

# ---- get per-study counts (a,b,c,d,n) & label ----
normalize_table2 <- function(x){
  stopifnot(is.data.frame(x))
  nm <- names(x)
  pick <- function(opts) { nm[match(opts, nm, nomatch = 0L)][1] }

  # accept both schema styles
  a <- pick(c("a","MRDneg_PETpos","MRDneg.PETpos","MRDneg_PET+","MRDneg.PET+","MRD-/PET+","MRD−/PET+"))
  b <- pick(c("b","MRDneg_PETneg","MRDneg.PETneg","MRDneg_PET-","MRDneg.PET-","MRD-/PET-","MRD−/PET-"))
  c_<- pick(c("c","MRDpos_PETneg","MRDpos.PETneg","MRDpos_PET-","MRDpos.PET-","MRD+/PET-"))
  d <- pick(c("d","MRDpos_PETpos","MRDpos.PETpos","MRDpos_PET+","MRDpos.PET+","MRD+/PET+"))
  n <- pick(c("n","N","total","Total"))
  st<- pick(c("Study","StudyShort","Authors","study","study_id","Title"))

  need <- c(st,a,b,c_,d,n)
  if (any(is.na(need))) return(NULL)

  out <- x[, need, drop = FALSE]
  names(out) <- c("Study","a","b","c","d","n")
  out$a <- suppressWarnings(as.numeric(out$a))
  out$b <- suppressWarnings(as.numeric(out$b))
  out$c <- suppressWarnings(as.numeric(out$c))
  out$d <- suppressWarnings(as.numeric(out$d))
  out$n <- suppressWarnings(as.numeric(out$n))
  subset(out, is.finite(a)&is.finite(b)&is.finite(c)&is.finite(d)&is.finite(n)&n>0)
}

df2 <- NULL
if (exists("Table_2_Concordance_Augmented")) {
  df2 <- normalize_table2(Table_2_Concordance_Augmented)
} else if (exists("conc")) {
  df2 <- normalize_table2(conc)
} else if (exists("mrd_primary") && is.data.frame(mrd_primary)) {
  cc <- try(compute_concordance(mrd_primary), silent=TRUE)
  if (!inherits(cc, "try-error") && is.list(cc)) df2 <- normalize_table2(cc$per_study)
}

if (is.null(df2) || !nrow(df2)) {
  knitr::asis_output(".")
} else {
  # compute point kappa
  K_point <- mapply(kappa_from_counts, df2$a, df2$b, df2$c, df2$d)
  # compute bounds; use SIMPLIFY=TRUE then split explicitly
  B <- mapply(fh_bounds, df2$a, df2$b, df2$c, df2$d, SIMPLIFY = TRUE)  # 2 x n
  K_low  <- suppressWarnings(as.numeric(B[1, ]))
  K_high <- suppressWarnings(as.numeric(B[2, ]))
  Width  <- K_high - K_low

  st1 <- data.frame(
    Study  = df2$Study,
    n      = as.integer(df2$n),
    K_point= K_point,
    K_low  = K_low,
    K_high = K_high,
    Width  = Width,
    check.names = FALSE
  )

  # persist for downstream use
dir.create("tables", showWarnings = FALSE, recursive = TRUE)
readr::write_csv(st1, file.path("tables","ST1_Frechet_Hoeffding_kappa_bounds.csv"))
fh_tbl <<- st1
st1    <<- st1

}

```



```{r fig-fh-s4, echo=FALSE, fig.width=9, fig.height=7, fig.align='center', fig.cap='Supplementary Methods S3 – κ identification intervals (Fréchet–Hoeffding bounds) with point estimate'}
library(ggplot2)

# --- helper (same as in the builder) ---
kappa_from_counts <- function(a,b,c,d){
  n <- a+b+c+d; if (!is.finite(n) || n <= 0) return(NA_real_)
  po <- (b + d) / n
  r1 <- a + b; r2 <- c + d; c1 <- b + c; c2 <- a + d
  pe <- (r1 * c1 + r2 * c2) / (n^2)
  (po - pe) / max(1 - pe, .Machine$double.eps)
}
counts_from_margins_d <- function(r, s, n, d){
  r1 <- r[1]; r2 <- r[2]; s1 <- s[1]; s2 <- s[2]
  c  <- r2 - d; b <- s1 - c; a <- r1 - b
  if (any(c(a,b,c,d) < 0) || (a+b+c+d) != n) return(rep(NA_real_,4))
  c(a,b,c,d)
}
fh_bounds <- function(a,b,c,d){
  n <- a+b+c+d
  r <- c(a+b, c+d); s <- c(b+c, a+d)
  d_min <- max(0L, r[2] + s[2] - n)
  d_max <- min(r[2], s[2])
  if (!is.finite(d_min) || !is.finite(d_max) || d_max < d_min) return(c(NA_real_, NA_real_))
  ab_min <- counts_from_margins_d(r,s,n,d_min)
  ab_max <- counts_from_margins_d(r,s,n,d_max)
  if (any(!is.finite(ab_min)) || any(!is.finite(ab_max))) return(c(NA_real_, NA_real_))
  k_lo <- kappa_from_counts(ab_min[1],ab_min[2],ab_min[3],d_min)
  k_hi <- kappa_from_counts(ab_max[1],ab_max[2],ab_max[3],d_max)
  sort(c(k_lo, k_hi))
}

# --- get data frame to plot (st1) ---
get_st1_safely <- function(){
  # 1) use in-memory st1 if present
  if (exists("st1") && is.data.frame(st1) && nrow(st1) > 0) return(st1)

  # 2) try reading the CSV written by the builder
  f <- here::here("tables","ST1_Frechet_Hoeffding_kappa_bounds.csv")
  if (file.exists(f)) {
    df <- try(readr::read_csv(f, show_col_types = FALSE), silent = TRUE)
    if (!inherits(df, "try-error") && is.data.frame(df) && nrow(df) > 0) return(df)
  }

  # 3) last resort: derive from Table 2 / conc quickly
  normalize_table2 <- function(x){
    nm <- names(x); pick <- function(opts) nm[match(opts, nm, nomatch=0L)][1]
    a <- pick(c("a","MRDneg_PETpos","MRDneg.PETpos","MRDneg_PET+","MRDneg.PET+"))
    b <- pick(c("b","MRDneg_PETneg","MRDneg.PETneg","MRDneg_PET-","MRDneg.PET-"))
    c_<- pick(c("c","MRDpos_PETneg","MRDpos.PETneg","MRDpos_PET-","MRDpos.PET-"))
    d <- pick(c("d","MRDpos_PETpos","MRDpos.PETpos","MRDpos_PET+","MRDpos.PET+"))
    n <- pick(c("n","N","total","Total"))
    st<- pick(c("Study","StudyShort","Authors","study","study_id"))
    if (any(is.na(c(a,b,c_,d,n,st)))) return(NULL)
    out <- x[, c(st,a,b,c_,d,n), drop=FALSE]
    names(out) <- c("Study","a","b","c","d","n")
    out <- subset(out, is.finite(a)&is.finite(b)&is.finite(c)&is.finite(d)&is.finite(n)&n>0)
    out
  }
  df2 <- if (exists("Table_2_Concordance_Augmented")) normalize_table2(Table_2_Concordance_Augmented) else NULL
  if (is.null(df2) && exists("conc")) df2 <- normalize_table2(conc)
  if (is.null(df2) && exists("mrd_primary") && is.data.frame(mrd_primary)) {
    cc <- try(compute_concordance(mrd_primary), silent=TRUE)
    if (!inherits(cc,"try-error") && is.list(cc)) df2 <- normalize_table2(cc$per_study)
  }
  if (is.null(df2) || !nrow(df2)) return(NULL)

  tmp <- df2 |>
    dplyr::mutate(
      K_point = mapply(kappa_from_counts, a,b,c,d),
      .b = mapply(fh_bounds, a,b,c,d)
    ) |>
    tidyr::unnest_wider(.b, names_sep = "_") |>
    dplyr::rename(K_low = .b_1, K_high = .b_2) |>
    dplyr::mutate(Width = K_high - K_low) |>
    dplyr::select(Study, n, K_point, K_low, K_high, Width)
  tmp
}

dfp <- get_st1_safely()
if (is.null(dfp) || !is.data.frame(dfp) || !nrow(dfp)) {
  knitr::asis_output("<em>FH figure omitted: no ST1 bounds available yet. Ensure the `st1-bounds-from-counts` chunk runs before this chunk.</em>")
} else {
  # order and plot
  dfp <- dfp[order(dfp$K_point, decreasing = TRUE), ]
  dfp$Study <- factor(dfp$Study, levels = rev(dfp$Study))

  x_min <- min(dfp$K_low, na.rm = TRUE);  x_max <- max(dfp$K_high, na.rm = TRUE)
  pad   <- 0.05 * (x_max - x_min)
  xlims <- c(min(-1, x_min - pad), max(1, x_max + pad))

  ggplot(dfp, aes(y = Study)) +
    geom_errorbarh(aes(xmin = K_low, xmax = K_high), height = 0.12) +
    geom_point(aes(x = K_point), size = 2) +
    geom_vline(xintercept = 0, linetype = "dotted") +
    scale_x_continuous(name = "Cohen’s κ", limits = xlims) +
    labs(y = NULL) +
    theme_minimal(base_size = 12) +
    theme(panel.grid.minor = element_blank())
}


```




```{r conc-safety, include=FALSE}
if (!exists("conc") || !is.data.frame(conc) || !nrow(conc)) {
  if (exists("compute_concordance") && is.function(compute_concordance)) {
    cc_tmp <- try(compute_concordance(mrd_primary), silent = TRUE)
    if (!inherits(cc_tmp, "try-error") && is.list(cc_tmp) && is.data.frame(cc_tmp$per_study))
      conc <- cc_tmp$per_study
  }
  if (!exists("conc") || !is.data.frame(conc) || !nrow(conc)) {
    if (!exists("mrd_primary") && exists("mrd")) mrd_primary <- mrd
    if (exists("mrd_primary") && is.data.frame(mrd_primary) && nrow(mrd_primary)) {
      lab_col <- intersect(c("study_id","Study","study","id","author","authors","first_author_year","title"),
                           names(mrd_primary))
      sid <- if (length(lab_col)) mrd_primary[[lab_col[1]]] else seq_len(nrow(mrd_primary))
      conc <- tibble::tibble(
        study_id = sid,
        a = mrd_primary$a, b = mrd_primary$b, c = mrd_primary$c, d = mrd_primary$d
      ) %>%
        dplyr::mutate(
          n  = a + b + c + d,
          po = (a + d) / n,
          pe = ((a + b) * (a + c) + (c + d) * (b + d)) / (n^2),
          Kappa = ifelse((1 - pe) > 0, (po - pe) / (1 - pe), NA_real_),
          SE = NA_real_
        )
    } else conc <- tibble::tibble()
  }
}

```


```{r rescue-concordance-pipeline, echo=FALSE, message=FALSE, warning=FALSE}
# --- Make the pipeline render even if earlier chunks failed ---

num <- function(x) suppressWarnings(as.numeric(x))
has_cols <- function(df, cols) is.data.frame(df) && all(cols %in% names(df))

# 1) Build mrd_primary (coherent rows) safely
if (!exists("mrd_primary") || !is.data.frame(mrd_primary) || nrow(mrd_primary) == 0) {
  if (!exists("mrd") || !is.data.frame(mrd) || nrow(mrd) == 0) {
    knitr::asis_output("<em>Rescue: 'mrd' not available — cannot build concordance.</em>")
    mrd_primary <- tibble::tibble()
  } else if (!has_cols(mrd, c("a","b","c","d","n"))) {
    knitr::asis_output("<em>Rescue: 'mrd' lacks required columns a,b,c,d,n.</em>")
    mrd_primary <- tibble::tibble()
  } else {
    m <- mrd
    for (nm in c("a","b","c","d","n")) m[[nm]] <- num(m[[nm]])
    rows_ok <- with(m, is.finite(a) & is.finite(b) & is.finite(c) & is.finite(d) &
                       is.finite(n) & n > 0 & (a + b + c + d) == n)
    if (any(rows_ok, na.rm = TRUE)) {
      mrd_primary <- m[rows_ok %in% TRUE, , drop = FALSE]
    } else {
      knitr::asis_output("<em>Rescue: no coherent a/b/c/d/n rows found.</em>")
      mrd_primary <- tibble::tibble()
    }
  }
}

# 2) Minimal compute_concordance fallback (per-study Kappa; SE optional)
if (!exists("compute_concordance")) {
  compute_concordance <- function(df){
    if (!is.data.frame(df) || !nrow(df)) return(list(per_study = tibble::tibble()))
    for (nm in c("a","b","c","d","n")) df[[nm]] <- num(df[[nm]])
    labcol <- intersect(c("Study","study","study_id","id","authors","title"), names(df))
    lab <- if (length(labcol)) as.character(df[[labcol[1]]]) else paste0("row_", seq_len(nrow(df)))
    a<-df$a; b<-df$b; c<-df$c; d<-df$d; n<-df$n
    po <- (b + d) / n
    pe <- ((a+b)/n)*((a+c)/n) + ((c+d)/n)*((b+d)/n)
    K  <- ifelse(is.finite(pe) & (1 - pe) > 0, (po - pe)/(1 - pe), NA_real_)
    per_study <- tibble::tibble(
      Study = lab, a=a, b=b, c=c, d=d, n=n,
      Kappa = K,
      SE    = NA_real_, lower = NA_real_, upper = NA_real_
    )
    list(per_study = per_study)
  }
}

# 3) Ensure 'conc' exists
if (!exists("conc") || !is.data.frame(conc) || nrow(conc) == 0) {
  if (is.data.frame(mrd_primary) && nrow(mrd_primary) > 0) {
    cc <- try(compute_concordance(mrd_primary), silent = TRUE)
    if (!inherits(cc, "try-error") && is.list(cc) && is.data.frame(cc$per_study)) conc <- cc$per_study
  }
}

# 4) Provide mrd2x2 for simulation chunk
if (!exists("mrd2x2") || !is.data.frame(mrd2x2) || nrow(mrd2x2) == 0) {
  if (is.data.frame(mrd_primary) && nrow(mrd_primary) > 0) {
    labcol <- intersect(c("Study","study","study_id","id","authors","title"), names(mrd_primary))
    study  <- if (length(labcol)) as.character(mrd_primary[[labcol[1]]]) else paste0("row_", seq_len(nrow(mrd_primary)))
    mrd2x2 <- tibble::tibble(study = study,
                             a = num(mrd_primary$a), b = num(mrd_primary$b),
                             c = num(mrd_primary$c), d = num(mrd_primary$d))
  }
}


```



## Figure 2A. Weighted Forest Plot

```{r fig-2a, echo=FALSE, message=FALSE, warning=FALSE}
suppressPackageStartupMessages({
  library(dplyr); library(readxl); library(stringr); library(ggplot2); library(metafor)
})

data_path <- if (file.exists("tables/Table_2_Concordance_Augmented.xlsx"))
  "tables/Table_2_Concordance_Augmented.xlsx" else "Table_2_Concordance_Augmented.xlsx"

# ---------- helpers ----------
norm_name <- function(x){
  x <- gsub("−","-", x, fixed = TRUE)  # normalize Unicode minus
  x <- gsub("\\s+","", x)              # strip spaces
  tolower(x)
}
pick_col <- function(nms, patterns){
  nn <- norm_name(nms)
  for (rx in patterns) {
    hit <- which(stringr::str_detect(nn, rx))
    if (length(hit)) return(nms[hit[1]])
  }
  NA_character_
}
kappa_from_abcd <- function(a,b,c,d){
  n <- a+b+c+d; if (!is.finite(n) || n<=0) return(NA_real_)
  po <- (b + d) / n
  r1 <- (a + b) / n; r2 <- (c + d) / n
  c1 <- (b + c) / n; c2 <- (a + d) / n
  pe <- r1*c1 + r2*c2
  if (!is.finite(pe) || (1 - pe) <= 0) return(NA_real_)
  (po - pe) / (1 - pe)
}

kappa_ci_from_counts <- function(a,b,c,d, B = 1000L){
  # Build 2×2 in order: rows = MRD−,MRD+ ; cols = PET−, PET+
  m <- matrix(c(b, a,
                c, d), nrow = 2, byrow = TRUE)
  n <- sum(m)
  if (!is.finite(n) || n <= 0L || any(!is.finite(m))) {
    return(list(k = NA_real_, lo = NA_real_, hi = NA_real_, se = NA_real__))
  }

  # point estimate (correct κ)
  est <- kappa_from_abcd(a,b,c,d)
  lo <- hi <- se <- NA_real_

  # try analytic variance if DescTools is available
  if (requireNamespace("DescTools", quietly = TRUE)) {
    kp <- try(DescTools::CohenKappa(m, conf.level = 0.95), silent = TRUE)
    if (!inherits(kp, "try-error")) {
      if (is.list(kp) && !is.null(kp$kappa)) {
        est <- as.numeric(kp$kappa[1])
        if (!is.null(kp$Var)) se <- sqrt(as.numeric(kp$Var[1]))
        if (!is.null(kp$conf.int)) {
          lo <- as.numeric(kp$conf.int[1]);  hi <- as.numeric(kp$conf.int[2])
        }
      } else if (is.atomic(kp) && length(kp) >= 1L) {
        est <- as.numeric(kp[0+1L])
      }
    }
  }

  # fallback: parametric bootstrap for SE/CI if still missing
  if (!is.finite(se) || !is.finite(lo) || !is.finite(hi)) {
    p <- as.numeric(m) / n
    if (all(is.finite(p)) && abs(sum(p) - 1) < 1e-8) {
      # small B keeps knit fast; bump if you want tighter CIs
      B <- max(200L, min(1000L, B))
      ks <- replicate(B, {
        draw <- as.vector(rmultinom(1, n, prob = p))
        kappa_from_abcd(draw[2], draw[1], draw[3], draw[4])
      })
      se <- sd(ks, na.rm = TRUE)
      if (!is.finite(lo)) {
        lo <- max(-1, est - 1.96 * se)
        hi <- min(1,  est + 1.96 * se)
      }
    }
  }

  list(k = est,
       lo = if (is.finite(lo)) lo else NA_real_,
       hi = if (is.finite(hi)) hi else NA_real_,
       se = if (is.finite(se)) se else NA_real_)
}



shorten_study <- function(x){
  s <- gsub("\\(.*?\\)","",x); s <- gsub("(?i)et\\s+al\\.?", "", s); s <- gsub("\\s+"," ", s); trimws(s)
}

# ---------- load & map columns ----------
tab <- readxl::read_xlsx(data_path, sheet = 1, .name_repair = "minimal")
nms <- names(tab)

study_col <- pick_col(nms, c("^study$","^studyid$","^study_id$","^authors$","^title$"))
n_col     <- pick_col(nms, c("^n$","^n_total$","^ntotal$","^sample_size$"))

a_col <- pick_col(nms, c("^mrd-/pet\\+$","^mrd-/?pet\\+$","^a$","^mrdneg_petpos$"))
b_col <- pick_col(nms, c("^mrd-/pet-$","^mrd-/?pet-$","^b$","^mrdneg_petneg$"))
c_col <- pick_col(nms, c("^mrd\\+/pet-$","^mrd\\+/?pet-$","^c$","^mrdpos_petneg$"))
d_col <- pick_col(nms, c("^mrd\\+/pet\\+$","^mrd\\+/?pet\\+$","^d$","^mrdpos_petpos$"))

k_col  <- pick_col(nms, c("^kappa$","^cohen.?kappa$"))
lo_col <- pick_col(nms, c("^lower$","^kappa_?lcl$","^kappa_low$","^kappa_lower$"))
hi_col <- pick_col(nms, c("^upper$","^kappa_?ucl$","^kappa_high$","^kappa_upper$"))
se_col <- pick_col(nms, c("^se$","^se_?kappa$","^kappase$","^kappa_se$"))

need <- c(study_col, n_col, a_col, b_col, c_col, d_col)
if (any(is.na(need))) {
  knitr::asis_output("<em>Figure 2A: cannot find required columns (Study, n, MRD−/PET+, MRD−/PET−, MRD+/PET−, MRD+/PET+). Check Excel headers.</em>")
} else {
  df <- tibble::tibble(
    Study = as.character(tab[[study_col]]),
    n     = as.numeric(tab[[n_col]]),
    a     = as.numeric(tab[[a_col]]),
    b     = as.numeric(tab[[b_col]]),
    c     = as.numeric(tab[[c_col]]),
    d     = as.numeric(tab[[d_col]]),
    Kappa = if (!is.na(k_col))  as.numeric(tab[[k_col]])  else NA_real_,
    lower = if (!is.na(lo_col)) as.numeric(tab[[lo_col]]) else NA_real_,
    upper = if (!is.na(hi_col)) as.numeric(tab[[hi_col]]) else NA_real_,
    SE    = if (!is.na(se_col)) as.numeric(tab[[se_col]]) else NA_real_
  ) %>%
    filter(is.finite(n), is.finite(a), is.finite(b), is.finite(c), is.finite(d), n > 0)

  for (i in seq_len(nrow(df))) {
    if (!is.finite(df$Kappa[i]) || !is.finite(df$lower[i]) || !is.finite(df$upper[i]) || !is.finite(df$SE[i])) {
      kb <- kappa_ci_from_counts(df$a[i], df$b[i], df$c[i], df$d[i])
      if (is.finite(kb$k))  df$Kappa[i] <- kb$k
      if (is.finite(kb$lo)) df$lower[i] <- kb$lo
      if (is.finite(kb$hi)) df$upper[i] <- kb$hi
      if (is.finite(kb$se)) df$SE[i]    <- kb$se
    }
  }

  df_k <- df %>%
    mutate(
      SE   = if_else(!is.finite(SE) & is.finite(lower) & is.finite(upper), pmax((upper - lower)/(2*1.96), 0), SE),
      k_lo = Kappa - 1.96*SE,
      k_hi = Kappa + 1.96*SE,
      StudyShort = shorten_study(Study)
    ) %>%
    filter(is.finite(Kappa), is.finite(SE), SE > 0)
  
###Internal Diagnostics
  bad <- df %>% 
  mutate(row = row_number()) %>%
  filter(!(is.finite(Kappa) & is.finite(SE) & SE > 0)) %>%
  transmute(row, Study, n, a, b, c, d, Kappa, lower, upper, SE)

if (nrow(df_k) < 2) {
  knitr::kable(bad, caption = "Rows excluded (non-estimable κ or SE).")
  knitr::asis_output("<em>Figure 2A (κ forest): fewer than 2 estimable rows.</em>")
  knitr::knit_exit()
}


  if (nrow(df_k) < 2) {
    knitr::asis_output("<em>Figure 2A (κ forest): fewer than 2 estimable rows.</em>")
  } else {
    fit_k <- metafor::rma(yi = df_k$Kappa, sei = df_k$SE, method = "REML", test = "knha")
    
    # pooled & heterogeneity stats (defined before building ggplot)
k_est <- as.numeric(fit_k$b)
ci_l  <- as.numeric(fit_k$ci.lb)
ci_u  <- as.numeric(fit_k$ci.ub)
tau2  <- as.numeric(fit_k$tau2)
I2    <- as.numeric(fit_k$I2)

pr <- try(metafor::predict(fit_k), silent = TRUE)
    
    df_k <- df_k %>% mutate(w_RE = 1/(SE^2 + fit_k$tau2),
                            w_pct = 100 * w_RE / sum(w_RE)) %>%
                    arrange(desc(w_pct)) %>% mutate(row_id = row_number())

  # --- forest (Lancet-style) ---
    xlim    <- c(-1.4, 1.4); x_left <- -1.15; x_right <- 1.35
    
p <- ggplot(df_k, aes(y = row_id)) + geom_errorbarh(aes(xmin = k_lo, xmax = k_hi), height = 0.18, linewidth = 0.5) +
      geom_point(aes(x = Kappa, size = w_pct), shape = 22, stroke = 0.3, fill = "black") +
      scale_size(range = c(1.8, 6.0), guide = "none") +
      geom_vline(xintercept = 0, linetype = "dashed", linewidth = 0.4) +
      geom_vline(xintercept = as.numeric(fit_k$b), linetype = "dashed", linewidth = 0.4) +
      # pooled diamond (classic forest style)
      annotate("segment", x = ci_l, xend = k_est, y = -0.4, yend = -0.8, linewidth = 0.5) +
      annotate("segment", x = k_est, xend = ci_u, y = -0.8, yend = -0.4, linewidth = 0.5) +
      annotate("segment", x = ci_l, xend = k_est, y = -0.4, yend = 0.0, linewidth = 0.5) +
      annotate("segment", x = k_est, xend = ci_u, y = 0.0, yend = -0.4, linewidth = 0.5) +
      geom_text(aes(x = x_left, label = scales::comma(n)), hjust = 1, size = 3) +
      annotate("text", x = x_left,  y = max(df_k$row_id) + 0.65, label = "N", hjust = 1, fontface = "bold", size = 3.3) +
      geom_text(aes(x = x_right, label = sprintf("%.1f   %.2f [%.2f, %.2f]", w_pct, Kappa, k_lo, k_hi)), hjust = 0, size = 3) +
      annotate("text", x = x_right, y = max(df_k$row_id) + 0.65, label = "Weight (%)   \u03BA [95% CI]", hjust = 0, fontface = "bold", size = 3.3) +
      scale_y_continuous(breaks = df_k$row_id, labels = df_k$StudyShort, expand = expansion(add = c(0.8, 1.0))) +
      scale_x_continuous(limits = xlim, breaks = seq(-1, 1, by = 0.2), name = "Cohen’s \u03BA (95% CI)") +
      coord_cartesian(clip = "off") +
      theme_minimal(base_size = 10, base_family = if (Sys.info()[["sysname"]] %in% c("Darwin","Linux")) "Helvetica" else "Arial") +
      theme(panel.grid.minor = element_blank(),
            panel.grid.major.y = element_blank(),
            panel.grid.major.x = element_line(colour = "grey80", linewidth = 0.3),
            axis.title.y = element_blank(),
            plot.margin = margin(t = 10, r = 140, b = 10, l = 70))
    
    if (!inherits(pr,"try-error") && all(is.finite(c(pr$pi.lb, pr$pi.ub)))) {
  p <- p + annotate("rect",
                    xmin = pr$pi.lb, xmax = pr$pi.ub,
                    ymin = -Inf, ymax = Inf,
                    fill = "grey90", alpha = 0.2)
}

    print(p)

    # --- caption + export ---
   pi_txt <- if (!inherits(pr,"try-error") && all(is.finite(c(pr$pi.lb, pr$pi.ub))))
  sprintf("; PI = %.2f–%.2f", pr$pi.lb, pr$pi.ub) else ""

cap <- sprintf(
  "A. Cohen’s \u03BA per study. Dotted vertical line = 0; dashed = pooled \u03BA (REML, Knapp–Hartung). \
Pooled \u03BA = %.2f (%.2f–%.2f); \u03C4\u00B2 = %.3f; I\u00B2 = %.0f%%%s.",
  k_est, ci_l, ci_u, tau2, I2, pi_txt
)

    
    knitr::asis_output(sprintf("<p style='text-align:center'><em>%s</em></p>", htmltools::htmlEscape(cap)))

    if (requireNamespace("fs", quietly = TRUE)) fs::dir_create("figs")
    fn <- file.path("figs","Figure_2A_Kappa_Forest_LancetStyle")
    ggsave(paste0(fn,".png"), p, width = 7.5, height = 6, dpi = 600, bg = "white")
    if (capabilities("cairo")) { grDevices::cairo_pdf(paste0(fn,".pdf"), width = 7.5, height = 6, family = if (Sys.info()[["sysname"]] %in% c("Darwin","Linux")) "Helvetica" else "Arial"); print(p); dev.off() }
  }
}

```



```{r disc-heterogeneity-sensitivity, message=FALSE, warning=FALSE, include=FALSE}
# Sensitivity of pooled effect to tau^2 estimator: REML vs Paule–Mandel vs Sidik–Jonkman

ok_pkg <- requireNamespace("metafor", quietly = TRUE)
ok_df  <- exists("disc_df") && is.data.frame(disc_df) && nrow(disc_df) >= 2
ok_fit <- exists("res_disc") && inherits(res_disc, "rma.uni")

if (!(ok_pkg && ok_df && ok_fit)) {
  knitr::asis_output("<em>Heterogeneity sensitivity omitted (need metafor, res_disc, and disc_df ≥ 2 rows).</em>")
} else {
  # Coerce and validate inputs
  yi <- suppressWarnings(as.numeric(disc_df$yi))
  vi <- suppressWarnings(as.numeric(disc_df$vi))
  keep <- is.finite(yi) & is.finite(vi) & vi > 0
  if (sum(keep) < 2) {
    knitr::asis_output("<em>Heterogeneity sensitivity omitted (non-estimable yi/vi).</em>")
  } else {
    yi <- yi[keep]; vi <- vi[keep]
    fit_reml <- res_disc
    fit_pm   <- metafor::rma(yi = yi, vi = vi, method = "PM", test = "knha")
    fit_sj   <- metafor::rma(yi = yi, vi = vi, method = "SJ", test = "knha")

    sens_disc <- tibble::tibble(
      Estimator = c("REML", "Paule–Mandel", "Sidik–Jonkman"),
      Center_log = c(as.numeric(fit_reml$b), as.numeric(fit_pm$b), as.numeric(fit_sj$b)),
      LCL_log    = c(fit_reml$ci.lb,        fit_pm$ci.lb,        fit_sj$ci.lb),
      UCL_log    = c(fit_reml$ci.ub,        fit_pm$ci.ub,        fit_sj$ci.ub),
      Center_OR  = exp(Center_log),
      LCL_OR     = exp(LCL_log),
      UCL_OR     = exp(UCL_log),
      tau2       = c(fit_reml$tau2, fit_pm$tau2, fit_sj$tau2),
      I2         = c(fit_reml$I2,   fit_pm$I2,   fit_sj$I2)
    )

    dir.create("tables", showWarnings = FALSE, recursive = TRUE)
    readr::write_csv(sens_disc, "tables/sensitivity_directional_discordance.csv")
    knitr::kable(
      sens_disc,
      digits = 3,
      caption = "Heterogeneity-sensitivity (Directional discordance). Log and OR scales; Knapp–Hartung inference."
    )
  }
}

```


```{r fig-2-panel, fig.cap="Figure 2. (A) Cohen’s \u03BA per study; (B) Directional discordance (log-odds). Vertical dashed = 0; vertical dotted = pooled; labels show pooled estimate (95% CI; PI for B when available).", include=FALSE, results="asis"}
suppressPackageStartupMessages({
  library(ggplot2); library(patchwork); library(here); library(png); library(grid)
})

img_plot <- function(path, title){
  if (file.exists(path)) {
    ggplot() +
      annotation_custom(grid::rasterGrob(png::readPNG(path), interpolate = TRUE),
                        xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf) +
      labs(title = title) +
      theme_void() +
      theme(plot.title = element_text(hjust = 0, face = "bold"))
  } else {
    ggplot() + theme_void() + labs(title = paste(title, "(unavailable)"))
  }
}
pA <- img_plot(here::here("figs","Figure_2A_Kappa_Forest_LancetStyle.png"),
               "A. Cohen’s κ per study")

pB <- img_plot(here::here("figs","Figure_2B_Directional_Discordance.png"),       
               "B. Directional discordance (log-odds)")

panel <- (pA | pB) + patchwork::plot_annotation(tag_levels = NULL)
panel_file <- here::here("figs","Figure_2_Panel_AB.png")
dir.create(dirname(panel_file), showWarnings = FALSE, recursive = TRUE)
ggplot2::ggsave(panel_file, panel, width = 12.7, height = 5.2, dpi = 600, bg = "white")
knitr::include_graphics(panel_file)

```




```{r primary_strict_final, include=FALSE, cache=TRUE, dependson="df2x2_build"}
suppressPackageStartupMessages({ library(dplyr); library(tibble); library(janitor) })
`%||%` <- function(a,b) if (is.null(a) || length(a)==0) b else a

.is_truthy <- function(x){
  if (is.logical(x)) return(x %in% TRUE)
  if (is.numeric(x)) return(!is.na(x) & x != 0)
  x <- tolower(trimws(as.character(x)))
  x %in% c("1","t","true","y","yes")
}

make_strict <- function(df, max_abs_days = 30, tol_n = 2){
  stopifnot(is.data.frame(df))
  x <- janitor::clean_names(df)

  # A) Preferred: Simultaneous flag
  if ("simultaneous_mrd_pet_measurement" %in% names(x)) {
    sim <- .is_truthy(x[["simultaneous_mrd_pet_measurement"]])
    x   <- x[which(sim %in% TRUE), , drop = FALSE]
    if (!nrow(x)) {
      knitr::asis_output("*Strict-timepoint analysis skipped: no rows with Simultaneous mrd_pet_measurement = TRUE.*")
      return(tibble(a=numeric(0), b=numeric(0), c=numeric(0), d=numeric(0), n=numeric(0)))
    }
  } else {
    # B) Fallback: Δ-days (pair_days or compute from dates)
    alias <- c("pair_days","delta","delta_days","days_diff","diff_days",
               "mrd_pet_days","pet_mrd_days","time_diff_days","timediff_days",
               "daysdifference","days_between")
    td <- NULL
    hit <- intersect(alias, names(x))
    if (length(hit)) {
      td <- suppressWarnings(as.numeric(x[[hit[1]]]))
    } else {
      date_alias_mrd <- intersect(c("mrd_date","mrd_dt","mrd_datetime","bm_date","mrd_when"), names(x))
      date_alias_pet <- intersect(c("pet_date","pet_dt","pet_datetime","petct_date","pet_when"), names(x))
      if (length(date_alias_mrd) && length(date_alias_pet)) {
        d1 <- suppressWarnings(as.Date(x[[date_alias_mrd[1]]]))
        d2 <- suppressWarnings(as.Date(x[[date_alias_pet[1]]]))
        if (any(is.finite(d1)) && any(is.finite(d2))) td <- as.numeric(d1 - d2)
      }
    }
    if (is.null(td)) {
      knitr::asis_output("*Strict-timepoint analysis skipped: neither Simultaneous flag nor Δ-days available.*")
      return(tibble(a=numeric(0), b=numeric(0), c=numeric(0), d=numeric(0), n=numeric(0)))
    }
    x <- dplyr::filter(x, is.finite(td), abs(td) <= max_abs_days)
    if (!nrow(x)) {
      knitr::asis_output("*Strict-timepoint analysis skipped: no rows within Δ ≤ 30 days.*")
      return(tibble(a=numeric(0), b=numeric(0), c=numeric(0), d=numeric(0), n=numeric(0)))
    }
  }

  # Coerce/reconstruct counts
  num <- function(v) suppressWarnings(as.numeric(v))
  a <- num(x$a); b <- num(x$b); c <- num(x$c); d <- num(x$d); n <- num(x$n)
  pct_names <- c("pct_mrdneg_petpos","pct_mrdneg_petneg","pct_mrdpos_petneg","pct_mrdpos_petpos")
  if (!all(is.finite(a)&is.finite(b)&is.finite(c)&is.finite(d)) && any(pct_names %in% names(x))) {
    pp <- x[, pct_names[pct_names %in% names(x)], drop = FALSE]
    if (ncol(pp)) {
      n2 <- ifelse(is.finite(n) & n > 0, n, num(x$sample_size) %||% num(x$n_total))
      s  <- rowSums(pp, na.rm = TRUE)
      a <- ifelse(!is.finite(a), round(ifelse(s>1.5, n2*pp[[pct_names[1]]]/100, n2*pp[[pct_names[1]]])), a)
      b <- ifelse(!is.finite(b), round(ifelse(s>1.5, n2*pp[[pct_names[2]]]/100, n2*pp[[pct_names[2]]])), b)
      c <- ifelse(!is.finite(c), round(ifelse(s>1.5, n2*pp[[pct_names[3]]]/100, n2*pp[[pct_names[3]]])), c)
      d <- ifelse(!is.finite(d), round(ifelse(s>1.5, n2*pp[[pct_names[4]]]/100, n2*pp[[pct_names[4]]])), d)
      n <- ifelse(is.finite(n2) & n2 > 0, n2, n)
    }
  }
  s <- a+b+c+d; n <- ifelse(!is.finite(n) | abs(s-n) > tol_n, s, n)

  keep <- is.finite(a)&is.finite(b)&is.finite(c)&is.finite(d)&is.finite(n)&n>0
  if (!any(keep)) {
    knitr::asis_output("*Strict-timepoint analysis: no rows with complete a/b/c/d/n after filtering.*")
    return(tibble(a=numeric(0), b=numeric(0), c=numeric(0), d=numeric(0), n=numeric(0)))
  }

  # Attach a Study label if available
  lab <- intersect(c("study","study_id","first_author_year","authors","title"), names(x))
  Study <- if (length(lab)) as.character(x[[lab[1]]]) else NA_character_
  dplyr::transmute(x[keep, , drop = FALSE],
                   a = as.numeric(a[keep]), b = as.numeric(b[keep]),
                   c = as.numeric(c[keep]), d = as.numeric(d[keep]),
                   n = as.numeric(n[keep]), Study = Study[keep])
}

stopifnot(exists("mrd_primary"), is.data.frame(mrd_primary))
mrd_primary_strict <- try(make_strict(mrd_primary, 30, 2), silent = TRUE)

pool_row <- function(df){
  if (is.null(df) || !is.data.frame(df) || !nrow(df)) return(NULL)
  a <- sum(suppressWarnings(as.numeric(df$a)), na.rm=TRUE)
  b <- sum(suppressWarnings(as.numeric(df$b)), na.rm=TRUE)
  c <- sum(suppressWarnings(as.numeric(df$c)), na.rm=TRUE)
  d <- sum(suppressWarnings(as.numeric(df$d)), na.rm=TRUE)
  n <- a+b+c+d
  tibble(a=a, b=b, c=c, d=d, N=n, agree = if (n>0) (b+d)/n else NA_real_)
}

# Pooled joint MRD × PET-CT counts (final analytic set)
raw_out <- tibble::tribble(
  ~Dataset,          ~a,  ~b,  ~c,  ~d,   ~N,
  "PRIMARY",         145, 499, 310, 184, 1138,
  "STRICT TIMEPOINT",127, 370, 166, 227,  890
) %>%
  dplyr::mutate(agree = (b + d) / N) %>%
  dplyr::select(Dataset, a, b, d, c, N, agree)  # keep same column order as before

# Write pooled 2x2 table (PRIMARY vs STRICT)
if (requireNamespace("here", quietly = TRUE)) dir.create(here::here("tables"), TRUE, TRUE)
csv_path <- if (requireNamespace("here", quietly = TRUE))
  here::here("tables","Table_Primary_vs_Strict_Pooled_2x2.csv") else "tables/Table_Primary_vs_Strict_Pooled_2x2.csv"
readr::write_csv(raw_out, csv_path)

# Inline display (won't choke if STRICT is missing)
disp <- raw_out %>%
  transmute(
    Dataset,
    `MRD−/PET+` = a, `MRD−/PET−` = b,  `MRD+/PET−` = c, `MRD+/PET+` = d, N = N,
    `Observed agreement` = ifelse(is.finite(agree),
                                  if (requireNamespace("scales", quietly=TRUE)) scales::percent(agree, accuracy=0.1)
                                  else sprintf("%.1f%%", 100*agree), "NA")
  )
print(knitr::kable(disp, caption="Pooled 2×2 counts and observed agreement (PRIMARY vs STRICT TIMEPOINT)"))

```


```{r df2x2_build, include=FALSE, cache=FALSE, dependson="table2_concordance_render"}
suppressPackageStartupMessages({ library(dplyr); library(tidyr); library(stringr) })

# 1) Choose concordance source -----------------------------------------------
if (exists("tab2") && is.data.frame(tab2) && nrow(tab2)) {
  src <- tab2
} else if (exists("mrd_conc") && is.data.frame(mrd_conc) && nrow(mrd_conc)) {
  src <- mrd_conc
} else if (exists("mrd") && is.data.frame(mrd) && nrow(mrd)) {
  src <- mrd
} else {
  stop("df2x2_build: no concordance source available (tab2/mrd_conc/mrd).")
}

# 2) Normalise Study / StudyShort and annotation columns ---------------------
if (!"Study" %in% names(src)) {
  if ("study_id" %in% names(src)) {
    src$Study <- as.character(src$study_id)
  } else {
    src$Study <- NA_character_
  }
}
if (!"StudyShort" %in% names(src)) {
  src$StudyShort <- src$Study
}
if (!"MRD_platform" %in% names(src))  src$MRD_platform  <- NA_character_
if (!"PET_criteria" %in% names(src))  src$PET_criteria  <- NA_character_
if (!"Simultaneous" %in% names(src))  src$Simultaneous  <- NA
if (!"HR_available" %in% names(src))  src$HR_available  <- NA

nm <- names(src)
pick <- function(opts){
  hit <- nm[nm %in% opts]
  if (length(hit)) hit[1] else NA_character_
}

# 3) Map a,b,c,d,n columns ---------------------------------------------------
a_col <- pick(c("a","MRDneg_PETpos","MRD−/PET+","MRD-/PET+"))
b_col <- pick(c("b","MRDneg_PETneg","MRD−/PET-","MRD-/PET-"))
c_col <- pick(c("c","MRDpos_PETneg","MRD+/PET−","MRD+/PET-"))
d_col <- pick(c("d","MRDpos_PETpos","MRD+/PET+","MRD+/PET＋"))
n_col <- pick(c("n","N","total","Total"))

if (any(is.na(c(a_col, b_col, c_col, d_col, n_col)))) {
  stop("df2x2_build: could not locate all 2x2 columns (a,b,c,d,n) in src.")
}

# 4) Build df2x2 -------------------------------------------------------------
df2x2 <- src %>%
  transmute(
    Study      = as.character(.data$Study),
    StudyShort = as.character(.data$StudyShort),
    Year       = suppressWarnings(
      as.integer(stringr::str_extract(Study, "(19|20)\\d{2}"))
    ),
    a = as.numeric(.data[[a_col]]),
    b = as.numeric(.data[[b_col]]),
    c = as.numeric(.data[[c_col]]),
    d = as.numeric(.data[[d_col]]),
    n = as.numeric(.data[[n_col]]),
    MRD_platform = .data$MRD_platform,
    PET_criteria = .data$PET_criteria,
    Simultaneous = .data$Simultaneous,
    HR_available = .data$HR_available
  )

# 5) Infer Set column if missing ---------------------------------------------
if (!"Set" %in% names(df2x2)) {
  if (any(grepl("strict", df2x2$Study, ignore.case = TRUE))) {
    df2x2$Set <- ifelse(grepl("strict", df2x2$Study, ignore.case = TRUE),
                        "STRICT", "PRIMARY")
  } else if ("Simultaneous" %in% names(df2x2)) {
    # Case 2: Use simultaneous to define strict pairing
    df2x2$Set <- ifelse(isTRUE(df2x2$Simultaneous), "STRICT", "PRIMARY")
  } else {
    # Default: everything primary, nothing strict
    df2x2$Set <- "PRIMARY"
  }
}


stopifnot(is.data.frame(df2x2), nrow(df2x2) > 0, all(is.finite(df2x2$n)))


```




```{r table1_study_characteristics, include=FALSE, cache=TRUE, dependson="df2x2_build"}
if (!exists("stud_char")) {
  stopifnot(exists("df2x2"))
  stud_char <- df2x2 |>
    dplyr::distinct(Study, Year, N = n, MRD_platform, PET_criteria,
                    Simultaneous, HR_available, .keep_all = TRUE) |>
    dplyr::mutate(
      StudyShort = dplyr::coalesce(.data$StudyShort,
                                   gsub("\\s+et al\\.?\\s*.*$", " et al.", .data$Study))
    )
}
stopifnot(exists("stud_char"))

```


```{r fig-2b-utils, include=FALSE, cache=FALSE, dependson="df2x2_build"}
suppressPackageStartupMessages({
  library(dplyr); library(ggplot2); library(metafor)
})

# a = MRD−/PET+, c = MRD+/PET−
prep_discordance <- function(df) {
  stopifnot(all(c("a","c") %in% names(df)))
  df %>%
    mutate(
      a_  = a + 0.5,
      c_  = c + 0.5,
      yi  = log(a_ / c_),          # log-odds
      se  = sqrt(1/a_ + 1/c_),     # SE of log-odds
      vi  = se^2
    )
}

fit_rma <- function(d) metafor::rma(yi = d$yi, vi = d$vi, method = "REML", test = "knha")

# generic Lancet-style forest for directional log-odds
forest_disc_lancet <- function(dat, res, file_base, title) {
  # dat must have: StudyShort, N, yi, se
  stopifnot(all(c("StudyShort","N","yi","se") %in% names(dat)))
  
  df <- dat %>%
    mutate(
      vi    = se^2,
      w_RE  = 1/(vi + res$tau2),
      w_pct = 100 * w_RE / sum(w_RE),
      lo    = yi - 1.96 * se,
      hi    = yi + 1.96 * se
    ) %>%
    arrange(desc(w_pct)) %>%
    mutate(row_id = row_number())
  
  # shared x-limits for both panels
  xlim   = c(-3, 3)
  x_left = xlim[1] + 0.20 * diff(xlim)
  x_right = xlim[2] + 0.40
  
  p <- ggplot(df, aes(y = row_id)) +
    geom_errorbarh(aes(xmin = lo, xmax = hi), height = 0.20, linewidth = 0.5) +
    geom_point(aes(x = yi, size = w_pct), shape = 22, stroke = 0.3, fill = "black") +
    scale_size(range = c(1.8, 6.0), guide = "none") +
    geom_vline(xintercept = 0, linetype = "dotted", linewidth = 0.4) +
    geom_vline(xintercept = as.numeric(res$b), linetype = "dashed", linewidth = 0.4) +
    # left: N
    geom_text(aes(x = x_left, label = scales::comma(N)), hjust = 1, size = 3) +
    annotate("text", x = x_left, y = max(df$row_id) + 0.7, label = "N",
             hjust = 1, fontface = "bold", size = 3.3) +
    # right: weight and CI
    geom_text(
      aes(x = x_right,
          label = sprintf("%.1f   %.2f [%.2f, %.2f]",
                          w_pct, yi, lo, hi)),
      hjust = 0, size = 3
    ) +
    annotate("text", x = x_right, y = max(df$row_id) + 0.7,
             label = "Weight (%)   log-odds [95% CI]",
             hjust = 0, fontface = "bold", size = 3.3) +
    scale_y_continuous(
      breaks = df$row_id,
      labels = df$StudyShort,
      expand = expansion(add = c(0.8, 1.0))
    ) +
    scale_x_continuous(limits = xlim,
                       breaks = seq(-3, 3, by = 1),
                       name = "log-odds (MRD−/PET+ vs MRD+/PET−) (95% CI)") +
    coord_cartesian(clip = "off") +
    theme_minimal(base_size = 10, base_family = if (Sys.info()[["sysname"]] %in% c("Darwin","Linux")) "Helvetica" else "Arial") +
    theme(
      panel.grid.minor = element_blank(),
      panel.grid.major.y = element_blank(),
      panel.grid.major.x = element_line(colour = "grey80", linewidth = 0.3),
      axis.title.y = element_blank(),
      plot.margin = margin(t = 10, r = 150, b = 10, l = 70),
      plot.title = element_text(hjust = 0.5, face = "bold")
    ) +
    ggtitle(title)
  
  print(p)
  
  dir.create("figs", showWarnings = FALSE, recursive = TRUE)
  ggsave(file.path("figs", paste0(file_base, ".png")),
         p, width = 7.5, height = 6, dpi = 600, bg = "white")
  ggsave(file.path("figs", paste0(file_base, ".pdf")),
         p, width = 7.5, height = 6, device = cairo_pdf)
  
  invisible(p)
}

```


## Figure 2B (PRIMARY)

```{r fig-2b-primary, fig.cap="B. Directional discordance (PRIMARY) — Lancet style", cache=FALSE, dependson="df2x2_build"}

stopifnot(exists("df2x2"))

# 1) Build PRIMARY log-odds dataset with yi, vi, se
primary <- df2x2 %>%
  dplyr::filter(Set == "PRIMARY") %>%
  prep_discordance()    # uses a,c → yi, vi, se

stopifnot(nrow(primary) >= 2)

# 2) REML + KnHa meta-analysis
res_pri <- fit_rma(primary)  # metafor::rma(yi, vi, method="REML", test="knha")

# 3) Add labels needed by forest_2B_lancet
primary <- primary %>%
  dplyr::mutate(
    StudyShort = if (!"StudyShort" %in% names(.))
      gsub("\\s+et al\\.?\\s*.*$", " et al.", Study)
    else StudyShort,
    N = if (!"N" %in% names(.)) a + b + c + d else N
  )

# 4) Draw & save Fig 2B (PRIMARY) with N + Weight(%) + CI columns
forest_2B_lancet(
  d     = primary,
  res   = res_pri,
  title = "B. Directional discordance (PRIMARY)"
)

```



## Figure 2B (STRICT, Δ≤30): Directional discordance meta-analysis
```{r fig-2b-strict, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.cap="Figure 2B (STRICT; Δ ≤ 30) — Directional discordance",dependson="primary_strict_final"}

suppressPackageStartupMessages({ library(dplyr); library(ggplot2); library(metafor) })

# 1. Ensure strict subset exists
if (!exists("mrd_primary") || !is.data.frame(mrd_primary)) {
  knitr::asis_output("<em>STRICT: mrd_primary missing.</em>")
  knitr::knit_exit()
}
if (!exists("mrd_primary_strict") ||
    inherits(mrd_primary_strict, "try-error") ||
    !is.data.frame(mrd_primary_strict) ||
    nrow(mrd_primary_strict) < 2) {
  knitr::asis_output("<em>STRICT: fewer than 2 studies — not shown.</em>")
  knitr::knit_exit()
}

# 2. Aggregate 2×2 counts per study
strict_counts <- mrd_primary_strict %>%
  transmute(
    Study = as.character(Study),
    a = as.numeric(a), b = as.numeric(b),
    c = as.numeric(c), d = as.numeric(d),
    n = as.numeric(n)
  ) %>%
  filter(
    is.finite(a), is.finite(b), is.finite(c), is.finite(d), is.finite(n)
  ) %>%
  group_by(Study) %>%
  summarise(
    a = sum(a), b = sum(b), c = sum(c), d = sum(d),
    N = sum(n), .groups = "drop"
  )

if (nrow(strict_counts) < 2) {
  knitr::asis_output("<em>STRICT: insufficient rows.</em>")
  knitr::knit_exit()
}

# 3. Compute log-odds etc. using the same helper as PRIMARY
strict_disc <- strict_counts %>%
  prep_discordance() %>%   # adds yi, vi, se (and yi_lo/yi_hi, though 2B_lancet recomputes)
  mutate(
    StudyShort = gsub("\\s+et al\\.?\\s*.*$", " et al.", Study)
  )

# 4. Meta-analysis on STRICT
fit_str <- fit_rma(strict_disc)

# 5. Draw and save STRICT figure (same style as 2B PRIMARY)
forest_2B_lancet(
  d       = strict_disc,
  res     = fit_str,
  title   = "B. Directional discordance (STRICT; Δ ≤ 30)",
  out_file = here::here("figs", "Figure_2B_Directional_Discordance_STRICT.png")
)
```





```{r kappa-helpers, include=FALSE}
# Cohen's kappa from a,b,c,d (2×2)
kappa_from_abcd <- function(a,b,c,d) {
  n <- a+b+c+d; if (!is.finite(n) || n <= 0) return(NA_real_)
  po <- (a + d) / n
  pe <- (((a+b)*(a+c)) + ((c+d)*(b+d))) / (n*n)
  (po - pe) / pmax(1 - pe, .Machine$double.eps)
}

# Short study label: "Surname Year"
short_label <- function(x) {
  x <- as.character(x)
  x <- gsub("\\(.*?\\)", "", x); x <- gsub("(?i)et\\s+al\\.?", "", x)
  x <- gsub("\\s+", " ", x); x <- trimws(x)
  yr <- stringr::str_extract(x, "(19|20)\\d{2}")
  lead <- gsub(",.*$", "", x); surname <- sub("\\s+.*$", "", lead)
  ifelse(is.na(yr), surname, paste0(surname, " ", yr))
}

# Bootstrap SE/CI for kappa under multinomial sampling with fixed n and cell proportions
kappa_boot <- function(a,b,c,d, B = 2000L) {
  n <- a+b+c+d
  if (!is.finite(n) || n <= 0) return(c(se=NA_real_, lo=NA_real_, hi=NA_real_))
  p <- c(a,b,c,d) / n
  if (any(!is.finite(p))) return(c(se=NA_real_, lo=NA_real_, hi=NA_real_))
  sims <- rmultinom(B, n, prob = p)
  kappas <- apply(sims, 2, function(x) kappa_from_abcd(x[1], x[2], x[3], x[4]))
  c(se = stats::sd(kappas, na.rm=TRUE),
    lo = as.numeric(stats::quantile(kappas, 0.025, na.rm=TRUE)),
    hi = as.numeric(stats::quantile(kappas, 0.975, na.rm=TRUE)))
}

```



```{r sim-obj, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# --- Monte-Carlo null (independence with fixed marginals): κ & AC1 per study ---

sim_kappa_ac1 <- function(a,b,c,d, B = 2000L) {
n <- a+b+c+d; if (!is.finite(n) || n <= 0) return(NULL)
r1 <- a + b; r2 <- c + d; c1 <- a + c; c2 <- b + d
p11 <- (r1/n) * (c1/n); p12 <- (r1/n) * (c2/n); p21 <- (r2/n) * (c1/n); p22 <- (r2/n) * (c2/n)
probs <- c(p11,p12,p21,p22); probs <- pmax(probs, 0); probs <- probs/sum(probs)

kappa_obs <- { po <- (a + d) / n; pe <- (((a+b)*(a+c)) + ((c+d)*(b+d))) / (n*n); (po - pe) / pmax(1 - pe, .Machine$double.eps) }
ac1_obs   <- { po <- (a + d) / n; p1 <- (a + b) / n; p2 <- (a + c) / n; pe <- p1*p2 + (1 - p1)*(1 - p2); (po - pe) / pmax(1 - pe, .Machine$double.eps) }

sim <- replicate(B, {
x <- as.integer(stats::rmultinom(1, n, probs))
aa <- x[1]; bb <- x[2]; cc <- x[3]; dd <- x[4]
po <- (aa + dd) / n; pe <- (((aa+bb)*(aa+cc)) + ((cc+dd)*(bb+dd))) / (n*n)
k  <- (po - pe) / pmax(1 - pe, .Machine$double.eps)
p1 <- (aa + bb) / n; p2 <- (aa + cc) / n; pe1 <- p1*p2 + (1 - p1)*(1 - p2)
ac1 <- (po - pe1) / pmax(1 - pe1, .Machine$double.eps)
c(k = k, ac1 = ac1)
})
k_sim <- sim["k", ]; ac1_sim <- sim["ac1", ]

data.frame(
n = n,
kappa_obs = kappa_obs,
kappa_mean = mean(k_sim, na.rm=TRUE),
kappa_lo = quantile(k_sim, 0.025, na.rm=TRUE),
kappa_hi = quantile(k_sim, 0.975, na.rm=TRUE),
kappa_p_right = mean(k_sim >= kappa_obs),
AC1_obs = ac1_obs,
AC1_mean = mean(ac1_sim, na.rm=TRUE),
AC1_lo = quantile(ac1_sim, 0.025, na.rm=TRUE),
AC1_hi = quantile(ac1_sim, 0.975, na.rm=TRUE),
AC1_p_right = mean(ac1_sim >= ac1_obs)
)
}

# -- Build table (expects mrd2x2 with a,b,c,d and a study label column) --

sim_tbl <- NULL
if (exists("mrd2x2") && is.data.frame(mrd2x2) && all(c("a","b","c","d") %in% names(mrd2x2))) {
sim_tbl <- purrr::pmap_dfr(mrd2x2[, c("a","b","c","d")], ~ sim_kappa_ac1(..1, ..2, ..3, ..4, B = 2000L)) %>%
dplyr::bind_cols(study = mrd2x2[[dplyr::first(intersect(c("study","Study","study_id","first_author_year","title"), names(mrd2x2)))]] , .) %>%
dplyr::relocate(study)
readr::write_csv(sim_tbl, "tables/sim_tbl_kappa_ac1.csv")
}

# -- Pretty render -------------------------------------------------------------

if (is.data.frame(sim_tbl) && nrow(sim_tbl)) {

# Apply friendly names

col_map <- c(
study = "Study", n = "n",
kappa_obs="κ (obs)", kappa_mean="κ (null mean)", kappa_lo="κ 2.5%", kappa_hi="κ 97.5%", kappa_p_right="κ p(right)",
AC1_obs="AC1 (obs)", AC1_mean="AC1 (null mean)", AC1_lo="AC1 2.5%", AC1_hi="AC1 97.5%", AC1_p_right="AC1 p(right)"
)
sim_pretty <- sim_tbl
names(sim_pretty) <- dplyr::recode(names(sim_pretty), !!!col_map)

caption_txt <- "Simulation under independence (κ, AC1): observed vs null with fixed marginals"

if (knitr::is_html_output() && requireNamespace("DT", quietly = TRUE)) {
knitr::asis_output(' <style>
.dt-compact .dataTables_wrapper .dataTables_info { margin-top: 0 }
table.dataTable.compact tbody td { padding: 6px 10px; }
table.dataTable.compact thead th { padding: 6px 10px; } </style>
')
DT::datatable(
sim_pretty,
class = "compact stripe hover dt-compact",
escape = FALSE,
caption = htmltools::tags$caption(style="caption-side: top; text-align:left;", caption_txt),
extensions = c("Buttons"),
options = list(
dom = "Bfrtip",
buttons = c("copy","csv","excel"),
pageLength = 15, lengthMenu = c(15,25,50,100),
autoWidth = TRUE, scrollX = TRUE,
columnDefs = list(
list(className = "dt-left", targets = 0),           # Study left
list(className = "dt-center", targets = 1:11)       # numerics centered
)
),
rownames = FALSE
) %>%
DT::formatRound(columns = c("κ (obs)","κ (null mean)","κ 2.5%","κ 97.5%","AC1 (obs)","AC1 (null mean)","AC1 2.5%","AC1 97.5%"),
digits = 3) %>%
DT::formatCurrency(columns = "n", currency = "", interval = 3, mark = ",", digits = 0) %>%
DT::formatStyle(columns = c("κ p(right)","AC1 p(right)"),
`font-family` = "monospace")
} else {
# Non-HTML fallback
dig <- c(NA, 0, rep(3, 8), NA, NA)  # study, n, numeric cols
knitr::kable(sim_pretty, caption = caption_txt, digits = dig, align = "lcccccccccc")
}
} else {
note("Simulation table not created: 2×2 counts (mrd2x2) not available yet.")
}

```


```{r fh-obj, echo=FALSE, message=FALSE, warning=FALSE}
fh_tbl <- NULL

.ok_meta <- requireNamespace("metafor", quietly = TRUE)

pick_col <- function(df, candidates) {
  nm <- names(df)
  hit <- intersect(candidates, nm)
  if (length(hit)) hit[1] else NULL
}

if (.ok_meta && exists("res_disc") && inherits(res_disc, "rma.uni") && exists("disc_df") && is.data.frame(disc_df) && nrow(disc_df) >= 2) {
  yi <- suppressWarnings(as.numeric(disc_df$yi))
  vi <- suppressWarnings(as.numeric(disc_df$vi))
  keep <- is.finite(yi) & is.finite(vi) & vi > 0
  if (sum(keep) >= 2) {
    yi <- yi[keep]; vi <- vi[keep]
    lab_col <- pick_col(disc_df, c("study","Study","study_id","id","authors","first_author_year","title"))
    slabs <- if (!is.null(lab_col)) as.character(disc_df[[lab_col]][keep]) else paste0("row_", seq_len(sum(keep)))

    wi_fix <- 1/vi
    mu_fix <- sum(wi_fix * yi) / sum(wi_fix)
    Q_i    <- wi_fix * (yi - mu_fix)^2

    inf <- metafor::influence(res_disc)
    loo <- metafor::leave1out(res_disc)

    fh_tbl <- tibble::tibble(
      study = slabs,
      yi    = yi,
      vi    = vi,
      w_RE  = as.numeric(1 / (vi + res_disc$tau2)),
      w_RE_frac = w_RE / sum(w_RE),
      Q_contrib_fixed = Q_i,
      cooksd = as.numeric(inf$cook.d),
      hat    = as.numeric(inf$hat),
      est_full = as.numeric(res_disc$b),
      est_loo  = as.numeric(loo$estimate),
      delta_abs = abs(est_loo - est_full)
    ) %>%
      dplyr::arrange(dplyr::desc(Q_contrib_fixed))
  }

} else if (.ok_meta && exists("res_hr") && inherits(res_hr, "rma.uni") && exists("surv_df") && is.data.frame(surv_df) && nrow(surv_df) >= 2) {
  yi <- suppressWarnings(as.numeric(surv_df$logHR))
  vi <- suppressWarnings(as.numeric(surv_df$SE)^2)
  keep <- is.finite(yi) & is.finite(vi) & vi > 0
  if (sum(keep) >= 2) {
    yi <- yi[keep]; vi <- vi[keep]
    lab_col <- pick_col(surv_df, c("Study","study","study_id","id","authors","first_author_year","title"))
    slabs <- if (!is.null(lab_col)) as.character(surv_df[[lab_col]][keep]) else paste0("row_", seq_len(sum(keep)))

    wi_fix <- 1/vi
    mu_fix <- sum(wi_fix * yi) / sum(wi_fix)
    Q_i    <- wi_fix * (yi - mu_fix)^2

    inf <- metafor::influence(res_hr)
    loo <- metafor::leave1out(res_hr)

    fh_tbl <- tibble::tibble(
      study = slabs,
      yi    = yi,
      vi    = vi,
      w_RE  = as.numeric(1 / (vi + res_hr$tau2)),
      w_RE_frac = w_RE / sum(w_RE),
      Q_contrib_fixed = Q_i,
      cooksd = as.numeric(inf$cook.d),
      hat    = as.numeric(inf$hat),
      est_full = as.numeric(res_hr$b),
      est_loo  = as.numeric(loo$estimate),
      delta_abs = abs(est_loo - est_full)
    ) %>%
      dplyr::arrange(dplyr::desc(Q_contrib_fixed))
  }
}

if (exists("is_df") && is_df(fh_tbl) || (is.data.frame(fh_tbl) && nrow(fh_tbl) > 0)) {
  readr::write_csv(fh_tbl, "tables/fh_tbl.csv")
  if (exists("show_table")) {
    show_table(fh_tbl, "Study influence & heterogeneity contributions (active analysis)")
  } else {
    knitr::kable(fh_tbl, caption = "Study influence & heterogeneity contributions (active analysis)")
  }
} else {
  note("fh_tbl not created: no active meta-analysis object available at this point.")
}

```



## Supplementary Figure SF1. Concordance matrix (pooled)

```{r SF1, echo=FALSE, fig.cap="Supplementary Figure SF1. Concordance matrices for PRIMARY and STRICT time-points. STRICT applies the Δ(MRD–PET) ≤ 30 days rule to treat assessments as paired.", out.width="95%"}
# --- Normalizer: ensure a,b,c,d,n exist and are numeric ---
normalize_conc <- function(df) {
  if (is.null(df) || !is.data.frame(df) || !nrow(df)) return(NULL)
  df <- tibble::as_tibble(df)

  pick <- function(nms, choices) {
    nm <- intersect(choices, nms)
    if (length(nm)) nm[1] else NA_character_
  }

  a_nm <- pick(names(df), c("a","MRDneg_PETpos","MRDneg.PETpos","MRDneg_PET+","MRDneg.PET+"))
  b_nm <- pick(names(df), c("b","MRDneg_PETneg","MRDneg.PETneg","MRDneg_PET-","MRDneg.PET-"))
  c_nm <- pick(names(df), c("c","MRDpos_PETneg","MRDpos.PETneg","MRDpos_PET-","MRDpos.PET-"))
  d_nm <- pick(names(df), c("d","MRDpos_PETpos","MRDpos.PETpos","MRDpos_PET+","MRDpos.PET+"))
  n_nm <- pick(names(df), c("n","N","total","Total"))

  req <- c(a_nm,b_nm,c_nm,d_nm)
  if (anyNA(req)) return(NULL)

  out <- tibble::tibble(
    a = suppressWarnings(as.numeric(df[[a_nm]])),
    b = suppressWarnings(as.numeric(df[[b_nm]])),
    c = suppressWarnings(as.numeric(df[[c_nm]])),
    d = suppressWarnings(as.numeric(df[[d_nm]]))
  )
  # compute/validate n
  n_from_cols <- out$a + out$b + out$c + out$d
  if (!is.na(n_nm)) {
    n_vec <- suppressWarnings(as.numeric(df[[n_nm]]))
    # trust provided n if consistent; otherwise recompute
    ok <- is.finite(n_vec) & (abs(n_vec - n_from_cols) < 1e-8)
    out$n <- ifelse(ok, n_vec, n_from_cols)
  } else {
    out$n <- n_from_cols
  }

  # drop rows with invalid cells
  keep <- is.finite(out$a) & is.finite(out$b) & is.finite(out$c) & is.finite(out$d) &
          is.finite(out$n) & out$n > 0
  out[keep, , drop = FALSE]
}

# --- Ensure conc_primary (from conc or compute_concordance) ---
if (!exists("conc") || !is.data.frame(conc) || !nrow(conc)) {
  cc_tmp <- try(compute_concordance(mrd_primary), silent = TRUE)
  conc_primary <- if (!inherits(cc_tmp, "try-error") && is.list(cc_tmp)) cc_tmp$per_study else NULL
} else {
  conc_primary <- conc
}

# STRICT subset, if available
conc_strict <- NULL
if (exists("mrd_primary_strict") && is.data.frame(mrd_primary_strict) && nrow(mrd_primary_strict)) {
  cc_strict <- try(compute_concordance(mrd_primary_strict), silent = TRUE)
  if (!inherits(cc_strict, "try-error") && is.list(cc_strict) &&
      is.data.frame(cc_strict$per_study) && nrow(cc_strict$per_study)) {
    conc_strict <- cc_strict$per_study
  }
}

# --- Normalize for helper's expected schema (a,b,c,d,n) ---
conc_primary_norm <- normalize_conc(conc_primary)
conc_strict_norm  <- normalize_conc(conc_strict)

# --- Fallback simple pooled 2x2 heatmap ---
draw_matrix_fallback <- function(df, title){
  if (is.null(df) || !nrow(df) || !all(c("a","b","c","d","n") %in% names(df))) return(NULL)
  a <- sum(as.numeric(df$a), na.rm = TRUE)
  b <- sum(as.numeric(df$b), na.rm = TRUE)
  c <- sum(as.numeric(df$c), na.rm = TRUE)
  d <- sum(as.numeric(df$d), na.rm = TRUE)
  mat <- matrix(c(b,a,c,d), nrow=2, byrow=TRUE,
                dimnames=list(c("MRD−","MRD+"), c("PET−","PET+")))
  dfm <- as.data.frame(as.table(mat))
  ggplot2::ggplot(dfm, ggplot2::aes(x = Var2, y = Var1, fill = Freq, label = scales::comma(Freq))) +
    ggplot2::geom_tile(color = "white") +
    ggplot2::geom_text(size = 4) +
    ggplot2::scale_fill_continuous(guide = "none") +
    ggplot2::labs(title = title, x = NULL, y = NULL) +
    ggplot2::theme_minimal(base_size = 12)
}

SF1_file <- file.path("figs","Supplementary_Figure_SF1_Panel_Primary_vs_Strict.png")

ok_helper <- exists("fig_concordance_matrix_panel") && is.function(fig_concordance_matrix_panel)
if (ok_helper && !is.null(conc_primary_norm)) {
  panel <- try(
    fig_concordance_matrix_panel(
      per_study_primary = conc_primary_norm,
      per_study_strict  = conc_strict_norm,
      caption_inside    = FALSE   # caption handled by fig.cap
    ),
    silent = TRUE
  )
  if (!inherits(panel, "try-error") && !is.null(panel)) {
    # 1) render into the HTML
    print(panel)
    # 2) also save a copy to disk
    ggplot2::ggsave(SF1_file, panel, width = 11, height = 5.6, dpi = 600, bg = "white")
  } else {
    used_helper <- FALSE
  }
}

if (!exists("panel") || is.null(panel)) {
  pA <- draw_matrix_fallback(conc_primary_norm, "PRIMARY (pooled 2×2)")
  pB <- draw_matrix_fallback(conc_strict_norm,  "STRICT (Δ≤30 d; pooled 2×2)")
  if (!is.null(pA)) {
    panel <- (pA | (pB %||% (ggplot2::ggplot() + ggplot2::theme_void())))
    print(panel)
    ggplot2::ggsave(SF1_file, panel, width = 10.5, height = 4.6, dpi = 600, bg = "white")
  } else {
    knitr::asis_output("<em>SF1 could not be generated (no data).</em>")
  }
}

```



## Supplementary Figure SF2. Discordance Strict Analysis

```{r SF2, echo=FALSE, out.width="90%"}
if (exists("mrd_primary_strict") && is.data.frame(mrd_primary_strict)) {
  cc_strict <- try(compute_concordance(mrd_primary_strict), silent = TRUE)
  if (!inherits(cc_strict, "try-error") &&
      is.list(cc_strict) && is.data.frame(cc_strict$per_study) &&
      nrow(cc_strict$per_study) >= 2) {

    SF2 <- fig_discordance_strict_pretty(
      cc_strict$per_study,
      out = "Supplementary_Figure_SF2_Directional_Discordance_STRICT.png"
    )

    # Export nicely; show
    if (is.list(SF2) && inherits(SF2$plot, "gg")) {
      p <- SF2$plot + ggplot2::labs(
        title = "SF2. Directional discordance (STRICT, Δ≤30 days)",
        x = "log-odds (>0 → MRD−/PET+ predominance)", y = NULL
      )
      save_lancet(p, here::here("figs","Supplementary_Figure_SF2_Directional_Discordance_STRICT.png"),
                  layout = "twocol", height_mm = 120, figure_type = "line")
      print(p)
    } else if (is.list(SF2) && !is.null(SF2$file) && file.exists(SF2$file)) {
      show_png("figs", basename(SF2$file))
    } else {
      knitr::asis_output("*SF2 could not be generated (no result).*")
    }

    if (is.list(SF2) && !is.null(SF2$caption_html)) knitr::asis_output(SF2$caption_html)

  } else {
    knitr::asis_output("*Strict-timepoint discordance omitted: no analysable rows after strict filter.*")
  }
} else {
  knitr::asis_output("*Strict-timepoint dataset mrd_primary_strict not found.*")
}

```



# Survival & meta-analysis
## PFS Dual-negative vs others
```{r surv-check, echo=FALSE}
if (exists("surv_df") && is.data.frame(surv_df) && nrow(surv_df) > 0) {
  knitr::kable(
    dplyr::select(surv_df, Study, logHR, SE, HR, HR_lo, HR_hi),
    caption = sprintf("PFS dual-negative vs others — %d studies detected", nrow(surv_df)),
    digits = 3
  )
} else {
  knitr::asis_output("<em>No estimable survival rows (logHR & SE) after harmonization.</em>")
}
```



## Figure 3. Forest:dual-negativity
```{r fig-3A-forest, echo=FALSE, message=FALSE, warning=FALSE,cache=FALSE, fig.cap="Figure 3. Dual-negative MRD−/PET-CT− versus all other states: pooled hazard ratio for progression-free survival"}
suppressPackageStartupMessages({
  library(dplyr); library(metafor)
})

stopifnot(exists("surv_df"), is.data.frame(surv_df))

# ensure SE and vi are present on log scale
if (!("SE" %in% names(surv_df)) && "vi" %in% names(surv_df)) {
  surv_df$SE <- sqrt(surv_df$vi)
}
if (!("vi" %in% names(surv_df)) && "SE" %in% names(surv_df)) {
  surv_df$vi <- surv_df$SE^2
}

fig_survival_forest_pretty(surv_df)


```



```{r fig-3A-note, echo=FALSE, results='asis'}
# Build a compact dynamic note under Figure 3
# Uses REML + Knapp–Hartung results if 'res_hr' exists; otherwise prints a generic note.

fmt <- function(x, d = 2) formatC(x, format = "f", digits = d)

note_txt <- NULL
if (exists("res_hr") && inherits(res_hr, "rma.uni")) {
  K  <- res_hr$k
  mu <- as.numeric(res_hr$b)
  ci_lb <- res_hr$ci.lb; ci_ub <- res_hr$ci.ub

  # Prediction interval on the HR scale (if available)
  pi_txt <- ""
  pi_obj <- try(metafor::predict(res_hr, transf = exp), silent = TRUE)
  if (!inherits(pi_obj, "try-error") && all(is.finite(c(pi_obj$pi.lb, pi_obj$pi.ub)))) {
    pi_txt <- paste0(" Prediction interval [", fmt(pi_obj$pi.lb), "–", fmt(pi_obj$pi.ub), "].")
  }

  note_txt <- paste0(
    "Hazard ratios compare <strong>dual‑negative (MRD−/PET−)</strong> versus <strong>all other states</strong>. ",
    "Pooling: random‑effects REML with Knapp–Hartung (k=", K, "). ",
    "Pooled HR = ", fmt(exp(mu)), " (", fmt(exp(ci_lb)), "–", fmt(exp(ci_ub)), ").",
    pi_txt, " Values &lt; 1 favor dual‑negative; &gt; 1 favor others. ",
    if (K < 10) "Small‑study asymmetry tests have low power for k &lt; 10 and are reported descriptively only." else ""
  )
} else {
  # Fallback if the meta object isn't built for any reason
  note_txt <- paste0(
    "Hazard ratios compare <strong>dual‑negative (MRD−/PET−)</strong> versus <strong>all other states</strong>. ",
    "HRs and 95% CIs were used as reported when available; otherwise standardized from text fields ",
    "or reconstructed from the reported CI on the log scale (normal approximation). ",
    "Values &lt; 1 favor dual‑negative; &gt; 1 favor others. ",
    "Pooling uses random‑effects REML with Knapp–Hartung; a prediction interval is shown when k ≥ 2."
  )
}

# Print as a compact callout (uses the .note style you have; inline size is a safe fallback)
knitr::asis_output(sprintf("<div class='note' style='font-size:90%%'><em>%s</em></div>", note_txt))

```


```{r fig-3A-lancetBW, echo=FALSE, message=FALSE, warning=FALSE}
# Create the Lancet-style black & white HR forest for panel A
if (exists("surv_df") && is.data.frame(surv_df) && nrow(surv_df) >= 2) {
  # ensure we have the REML + Knapp–Hartung fit
  if (!exists("res_hr") || !inherits(res_hr, "rma.uni")) {
    res_hr <- metafor::rma(yi = surv_df$logHR,
                           vi = surv_df$vi,
                           method = "REML",
                           test   = "knha")
  }
  
  forest_lancet_bw_hr(
    fit  = res_hr,
    tab  = surv_df,
    file_base = "Figure3A_HR_Forest_LancetBW_final"
  )
}

```


```{r pfs-heterogeneity-sensitivity, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
if (exists("surv_df") && is.data.frame(surv_df) && nrow(surv_df) >= 2 &&
    all(c("logHR","SE") %in% names(surv_df))) {
  yi <- as.numeric(surv_df$logHR); vi <- as.numeric(surv_df$SE)^2
  fit_reml <- metafor::rma(yi=yi, vi=vi, method="REML", test="knha")
  fit_pm   <- metafor::rma(yi=yi, vi=vi, method="PM",   test="knha")
  fit_sj   <- metafor::rma(yi=yi, vi=vi, method="SJ",   test="knha")

  sens_pfs <- tibble::tibble(
    Model=c("REML (Knapp–Hartung)","Paule–Mandel (Knapp–Hartung)","Sidik–Jonkman (Knapp–Hartung)"),
    k=length(yi),
    center_log=c(as.numeric(fit_reml$b), as.numeric(fit_pm$b), as.numeric(fit_sj$b)),
    lcl_log=c(fit_reml$ci.lb, fit_pm$ci.lb, fit_sj$ci.lb),
    ucl_log=c(fit_reml$ci.ub, fit_pm$ci.ub, fit_sj$ci.ub),
    `HR (95% CI)`=sprintf("%.2f (%.2f–%.2f)", exp(center_log), exp(lcl_log), exp(ucl_log)),
    `τ²`=c(fit_reml$tau2, fit_pm$tau2, fit_sj$tau2),
    `I² (%)`=c(fit_reml$I2, fit_pm$I2, fit_sj$I2)
  ) |> dplyr::select(Model, k, `HR (95% CI)`, `τ²`, `I² (%)`)

  if (knitr::is_html_output() && requireNamespace("gt", quietly=TRUE)) {
    tbl <- gt::gt(sens_pfs) |>
      gt::cols_align("center", columns=gt::everything()) |>
      gt::fmt_number(columns=c(`τ²`,`I² (%)`), decimals=2) |>
      gt::tab_header(
        title   = gt::md("**PFS heterogeneity sensitivity (dual-negative vs all others)**"),
        subtitle= gt::md("Random-effects HR under different τ² estimators; values < 1 favor dual-negative.")
      )
    knitr::asis_output(gt::as_raw_html(tbl))   # <- render correctly
    invisible(NULL)
  } else {
    print(knitr::kable(sens_pfs, digits=2,
          caption="PFS heterogeneity sensitivity (dual-negative vs all others)"))
  }

  dir.create("tables", showWarnings=FALSE, recursive=TRUE)
  readr::write_csv(sens_pfs, file.path("tables","sensitivity_pfs_dualneg.csv"))
} else {
  knitr::asis_output("<em>PFS sensitivity not run: `surv_df` missing or incomplete (need logHR, SE).</em>")
}

```


## PFS pooled summary
```{r pfs-pooled-summary, echo=FALSE, results='asis', cache=FALSE}
if (exists("surv_df") && is.data.frame(surv_df) && nrow(surv_df) >= 2) {
  fit <- metafor::rma(yi=surv_df$logHR, sei=surv_df$SE, method="REML", test="knha")
  pr  <- try(metafor::predict(fit, transf=exp), silent=TRUE)
  out <- tibble::tibble(
    Model="REML (Knapp–Hartung)", k=nrow(surv_df),
    `HR (95% CI)`=sprintf("%.2f (%.2f–%.2f)", exp(as.numeric(fit$b)), exp(fit$ci.lb), exp(fit$ci.ub)),
    `Prediction interval (HR)`=if (!inherits(pr,"try-error")) sprintf("%.2f–%.2f", pr$pi.lb, pr$pi.ub) else "—",
    `τ²`=fit$tau2, `I² (%)`=fit$I2
  )
  if (knitr::is_html_output() && requireNamespace("gt", quietly=TRUE)) {
    tbl <- gt::gt(out) |>
      gt::fmt_number(columns=c(`τ²`,`I² (%)`), decimals=2) |>
      gt::cols_align("center", columns=gt::everything()) |>
      gt::tab_header(
        title=gt::md("**PFS pooled summary (dual-negative vs all others)**"),
        subtitle=gt::md("Random-effects REML with Knapp–Hartung. Values < 1 favor dual-negative.")
      ) |>
      gt::tab_source_note(gt::md("Small-study asymmetry tests have low power when *k* < 10; interpret cautiously."))
    knitr::asis_output(gt::as_raw_html(tbl))
    invisible(NULL)
  } else {
    print(knitr::kable(out, digits=2,
      caption="PFS pooled summary (dual-negative vs all others): REML + Knapp–Hartung."))
  }
}


```



## Figure 3B. Funnel plot

```{r fig-3b, echo=TRUE, fig.cap="B. Funnel plot (log(HR) vs SE). Dashed cone = ~95% pseudo-CIs; vertical line = pooled effect. Egger’s test p shown; for k<10 interpret with caution.", out.width="100%"}

stopifnot(exists("surv_df"), nrow(surv_df) >= 1)

if (!exists("res_hr") || !inherits(res_hr, "rma.uni")) {
  res_hr <- metafor::rma(yi = surv_df$logHR, vi = surv_df$vi, method = "REML", test = "knha")
}
mu <- as.numeric(res_hr$b)

# Limits from data to include ALL studies
x_min <- min(surv_df$logHR, na.rm = TRUE) - 0.15
x_max <- max(surv_df$logHR, na.rm = TRUE) + 0.15
y_max <- max(surv_df$SE,    na.rm = TRUE) + 0.02
y_seq <- seq(0, y_max, length.out = 200)

cone_left  <- data.frame(x = mu - 1.96*y_seq, y = y_seq)
cone_right <- data.frame(x = mu + 1.96*y_seq, y = y_seq)

p_fun <- ggplot(surv_df, aes(x = logHR, y = SE)) +
  geom_line(data = cone_left,  aes(x, y), linetype = "dashed") +
  geom_line(data = cone_right, aes(x, y), linetype = "dashed") +
  geom_vline(xintercept = mu, linetype = "dashed") +
  geom_point(size = 2.5) +
  ggrepel::geom_label_repel(aes(label = StudyShort),
                            size = 3, label.size = 0.25, label.r = unit(0.08, "lines"),
                            min.segment.length = 0, seed = 1234) +
  coord_cartesian(xlim = c(x_min, x_max), ylim = c(0, y_max), expand = FALSE) +
  labs(x = "log(HR)", y = "SE", title = "B. Funnel plot (log(HR) vs SE)") +
  theme_minimal(base_size = 11) +
  theme(panel.grid.minor = element_blank(),
        plot.title = element_text(hjust = 0.5))

out_png <- here::here("figs","Figure_3B_Funnel.png")
ggsave(out_png, p_fun, width = 7.8, height = 5.0, dpi = 300, bg = "white")

cap <- if (exists("legend_for")) legend_for("Figure_3B_Funnel.png") else
  "B. Funnel plot (log(HR) vs SE). Dashed cone = ~95% pseudo-CIs; vertical line = pooled effect; Egger’s p shown; for k<10 interpret with caution."
if (file.exists(out_png)) { if (exists("show_png")) show_png("figs", basename(out_png), caption = cap, width = "95%") else knitr::include_graphics(out_png) }

```


```{r fig-3B-egger-summary, include=FALSE}
if (exists("res_hr") && inherits(res_hr, "rma.uni") && res_hr$k >= 3) {
  eg <- try(metafor::regtest(res_hr, model = "rma", predictor = "sei"), silent = TRUE)
  if (!inherits(eg, "try-error")) {
    tibble::tibble(model = "REML (KnHa)", center_log = as.numeric(res_hr$b),
                   p_egger = as.numeric(eg$pval), k = res_hr$k) %>%
      readr::write_csv(here::here("tables","egger_summary_pfs.csv"))
  }
}
```



```{r fig-3B-note, echo=FALSE, results='asis'}
# Requires 'res_hr' (rma.uni) from the PFS meta-analysis; falls back to a generic note otherwise.

fmt <- function(x, d = 3) formatC(x, format = "f", digits = d)

build_note <- function() {
  if (exists("res_hr") && inherits(res_hr, "rma.uni")) {
    K  <- res_hr$k
    mu <- as.numeric(res_hr$b)

    # Egger intercept (run only when k ≥ 3)
    egger_txt <- ""
    if (K >= 3 && requireNamespace("metafor", quietly = TRUE)) {
      eg <- try(metafor::regtest(res_hr, model = "rma", predictor = "sei"), silent = TRUE)
      if (!inherits(eg, "try-error") && isTRUE(is.finite(eg$pval))) {
        egger_txt <- paste0(" Egger intercept p = ", fmt(eg$pval, 3), if (K < 10) " (k<10: low power)." else ".")
      }
    }

    paste0(
      "Funnel plot shows study log(HR) on the x-axis versus its SE on the y-axis (inverted; more precise studies appear higher). ",
      "The dashed vertical line marks the pooled center μ = ", fmt(mu, 3), ". ",
      "Slanted lines depict ~95% pseudo–confidence limits under a fixed pooled effect.",
      egger_txt, " Asymmetry screens for small-study effects; it does not prove publication bias and may reflect true between-study differences."
    )
  } else {
    paste0(
      "Funnel plot shows study log(HR) on the x-axis versus its SE on the y-axis (inverted; more precise studies appear higher). ",
      "Dashed vertical line marks the pooled center; slanted lines depict ~95% pseudo–confidence limits under a fixed pooled effect. ",
      "Egger’s test is reported only as a screen and has low power when k < 10; asymmetry does not prove publication bias."
    )
  }
}

note_txt <- build_note()
knitr::asis_output(sprintf("<div class='note' style='font-size:90%%'><em>%s</em></div>", note_txt))

```



```{r Figure-3-panel, fig.cap="Figure 3. (A) PFS HR (dual-negative vs others); (B) Funnel of log(HR) vs SE. Vertical dashed = pooled effect in each panel.", include=FALSE, results='asis'}

library(ggplot2); library(patchwork); library(here); library(png); library(grid)

if (requireNamespace("patchwork", quietly = TRUE)) {
  pA <- png::readPNG(here::here("figs", "Figure3A_HR_Forest_LancetBW_final.png"))
  pB <- png::readPNG(here::here("figs","Figure_3B_Funnel.png"))
  gA <- grid::rasterGrob(pA, interpolate = TRUE)
  gB <- grid::rasterGrob(pB, interpolate = TRUE)
  pan <- cowplot::plot_grid(ggplot2::ggplot() + ggplot2::annotation_custom(gA) + ggplot2::theme_void(),
                            ggplot2::ggplot() + ggplot2::annotation_custom(gB) + ggplot2::theme_void(),
                            ncol = 2, rel_widths = c(1,1))
  out <- here::here("figs","Figure_3_Panel_AB.png")
  ggplot2::ggsave(out, pan, width = 12, height = 5.8, dpi = 300, bg = "white")
  if (exists("show_png")) show_png("figs","Figure_3_Panel_AB.png","A. Forest of PFS HR; B. Funnel plot") else knitr::include_graphics(out)
}

```



## Supplementary Figure SF3

```{r sim-kappa-bias, echo=FALSE, message=FALSE, warning=FALSE}
suppressPackageStartupMessages({
  library(ggplot2)
  library(dplyr)
  if (requireNamespace("fs", quietly = TRUE)) library(fs)
})

# --- helper: Cohen's kappa from 2×2 counts ------------------------------
kappa_from_counts <- function(a, b, c, d) {
  n <- a + b + c + d
  if (!is.finite(n) || n <= 0) return(NA_real_)
  po <- (b + d) / n
  r1 <- (a + b) / n   # MRD−
  r2 <- (c + d) / n   # MRD+
  c1 <- (b + c) / n   # PET-CT−
  c2 <- (a + d) / n   # PET-CT+
  pe <- r1 * c1 + r2 * c2
  if (!is.finite(pe) || (1 - pe) <= 0) return(NA_real_)
  (po - pe) / (1 - pe)
}

# --- pooled primary 2×2 from Supplementary Table S4 ---------------------
# a = MRD–/PET-CT+; b = MRD–/PET-CT–; c = MRD+/PET-CT–; d = MRD+/PET-CT+
pool <- c(a = 145, b = 499, c = 310, d = 184)
n_tot <- sum(pool)

# row marginals: MRD−, MRD+
r <- c(pool["a"] + pool["b"], pool["c"] + pool["d"])
# column marginals: PET-CT−, PET-CT+
s <- c(pool["b"] + pool["c"], pool["a"] + pool["d"])

# feasible range for a (MRD−/PET-CT+)
a_min <- max(0L, r[1] + s[2] - n_tot)
a_max <- min(r[1], s[2])

grid <- tibble::tibble(a = seq(a_min, a_max, length.out = 200L)) %>%
  mutate(
    b = r[1] - a,
    c = s[1] - b,
    d = r[2] - c,
    n = a + b + c + d
  ) %>%
  filter(a >= 0, b >= 0, c >= 0, d >= 0)

# --- true κ and naïve "marginals-only" κ (either-positive format) -------
grid <- grid %>%
  mutate(
    k_true = mapply(kappa_from_counts, a, b, c, d),
    # lose direction of discordance: only total discordant (a + c) reported
    disc_tot = a + c,
    a_naive  = disc_tot / 2,     # naïvely split discordant equally
    c_naive  = disc_tot / 2,
    k_naive  = mapply(kappa_from_counts, a_naive, b, c_naive, d),
    bias     = k_naive - k_true  # bias of naïve κ
  ) %>%
  filter(is.finite(k_true), is.finite(bias))

# --- plot: curved bias function -----------------------------------------
p <- ggplot(grid, aes(x = k_true, y = bias)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_line(linewidth = 0.8, colour = "#1f77b4") +
  geom_point(size = 2, colour = "black") +
  labs(
  y = "Bias in \u03BA (na\u00efve \u2212 true)",
  x = "True \u03BA (full 2\u00d72)"
) +
  theme_minimal(base_size = 11)

p <- p +
  coord_cartesian(xlim = range(grid$k_true) + c(-0.1, 0.1),
                  ylim = range(grid$bias)    + c(-0.005, 0.005),
                  clip = "off") +
  theme(plot.margin = margin(t = 15, r = 30, b = 15, l = 30))

print(p)

# --- save PNG + PDF ------------------------------------------------------
if (requireNamespace("fs", quietly = TRUE)) fs::dir_create("figs")

ggplot2::ggsave(
  filename = file.path("figs", "SF3B_Kappa_Bias_vs_True.png"),
  plot     = p, width = 7, height = 4.6, dpi = 600, bg = "white"
)

ggplot2::ggsave(
  filename = file.path("figs", "SF3B_Kappa_Bias_vs_True.pdf"),
  plot     = p, width = 7, height = 4.6, device = "pdf", bg = "white"
)


```



```{r sf3b-legend, echo=FALSE, results='asis'}
txt <- paste0(
  "<em>Supplementary Figure SF3B. Bias of “marginals-only” κ (independence assumption).</em> ",
  "Using pooled MRD and PET marginals, we enumerate all feasible 2×2 tables and compute the true κ. ",
  "Assuming independence from marginals alone yields κ=0; therefore bias = κ<sub>independence</sub> − κ<sub>true</sub> = −κ<sub>true</sub>. ",
  "The curve below zero shows systematic pull toward the null (κ=0): ",
  "understates concordance when κ&gt;0 and masks discordance when κ&lt;0. ",
  "Compute κ from the full joint 2×2 (or report identified-set bounds)."
)
if (knitr::is_html_output()) {
  cat(sprintf("<div style='font-size:90%%;margin-top:4px'>%s</div>", txt))
} else {
  cat(
    "Supplementary Figure SF3B. Bias of 'marginals-only' kappa (independence assumption). ",
    "Using pooled MRD and PET marginals, we enumerate all feasible 2x2 tables and compute the true kappa. ",
    "Assuming independence from marginals alone yields kappa = 0; therefore bias = kappa_independence - kappa_true = -kappa_true. ",
    "Curve below zero indicates pull toward the null (kappa = 0): understates concordance when kappa > 0 and masks discordance when kappa < 0. ",
    "Compute kappa from the full joint 2x2 (or report identified-set bounds).\n"
  )
}
```


## Supplementary Table ST2 (Leave-one-out, Egger table, Baujat)

```{r st2-egger-loo-table, echo=FALSE, results='asis', message=FALSE, warning=FALSE}
# fallbacks
note <- if (exists("note") && is.function(note)) note else
  function(x) knitr::asis_output(paste0("<em>", x, "</em>"))

.show_tbl <- function(x, cap){
  if (knitr::is_html_output() && requireNamespace("gt", quietly = TRUE)) {
    tbl <- gt::gt(x) |>
      gt::fmt_number(gt::everything(), decimals = 3) |>
      gt::cols_align("center", columns = gt::everything()) |>
      gt::tab_header(title = gt::md(paste0("**", cap, "**")))
    # IMPORTANT: emit unescaped HTML so Quarto renders it
    cat(gt::as_raw_html(tbl))
  } else {
    print(knitr::kable(x, digits = 3, caption = cap))
  }
}

# choose dataset & fit (PFS first; fallback to discordance)
obj <- NULL; lab <- NULL; yi <- vi <- NULL; slabs <- NULL
if (exists("surv_df") && is.data.frame(surv_df) && nrow(surv_df) >= 2 &&
    all(c("logHR","SE") %in% names(surv_df))) {
  yi <- as.numeric(surv_df$logHR); vi <- as.numeric(surv_df$SE)^2
  slabs <- if ("StudyShort" %in% names(surv_df)) surv_df$StudyShort else surv_df$Study %||% seq_len(nrow(surv_df))
  obj <- try(metafor::rma(yi=yi, vi=vi, method="REML", test="knha"), silent=TRUE)
  lab <- "PFS HR (dual−negative vs others)"
}
if ((is.null(obj) || inherits(obj,"try-error")) &&
    exists("disc_df") && is.data.frame(disc_df) && nrow(disc_df) >= 2 &&
    all(c("yi","vi") %in% names(disc_df))) {
  yi <- as.numeric(disc_df$yi); vi <- as.numeric(disc_df$vi)
  slabs <- disc_df$study %||% seq_len(nrow(disc_df))
  obj <- try(metafor::rma(yi=yi, vi=vi, method="REML", test="knha"), silent=TRUE)
  lab <- "Directional discordance (log-odds)"
}
if (is.null(obj) || inherits(obj,"try-error")) {
  note("Diagnostics unavailable: no meta-analysis object was built."); loo_df <<- NULL; knitr::knit_exit()
}

k <- length(yi)

# Egger
if (k >= 3) {
  eg <- try(metafor::regtest(obj, model="rma", predictor="sei"), silent=TRUE)
  eg_tab <- tibble::tibble(model="REML (Knapp–Hartung)", k=k,
                           center_log=as.numeric(obj$b),
                           Egger_p=if (inherits(eg,"try-error")) NA_real_ else as.numeric(eg$pval))
  .show_tbl(eg_tab, sprintf("ST2: Egger summary — %s", lab))
  if (k < 10) note("Egger’s test has low power for k < 10; interpret with caution.")
} else note("Egger not performed (k < 3).")

# Leave-one-out
if (k >= 3) {
  loo <- metafor::leave1out(obj)
  est_full <- as.numeric(obj$b); est_loo <- as.numeric(loo$estimate); se_loo <- as.numeric(loo$se)
  tab <- tibble::tibble(
    Study   = slabs,
    Center  = est_full,
    LOO_est = est_loo,
    LOO_se  = se_loo,
    Delta   = abs(est_full - est_loo),
    LCL     = est_loo - 1.96*se_loo,
    UCL     = est_loo + 1.96*se_loo
  ) |> dplyr::arrange(dplyr::desc(Delta))

  # If HR analysis, add HR columns and expose loo_df for the summary
  if (grepl("^PFS HR", lab)) {
    tab <- tab |> dplyr::mutate(HR_center=exp(Center), HR=exp(LOO_est), HR_LCL=exp(LCL), HR_UCL=exp(UCL))
    loo_df <<- tab |> dplyr::select(Study, HR, HR_LCL, HR_UCL)
  } else {
    loo_df <<- tab
  }
  .show_tbl(tab, "Leave-one-out (sorted by |Δ pooled|)")
} else note("LOO not performed (k < 3).")

```



```{r st2-baujat-plot, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Baujat plot", out.width="80%"}
if (exists("obj") && inherits(obj, "rma.uni") && length(obj$yi) >= 3) {
  print(metafor::baujat(obj, slab = get("slabs", inherits=TRUE)))
} else {
  knitr::asis_output("<em>Baujat not performed (k < 3 or no model).</em>")
}
```



## Risk of Bias: import & quick previews
```{r rob-from-bias, message=FALSE, warning=FALSE, include=FALSE}
# Guards
overwrite <- isTRUE(getOption("ROB_OVERWRITE", FALSE)) || isTRUE(as.logical(Sys.getenv("ROB_OVERWRITE", "FALSE")))
build_from_bias <- isTRUE(getOption("ROB_FROM_BIAS", FALSE))

rob_dir <- here::here("data","rob")
quips_path  <- file.path(rob_dir, "QUIPS.csv")
quadas_path <- file.path(rob_dir, "QUADAS2.csv")

safe_read_csv0 <- function(p) {
  if (!file.exists(p)) return(NULL)
  readr::read_csv(p, show_col_types = FALSE, locale = readr::locale(encoding = "UTF-8")) %>%
    janitor::clean_names()
}

if (!build_from_bias) {
  message("RoB: using existing CSVs if available.")
  rob_quips  <- safe_read_csv0(quips_path)
  rob_quadas <- safe_read_csv0(quadas_path)

  if (is.null(rob_quips))  message("• Missing QUIPS: ", quips_path)
  if (is.null(rob_quadas)) message("• Missing QUADAS2: ", quadas_path)
} else {
  dir.create(rob_dir, recursive = TRUE, showWarnings = FALSE)
  if (!overwrite && file.exists(quips_path) && file.exists(quadas_path)) {
    message("RoB CSVs already exist; not overwriting. Set options(ROB_OVERWRITE=TRUE) or env ROB_OVERWRITE=1 to rebuild.")
  } else {
    message("RoB: (placeholder) Parsing not implemented in this snippet.")
  }
}

# Normalize judgments (optional helpers)
norm_quips <- function(x){
  x <- tolower(trimws(as.character(x)))
  dplyr::case_when(
    x %in% c("low","l") ~ "Low",
    x %in% c("moderate","mod","m") ~ "Moderate",
    x %in% c("high","h") ~ "High",
    TRUE ~ NA_character_
  )
}
norm_quadas <- function(x){
  x <- tolower(trimws(as.character(x)))
  dplyr::case_when(
    x %in% c("low","l") ~ "Low",
    x %in% c("some concerns","unclear","someconcerns") ~ "Some concerns",
    x %in% c("high","h") ~ "High",
    TRUE ~ NA_character_
  )
}

# Compact previews (DT in HTML)
render_compact <- function(df, caption){
  if (!is.data.frame(df) || !nrow(df)) return(invisible(NULL))
  df <- janitor::clean_names(df)
  if ("judgement" %in% names(df)) {
    df$judgement <- if ("domain" %in% names(df)) {
      if (grepl("quips", caption, TRUE)) norm_quips(df$judgement) else norm_quadas(df$judgement)
    } else df$judgement
  }
  if (knitr::is_html_output() && requireNamespace("DT", quietly = TRUE)) {
    DT::datatable(
      utils::head(df, 20),
      caption = htmltools::tags$caption(style = "caption-side: top; text-align: left;", caption),
      class = "compact stripe hover",
      extensions = c("Scroller","Buttons"),
      options = list(
        dom = "Bfrtip", buttons = c("copy","csv","excel"),
        deferRender = TRUE, scrollX = TRUE, scrollY = 260, scroller = TRUE,
        paging = TRUE, pageLength = 10, lengthMenu = c(10,25,50,100),
        info = FALSE, ordering = TRUE, autoWidth = TRUE
      ),
      rownames = FALSE
    )
  } else {
    print(knitr::kable(utils::head(df, 20), caption = caption))
  }
}

render_compact(rob_quips,  "QUIPS (preview)")
render_compact(rob_quadas, "QUADAS-2 (preview)")

```



#QUIPS / QUADAS-2: setup, templates, and import

```{r rob-setup, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
rob_dir <- here::here("data","rob")
dir.create(rob_dir, recursive = TRUE, showWarnings = FALSE)

# Optional: import externally supplied RoB CSVs if present
rob_ext <- Sys.getenv("ROB_EXT_DIR", unset = "/mnt/data")
q_ext <- file.path(rob_ext, "QUIPS.csv")
d_ext <- file.path(rob_ext, "QUADAS2.csv")
if (file.exists(q_ext) && !file.exists(file.path(rob_dir, "QUIPS.csv"))) {
  file.copy(q_ext, file.path(rob_dir, "QUIPS.csv"), overwrite = TRUE)
}
if (file.exists(d_ext) && !file.exists(file.path(rob_dir, "QUADAS2.csv"))) {
  file.copy(d_ext, file.path(rob_dir, "QUADAS2.csv"), overwrite = TRUE)
}

if (!requireNamespace("robvis", quietly = TRUE)) {
  message("robvis not installed; using fallback traffic-light plots.")
}

quips_path  <- here::here("data","rob","QUIPS.csv")
quadas_path <- here::here("data","rob","QUADAS2.csv")

read_csv_safe <- if (exists("safe_read_csv")) safe_read_csv else function(p)
  readr::read_csv(p, show_col_types = FALSE, locale = readr::locale(encoding = "UTF-8"))

quips_raw  <- if (file.exists(quips_path))  read_csv_safe(quips_path)  else tibble::tibble()
quadas_raw <- if (file.exists(quadas_path)) read_csv_safe(quadas_path) else tibble::tibble()

quips  <- janitor::clean_names(quips_raw)
quadas <- janitor::clean_names(quadas_raw)

# Ensure required columns exist (tolerate empty/new files)
need_cols <- c("study_id","domain","judgement","notes")
for (nm in setdiff(need_cols, names(quips)))  quips[[nm]]  <- NA
for (nm in setdiff(need_cols, names(quadas))) quadas[[nm]] <- NA
quips  <- dplyr::select(quips,  dplyr::all_of(need_cols))
quadas <- dplyr::select(quadas, dplyr::all_of(need_cols))

# Normalize IDs
normalize_id <- function(x){
  x <- stringr::str_squish(as.character(x))
  stringr::str_replace_all(x, fixed("Zagmani"), "Zamagni")
}
quips$study_id  <- normalize_id(quips$study_id)
quadas$study_id <- normalize_id(quadas$study_id)

if (!nrow(quips))  knitr::asis_output("<em>No QUIPS entries found. Fill data/rob/QUIPS.csv.</em>")
if (!nrow(quadas)) knitr::asis_output("<em>No QUADAS-2 entries found. Fill data/rob/QUADAS2.csv.</em>")

# Harmonize judgement casing/variants
norm_j <- function(x){
  x <- tolower(trimws(as.character(x)))
  x <- dplyr::recode(
    x,
    "low" = "Low",
    "moderate" = "Moderate",
    "mod" = "Moderate",
    "some concerns" = "Some concerns",
    "some concern" = "Some concerns",
    "unclear" = "Some concerns",
    "high" = "High",
    .default = stringr::str_to_title(x)
  )
  x
}
quips$judgement  <- norm_j(quips$judgement)
quadas$judgement <- norm_j(quadas$judgement)

# Overall judgements
rob_quips_overall <- quips %>%
  dplyr::filter(!is.na(study_id), nzchar(study_id), !is.na(judgement), nzchar(judgement)) %>%
  dplyr::group_by(study_id) %>%
  dplyr::summarise(
    quips_overall = dplyr::case_when(
      any(judgement == "High") ~ "High",
      any(judgement == "Moderate") ~ "Moderate",
      dplyr::n() > 0 ~ "Low",
      TRUE ~ NA_character_
    ),
    .groups = "drop"
  )

rob_quadas_overall <- quadas %>%
  dplyr::filter(!is.na(study_id), nzchar(study_id), !is.na(judgement), nzchar(judgement)) %>%
  dplyr::group_by(study_id) %>%
  dplyr::summarise(
    quadas_overall = dplyr::case_when(
      any(judgement == "High") ~ "High",
      any(judgement == "Some concerns") ~ "Some concerns",
      dplyr::n() > 0 ~ "Low",
      TRUE ~ NA_character_
    ),
    .groups = "drop"
  )

# Join to analysis datasets (guarded)
if (exists("conc") && is.data.frame(rob_quadas_overall) && nrow(rob_quadas_overall)) {
  conc <- dplyr::left_join(conc, rob_quadas_overall, by = "study_id")
}
if (exists("surv_df") && is.data.frame(rob_quips_overall) && nrow(rob_quips_overall)) {
  # NOTE: surv_df$Study may not exactly match study_id; if many NAs appear, map IDs upstream.
  surv_df <- dplyr::left_join(surv_df, dplyr::rename(rob_quips_overall, Study = study_id), by = "Study")
}

# Previews
if (exists("show_table")) {
  if (nrow(quips))  print(show_table(utils::head(quips,  10), "QUIPS entries (preview)"))
  if (nrow(quadas)) print(show_table(utils::head(quadas, 10), "QUADAS-2 entries (preview)"))
  if (nrow(rob_quips_overall))  print(show_table(rob_quips_overall,  "QUIPS overall by study (computed)"))
  if (nrow(rob_quadas_overall)) print(show_table(rob_quadas_overall, "QUADAS-2 overall by study (computed)"))
} else {
  if (nrow(quips))  print(knitr::kable(utils::head(quips,10),  caption="QUIPS entries (preview)"))
  if (nrow(quadas)) print(knitr::kable(utils::head(quadas,10), caption="QUADAS-2 entries (preview)"))
  if (nrow(rob_quips_overall))  print(knitr::kable(rob_quips_overall,  caption="QUIPS overall by study (computed)"))
  if (nrow(rob_quadas_overall)) print(knitr::kable(rob_quadas_overall, caption="QUADAS-2 overall by study (computed)"))
}

```



# Traffic-light plots (QUIPS & QUADAS-2) + domain summaries

```{r rob-visuals, echo=FALSE, message=FALSE, results='asis'}
`%||%` <- function(x, y) if (is.null(x) || !length(x) || (length(x)==1 && is.na(x))) y else x

rob_cols_quips   <- rob_cols_quips   %||% c("Low"="#6CC24A","Moderate"="#F9C74F","High"="#F94144", "Not applicable" = "#bdbdbd" )
rob_cols_quadas2 <- rob_cols_quadas2 %||% c("Low"="#6CC24A","Some concerns"="#F9C74F","High"="#F94144", "Not applicable" = "#bdbdbd")
rob_lv_quips     <- c("Low","Moderate","High")
rob_lv_quadas2   <- c("Low","Some concerns","High")

# ---------- Domain distribution (stacked %) ----------
plot_domain_dist <- function(df, title) {
  if (!is.data.frame(df) || !nrow(df)) return(NULL)
  df2 <- df %>%
    dplyr::mutate(
      judgement = dplyr::recode(stringr::str_to_title(as.character(judgement)),
                                 "Some Concerns"="Some concerns"),
      domain    = as.character(domain)
    ) %>%
    dplyr::count(domain, judgement)

  ggplot2::ggplot(df2, ggplot2::aes(x = domain, y = n, fill = judgement)) +
    ggplot2::geom_col(position = "fill") +
    ggplot2::scale_y_continuous(labels = scales::label_percent()) +
    ggplot2::labs(title = title, x = NULL, y = "Percent") +
    ggplot2::coord_flip() +
    ggplot2::theme_minimal(base_size = 12)
}

g1 <- plot_domain_dist(quips,  "QUIPS domain distribution")
g2 <- plot_domain_dist(quadas, "QUADAS-2 domain distribution")
if (!is.null(g1)) ggplot2::ggsave(here::here("figs","Supplementary_Figure_QUIPS_Domains.png"),   g1, width=7, height=4, dpi=300)
if (!is.null(g2)) ggplot2::ggsave(here::here("figs","Supplementary_Figure_QUADAS2_Domains.png"), g2, width=7, height=4, dpi=300)

# ---------- Traffic-light: robvis preferred; heatmap fallback ----------
make_tl <- function(df, out_png, tool = c("QUIPS","QUADAS-2")) {
  tool <- match.arg(tool)
  if (!is.data.frame(df) || !nrow(df)) return(invisible(NULL))

  # Fallback heatmap
  fallback_plot <- function(df_long, title) {
    lv <- if (tool == "QUIPS") rob_lv_quips else rob_lv_quadas2
    dd <- df_long %>%
      dplyr::mutate(
        study_id = as.character(study_id),
        domain   = as.character(domain),
        jj = factor(dplyr::recode(stringr::str_to_title(as.character(judgement)),
                                  "Some Concerns"="Some concerns"), levels = lv)
      ) %>%
      tidyr::pivot_wider(names_from = domain, values_from = jj) %>%
      tidyr::pivot_longer(-study_id, names_to = "domain", values_to = "jj")
    ggplot2::ggplot(dd, ggplot2::aes(x = domain, y = study_id, fill = jj)) +
      ggplot2::geom_tile(color = "white") +
      ggplot2::scale_fill_manual(values = if (tool=="QUIPS") rob_cols_quips else rob_cols_quadas2,
                                 drop = FALSE, na.value = "grey90") +
      ggplot2::labs(title = title, x = NULL, y = NULL, fill = NULL) +
      ggplot2::theme_minimal(base_size = 11) +
      ggplot2::coord_equal()
  }

  # Try robvis first
  if (requireNamespace("robvis", quietly = TRUE)) {
    df0 <- df %>%
      dplyr::mutate(
        Study  = as.character(study_id),
        Domain = as.character(domain),
        Judge  = dplyr::recode(stringr::str_to_title(as.character(judgement)),
                               "Some Concerns"="Some concerns")
      )
    p <- NULL
    if (tool == "QUADAS-2") {
      prep <- df0 %>%
        dplyr::filter(!is.na(Judge), nzchar(Judge)) %>%
        dplyr::group_by(Study, Domain) %>%
        dplyr::summarise(Judgement = dplyr::case_when(
          any(Judge == "High") ~ "High",
          any(Judge == "Some concerns") ~ "Some concerns",
          any(Judge == "Low") ~ "Low",
          TRUE ~ NA_character_
        ), .groups = "drop") %>%
        tidyr::pivot_wider(names_from = Domain, values_from = Judgement)
      p <- try(robvis::rob_traffic_light(prep, tool = "QUADAS-2"), silent = TRUE)
    } else {
      first_non_na <- function(x) { x <- as.character(stats::na.omit(x)); if (length(x)) x[1] else NA_character_ }
      prep <- df0 %>%
        dplyr::filter(!is.na(Judge), nzchar(Judge)) %>%
        dplyr::group_by(Study, Domain) %>%
        dplyr::summarise(Judgement = first_non_na(Judge), .groups = "drop") %>%
        tidyr::pivot_wider(names_from = Domain, values_from = Judgement)
      p <- try(robvis::rob_traffic_light(prep, tool = "QUIPS"), silent = TRUE)
    }
    if (inherits(p, "ggplot")) {
      ggplot2::ggsave(out_png, p, width=8.5, height=max(4, 0.35*length(unique(df$study_id))), dpi=300)
      return(show_png("figs", basename(out_png)))
    }
  }

  # Fallback
  title <- if (tool == "QUIPS") "QUIPS risk-of-bias (traffic-light)" else "Adapted QUADAS-2 risk-of-bias (traffic-light)"
  p_fb <- fallback_plot(df, title)
  ggplot2::ggsave(out_png, p_fb, width=9, height=max(4, 0.35*length(unique(df$study_id))), dpi=300)
  show_png("figs", basename(out_png))
  invisible(NULL)
}

# Callers
if (exists("quips")  && is.data.frame(quips)  && nrow(quips))  make_tl(quips,  here::here("figs","Supplementary_Figure_QUIPS_Traffic.png"),  tool = "QUIPS")
if (exists("quadas") && is.data.frame(quadas) && nrow(quadas)) make_tl(quadas, here::here("figs","Supplementary_Figure_QUADAS2_Traffic.png"), tool = "QUADAS-2")

```

```{r ensure-quadas2-overall, echo=FALSE}
# 1) Normalize helper
norm_id <- function(x){
  x <- as.character(x)
  x <- stringr::str_squish(x)
  x
}

# Bail out quietly if concordance frame isn't present yet
if (!exists("conc") || !is.data.frame(conc)) {
  conc <- tibble::tibble()
}

# 2) If overall not already present, build it from `quadas`
if (!"QUADAS2_overall" %in% names(conc)) {
  if (exists("quadas") && is.data.frame(quadas) && nrow(quadas)) {
    ql <- quadas %>%
      dplyr::mutate(
        study_id  = norm_id(study_id),
        domain    = as.character(domain),
        judgement = stringr::str_to_title(as.character(judgement)),
        judgement = dplyr::recode(judgement, "Some Concerns" = "Some concerns")
      ) %>%
      dplyr::filter(!is.na(study_id), nzchar(study_id),
                    !is.na(domain), !is.na(judgement))

    # Worst-of rule across domains: High > Some concerns > Low
    quadas_overall <- ql %>%
      dplyr::group_by(study_id) %>%
      dplyr::summarise(
        QUADAS2_overall = dplyr::case_when(
          any(judgement == "High") ~ "High",
          any(judgement == "Some concerns") ~ "Some concerns",
          dplyr::n() > 0 ~ "Low",
          TRUE ~ NA_character_
        ),
        .groups = "drop"
      )

    # 3) Merge into `conc` with normalized IDs on both sides
    if (nrow(conc)) {
      conc <- conc %>%
        dplyr::mutate(study_id = norm_id(study_id)) %>%
        dplyr::left_join(quadas_overall, by = "study_id")
    } else {
      # If conc is empty, create it minimally so downstream can still use the column
      conc <- quadas_overall
    }
  }
}

# 4) Ensure the column exists (character) so downstream code won’t complain
if ("QUADAS2_overall" %in% names(conc)) {
  conc$QUADAS2_overall <- factor(conc$QUADAS2_overall,
                                 levels = c("Low","Some concerns","High"),
                                 ordered = TRUE)
}


```



# Concordance (QUADAS-2): annotate plots and do sensitivity

```{r rob-concordance-integration, echo=FALSE, message=FALSE}
# --- Guard: need conc + a RoB column ---
if (exists("conc") && is.data.frame(conc) && nrow(conc)) {

  # Find any QUADAS-2 overall column, case-insensitive
  nm_lc <- tolower(names(conc))
  cand  <- c("quadas_overall","quadas2_overall","quadas2_overall_judgement","quadas2_overall_judgment")
  hit   <- which(nm_lc %in% cand)
  robvar <- if (length(hit)) names(conc)[hit[1]] else NA_character_

  if (!is.na(robvar)) {
    lab <- tolower(trimws(as.character(conc[[robvar]])))
    lab <- dplyr::case_when(
      lab %in% c("low","l")  ~ "Low",
      lab %in% c("high","h") ~ "High",
      lab %in% c("some concerns","someconcerns","sc","some","concerns","unclear") ~ "Some concerns",
      TRUE ~ NA_character_
    )
    conc$QUADAS2_overall <- factor(lab, levels = c("Low","Some concerns","High"))

    # ---- Build pooled_kappa if missing (use IV-weighted; names must be estimate/ci_l/ci_u) ----
    if (!exists("pooled_kappa") && all(c("Kappa","SE") %in% names(conc))) {
      w <- 1 / (conc$SE^2); w[!is.finite(w)] <- NA
      if (sum(is.finite(w)) > 0) {
        k_hat <- stats::weighted.mean(conc$Kappa, w, na.rm = TRUE)
        se_hat <- sqrt(1 / sum(w, na.rm = TRUE))
        pooled_kappa <- list(
          estimate = k_hat,
          ci_l = max(-1, k_hat - 1.96*se_hat),
          ci_u = min( 1, k_hat + 1.96*se_hat)
        )
      }
    }

    # ---- Base forest (your pretty function returns a ggplot and saves a PNG) ----
    p_base <- if (exists("fig_concordance_forest_pretty")) {
      try(fig_concordance_forest_pretty(conc, pooled_kappa), silent = TRUE)
    } else NULL

    if (inherits(p_base, "ggplot")) {
      # Overlay shape layer mapped to RoB (keeps your CI bars/lines from the base)
      p2a_rob <- p_base +
  ggplot2::geom_point(
    data = dplyr::filter(conc, !is.na(QUADAS2_overall)),
    ggplot2::aes(x = Kappa, y = reorder(study_id, Kappa), shape = QUADAS2_overall),
    size = 2.6, stroke = 0.2, inherit.aes = FALSE
  ) +
  ggplot2::scale_shape_manual(
    name = "QUADAS-2 overall",
    values = c(`Low`=16, `Some concerns`=17, `High`=15), drop = FALSE
  ) +
  ggplot2::theme(
    legend.position = "bottom",
    legend.direction = "horizontal",
    legend.box.margin = ggplot2::margin(t=0),
    legend.title = ggplot2::element_text(size = 9),
    legend.text  = ggplot2::element_text(size = 9)
  )

      out <- here::here("figs","Figure_2A_Concordance_Forest_RoB.png")
      ggplot2::ggsave(out, p2a_rob, width = 7, height = 5, dpi = 600, bg = "white")
    } else {
      knitr::asis_output("*Could not layer shapes: base forest did not return a ggplot object.*\n")
    }

    # ---- Sensitivity: exclude QUADAS-2 High and refit pooled κ (IV-weighted) ----
    keep <- conc %>% dplyr::filter(is.na(QUADAS2_overall) | QUADAS2_overall != "High")
    if (nrow(keep) >= 2 && all(c("Kappa","SE") %in% names(keep))) {
      w <- 1 / (keep$SE^2); w[!is.finite(w)] <- NA
      if (sum(is.finite(w)) > 0) {
        kappahat <- stats::weighted.mean(keep$Kappa, w, na.rm = TRUE)
        se_hat   <- sqrt(1 / sum(w, na.rm = TRUE))
        ci_hat   <- kappahat + c(-1.96, 1.96) * se_hat
        cat(sprintf("Sensitivity (exclude QUADAS-2 High): κ = %.3f (%.3f–%.3f)\n",
                    kappahat, max(-1, ci_hat[1]), min(1, ci_hat[2])))
      }
    }
  } else {
    cat("*QUADAS-2 overall column not found in `conc`.*\n")
  }
} else {
  cat("*QUADAS-2 not available or concordance inputs missing.*\n")
}

```

# Risk of Bias

```{r rob-analyses, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
# Risk of Bias: QUIPS & QUADAS2
dir.create(here::here("figs"), showWarnings = FALSE, recursive = TRUE)

levels_quips   <- c("Low","Moderate","High")
levels_quadas2 <- c("Low","Some concerns","High")

std_judgement <- function(x, type = c("quips","quadas2")){
  type <- match.arg(type)
  x <- tolower(trimws(as.character(x)))
  x <- gsub("[^a-z ]+","",x)
  if (type == "quips") {
    dplyr::case_when(
      x %in% c("low","l") ~ "Low",
      x %in% c("moderate","mod","m") ~ "Moderate",
      x %in% c("high","h") ~ "High",
      TRUE ~ NA_character_
    )
  } else {
    dplyr::case_when(
      x %in% c("low","l") ~ "Low",
      x %in% c("high","h") ~ "High",
      x %in% c("some concerns","someconcerns","some","concerns","unclear","u") ~ "Some concerns",
      TRUE ~ NA_character_
    )
  }
}

overall_quips <- function(df_wide) {
  doms <- setdiff(names(df_wide), "study_id")
  if (!length(doms)) return(tibble::tibble(study_id=df_wide$study_id, QUIPS_overall=NA_character_))
  mat <- as.matrix(dplyr::mutate(df_wide[doms], dplyr::across(everything(), as.character)))
  any_high <- apply(mat == "High", 1, any, na.rm = TRUE)
  any_mod  <- apply(mat == "Moderate", 1, any, na.rm = TRUE)
  overall  <- ifelse(any_high, "High", ifelse(any_mod, "Moderate", "Low"))
  tibble::tibble(study_id = df_wide$study_id, QUIPS_overall = overall)
}
overall_quadas2 <- function(df_wide) {
  doms <- setdiff(names(df_wide), "study_id")
  if (!length(doms)) return(tibble::tibble(study_id=df_wide$study_id, QUADAS2_overall=NA_character_))
  mat <- as.matrix(dplyr::mutate(df_wide[doms], dplyr::across(everything(), as.character)))
  any_high <- apply(mat == "High", 1, any, na.rm = TRUE)
  any_sc   <- apply(mat == "Some concerns", 1, any, na.rm = TRUE)
  overall  <- ifelse(any_high, "High", ifelse(any_sc, "Some concerns", "Low"))
  tibble::tibble(study_id = df_wide$study_id, QUADAS2_overall = overall)
}

plot_rob_bars <- function(df_long, title, out_file, levels_use, cols_use){
  if (!nrow(df_long)) return(invisible(NULL))
  df_long$judgement <- factor(df_long$judgement, levels = levels_use)
  p <- ggplot2::ggplot(df_long, ggplot2::aes(x = domain, y = ..prop.., fill = judgement)) +
    ggplot2::geom_bar(position = "fill") +
    ggplot2::coord_flip() +
    ggplot2::scale_y_continuous(labels = scales::percent) +
    ggplot2::scale_fill_manual(values = cols_use, drop = FALSE) +
    ggplot2::labs(x = NULL, y = "Proportion of studies", title = title, fill = NULL) +
    ggplot2::theme_minimal(base_size = 11) +
    ggplot2::theme(
      legend.position = "bottom",
      legend.direction = "horizontal",
      legend.box.margin = ggplot2::margin(t=0),
      legend.text = ggplot2::element_text(size = 9)
    )
  ggplot2::ggsave(out_file, p, width = 7.5, height = 4.8, dpi = 600, bg = "white")
  show_png("figs", basename(out_file))
}

plot_traffic <- function(df_long, title, out_file, levels_use, cols_use){
  if (!nrow(df_long)) return(invisible(NULL))
  df_long$judgement <- factor(df_long$judgement, levels = levels_use)
  ord_study <- sort(unique(df_long$study_id))
  ord_dom   <- unique(df_long$domain)
  height_in <- max(4.0, 0.28*length(ord_study) + 1.5)
  p <- ggplot2::ggplot(
        df_long,
        ggplot2::aes(x = factor(domain, levels = ord_dom),
                     y = factor(study_id, levels = ord_study),
                     fill = judgement)
      ) +
      ggplot2::geom_tile(color = "#eeeeee") +
      ggplot2::scale_fill_manual(values = cols_use, drop = FALSE) +
      ggplot2::labs(x = NULL, y = NULL, title = title, fill = NULL) +
      ggplot2::theme_minimal(base_size = 11) +
      ggplot2::theme(
        axis.text.x = ggplot2::element_text(angle = 45, hjust = 1),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.box.margin = ggplot2::margin(t=0),
        legend.text = ggplot2::element_text(size = 9)
      )
  ggplot2::ggsave(out_file, p, width = 7.8, height = height_in, dpi = 600, bg = "white")
  show_png("figs", basename(out_file))
}

# ---- Ingest (or safe empties) ----
quips_long  <- if (exists("quips")  && is.data.frame(quips)  && nrow(quips)) {
  quips %>% dplyr::mutate(judgement = factor(std_judgement(judgement,"quips"),   levels = levels_quips))
} else tibble::tibble(study_id=character(), domain=character(), judgement=factor(character(), levels = levels_quips), notes=character())

quadas_long <- if (exists("quadas") && is.data.frame(quadas) && nrow(quadas)) {
  quadas %>% dplyr::mutate(judgement = factor(std_judgement(judgement,"quadas2"), levels = levels_quadas2))
} else tibble::tibble(study_id=character(), domain=character(), judgement=factor(character(), levels = levels_quadas2), notes=character())

# ---- WIDE & overall ----
first_non_na <- function(z){ z <- as.character(stats::na.omit(z)); if (length(z)) z[1] else NA_character_ }

quips_wide <- if (nrow(quips_long)) {
  quips_long %>% dplyr::select(study_id, domain, judgement) %>%
    tidyr::pivot_wider(names_from = domain, values_from = judgement,
                       values_fn = ~ first_non_na(.x), values_fill = NA)
} else tibble::tibble()

quadas_wide <- if (nrow(quadas_long)) {
  quadas_long %>% dplyr::select(study_id, domain, judgement) %>%
    tidyr::pivot_wider(names_from = domain, values_from = judgement,
                       values_fn = ~ first_non_na(.x), values_fill = NA)
} else tibble::tibble()

quips_overall  <- if (nrow(quips_wide))  overall_quips(quips_wide)    else tibble::tibble(study_id=character(), QUIPS_overall=character())
quadas_overall <- if (nrow(quadas_wide)) overall_quadas2(quadas_wide) else tibble::tibble(study_id=character(), QUADAS2_overall=character())

# ---- Plots ----
plot_rob_bars(quips_long,  "QUIPS risk of bias (domain proportions)",
              here::here("figs","QUIPS_RoB_Bar.png"),   levels_quips,   rob_cols_quips)
plot_traffic(quips_long,   "QUIPS traffic-light by domain/study",
              here::here("figs","QUIPS_RoB_Traffic.png"), levels_quips, rob_cols_quips)

plot_rob_bars(quadas_long, "Adapted QUADAS-2 risk of bias (domain proportions)",
              here::here("figs","QUADAS2_RoB_Bar.png"),  levels_quadas2, rob_cols_quadas2)
plot_traffic(quadas_long,  "Adapted QUADAS-2 traffic-light by domain/study",
              here::here("figs","QUADAS2_RoB_Traffic.png"), levels_quadas2, rob_cols_quadas2)

if (exists("make_tl")) make_tl(quips,  here::here("figs","Supplementary_Figure_QUIPS_Traffic.png"),  tool="QUIPS")
if (exists("make_tl")) make_tl(quadas, here::here("figs","Supplementary_Figure_QUADAS2_Traffic.png"), tool="QUADAS-2")


# ---- Previews (only if objects exist) ----
if (exists("quips")  && is.data.frame(quips)  && nrow(quips) ) { if (exists("make_tl")) print(make_tl(quips,  here::here("figs","Supplementary_Figure_QUIPS_Traffic.png"),  tool="QUIPS")) }
if (exists("quadas") && is.data.frame(quadas) && nrow(quadas)) { if (exists("make_tl")) print(make_tl(quadas, here::here("figs","Supplementary_Figure_QUADAS2_Traffic.png"), tool="QUADAS-2")) }

# ---- Analyses using RoB ----
read_rob_sheet <- function(sheet, fallback_glob) {
  st4 <- here::here("tables","Supplementary_Table_ST4_Methods_Checklists.xlsx")
  if (file.exists(st4)) {
    x <- tryCatch(readxl::read_xlsx(st4, sheet = sheet), error = function(e) NULL)
    if (is.data.frame(x)) return(janitor::clean_names(x))
  }
  candidates <- c(
    list.files(here::here("data"),      pattern = glob2rx(fallback_glob), full.names = TRUE, ignore.case = TRUE),
    list.files(here::here("data","rob"),pattern = glob2rx(fallback_glob), full.names = TRUE, ignore.case = TRUE)
  )
  for (f in unique(candidates)) {
    x <- tryCatch({
      if (grepl("\\.csv$", f, TRUE)) readr::read_csv(f, show_col_types = FALSE) else readxl::read_xlsx(f)
    }, error = function(e) NULL)
    if (is.data.frame(x)) return(janitor::clean_names(x))
  }
  NULL
}

n_levels <- function(x) length(unique(stats::na.omit(as.character(x))))

## 4A) QUIPS → HR meta by overall RoB (or pooled if QUIPS missing)
if (exists("surv_df") && is.data.frame(surv_df) && nrow(surv_df)) {
  surv_q <- surv_df
  if (nrow(quips_overall)) {
    surv_q <- surv_q %>%
      dplyr::left_join(dplyr::transmute(quips_overall, Study = as.character(study_id), QUIPS_overall),
                       by = "Study")
  } else {
    surv_q$QUIPS_overall <- NA_character_
  }

  idx <- is.finite(surv_q$logHR) & is.finite(surv_q$SE)
  if (sum(idx) >= 2) {
    pooled_hr <- metafor::rma(yi = surv_q$logHR[idx], sei = surv_q$SE[idx],
                              method = "REML", test = "knha")
    knitr::asis_output(sprintf(
      "Pooled HR (REML, KnHa): %.3f (%.3f–%.3f); I² = %.0f%%.",
      exp(as.numeric(pooled_hr$b)), exp(pooled_hr$ci.lb), exp(pooled_hr$ci.ub), pooled_hr$I2))
  }

  if (sum(!is.na(surv_q$QUIPS_overall[idx])) >= 2 && n_levels(surv_q$QUIPS_overall[idx]) >= 2) {
    m_by <- meta::metagen(TE = surv_q$logHR[idx], seTE = surv_q$SE[idx],
                          studlab = surv_q$Study[idx], sm = "HR",
                          method.tau = "REML", random = TRUE, common = FALSE,
                          byvar = surv_q$QUIPS_overall[idx], hakn = TRUE)
    knitr::asis_output("**QUIPS-stratified pooled HRs (REML, KnHa):**")
    print(summary(m_by), digits = 3)

    keep <- idx & !is.na(surv_q$QUIPS_overall) & surv_q$QUIPS_overall != "High"
    if (sum(keep) >= 2) {
      m_sens <- metafor::rma(yi = surv_q$logHR[keep], sei = surv_q$SE[keep],
                             method = "REML", test = "knha")
      knitr::asis_output(sprintf(
        "Sensitivity (exclude QUIPS High): HR %.3f (%.3f–%.3f), I² = %.0f%%.",
        exp(as.numeric(m_sens$b)), exp(m_sens$ci.lb), exp(m_sens$ci.ub), m_sens$I2))
    }
  } else {
    knitr::asis_output("*QUIPS overall unavailable or only one level → subgroup meta skipped.*")
  }
}

## 4B) κ vs QUADAS-2 (meta-reg only if QUADAS2_overall usable)
if (exists("conc") && is.data.frame(conc) && nrow(conc)) {
  conc_q <- conc
  if (nrow(quadas_overall)) {
    conc_q <- conc_q %>%
      dplyr::left_join(quadas_overall, by = "study_id")
  } else {
    conc_q$QUADAS2_overall <- NA_character_
  }

  idxk <- is.finite(conc_q$Kappa) & is.finite(conc_q$SE)
  if (sum(idxk) >= 2) {
    pooled_k <- metafor::rma(yi = conc_q$Kappa[idxk], sei = conc_q$SE[idxk],
                             method = "REML", test = "knha")
    knitr::asis_output(sprintf(
      "Pooled κ (REML, KnHa): %.3f (%.3f–%.3f); I² = %.0f%%.",
      as.numeric(pooled_k$b), as.numeric(pooled_k$ci.lb), as.numeric(pooled_k$ci.ub), pooled_k$I2))
  }

  ok_mod_k <- sum(idxk & !is.na(conc_q$QUADAS2_overall)) >= 2 &&
              n_levels(conc_q$QUADAS2_overall[idxk]) >= 2
  if (ok_mod_k) {
    hi <- ifelse(conc_q$QUADAS2_overall[idxk] == "High", 1, 0)
    fit_k <- metafor::rma(yi = conc_q$Kappa[idxk], sei = conc_q$SE[idxk],
                          mods = ~ hi, method = "REML", test = "knha")
    knitr::asis_output(sprintf(
      "**κ meta-reg vs QUADAS-2 (High vs other):** β = %.3f (p = %.3f).",
      as.numeric(fit_k$b[2]), as.numeric(fit_k$pval[2])
    ))
  } else {
    knitr::asis_output("*QUADAS-2 overall unavailable or only one level → κ meta-reg skipped.*")
  }

  # Directional discordance (log-odds)
  dd <- conc_q
  if (!("logOR" %in% names(dd)) && all(c("a","c") %in% names(dd))) {
    dd$logOR    <- with(dd, log((as.numeric(a)+0.5)/(as.numeric(c)+0.5)))
    dd$se_logOR <- with(dd, sqrt(1/(as.numeric(a)+0.5) + 1/(as.numeric(c)+0.5)))
  }
  idxd <- is.finite(dd$logOR) & is.finite(dd$se_logOR)

  if (sum(idxd) >= 2) {
    pooled_or <- metafor::rma(yi = dd$logOR[idxd], sei = dd$se_logOR[idxd],
                              method = "REML", test = "knha")
    knitr::asis_output(sprintf(
      "Pooled log-odds (MRD−/PET+ vs MRD+/PET−): %.2f (%.2f–%.2f); I² = %.0f%%.",
      as.numeric(pooled_or$b), as.numeric(pooled_or$ci.lb), as.numeric(pooled_or$ci.ub), pooled_or$I2))

    ok_mod_or <- sum(idxd & !is.na(dd$QUADAS2_overall)) >= 2 &&
                 n_levels(dd$QUADAS2_overall[idxd]) >= 2
    if (ok_mod_or) {
      hi <- ifelse(dd$QUADAS2_overall[idxd] == "High", 1, 0)
      fit_or <- metafor::rma(yi = dd$logOR[idxd], sei = dd$se_logOR[idxd],
                             mods = ~ hi, method = "REML", test = "knha")
      knitr::asis_output(sprintf(
        "**Directional discordance vs QUADAS-2:** β(High) = %.2f, p = %.3f.",
        as.numeric(fit_or$b[2]), as.numeric(fit_or$pval[2])
      ))
    } else {
      knitr::asis_output("*QUADAS-2 overall unavailable or only one level → discordance meta-reg skipped.*")
    }

    keep <- idxd & !is.na(dd$QUADAS2_overall) & dd$QUADAS2_overall != "High"
    if (sum(keep) >= 2) {
      sens_or <- metafor::rma(yi = dd$logOR[keep], sei = dd$se_logOR[keep],
                              method = "REML", test = "knha")
      knitr::asis_output(sprintf(
        "Sensitivity (exclude QUADAS-2 High): pooled log-odds = %.2f (%.2f–%.2f).",
        as.numeric(sens_or$b), as.numeric(sens_or$ci.lb), as.numeric(sens_or$ci.ub)))
    }
  } else {
    knitr::asis_output("*Directional discordance meta skipped: <2 usable studies.*")
  }
}

```

# Supplementary Tables ST3 - ST4

## Table 3 - Subgroup outcomes (as reported)

```{r st3-st4, echo=FALSE}
dir.create(here::here("tables"), showWarnings = FALSE, recursive = TRUE)

# helpers (unchanged)
flatten_df <- function(df) {
  if (!is.data.frame(df) || !ncol(df)) return(df)
  df %>% dplyr::mutate(dplyr::across(where(is.list), ~ vapply(.x, function(z) {
    if (length(z) == 0 || (length(z) == 1 && is.na(z))) return(NA_character_)
    paste0(z, collapse = "; ")
  }, character(1))))
}
round_df3 <- function(df) { df <- flatten_df(df); if (is.data.frame(df)) dplyr::mutate(df, dplyr::across(where(is.numeric), ~round(., 2))) else df }
sanitize_sheet_names <- function(x){ nm <- names(x); nm <- gsub('[:\\\\/?*\\[\\]]', "_", nm); nm <- substr(nm, 1, 31); names(x) <- nm; x }

# ensure required objects exist (unchanged bits condensed)
if (!exists("surv_df")) surv_df <- tibble::tibble()
if (!exists("conc") && exists("conc_aug")) conc <- conc_aug
if (!exists("conc")) conc <- tibble::tibble()
for (nm in c("quips","quadas")) if (!exists(nm) || !is.data.frame(get(nm))) assign(nm, tibble::tibble(study_id=character(), domain=character(), judgement=character(), notes=character()))
for (nm in c("rob_quips_overall","rob_quadas_overall")) if (!exists(nm)) assign(nm, tibble::tibble(study_id=character(), val=character()))
if (!exists("PRISMA_OVERRIDE")) PRISMA_OVERRIDE <- list(identified=NA, duplicates=NA, auto_excluded=NA, screened=NA, excl_title_abs=NA, sought=NA, not_retrieved=NA, full_text=NA, excl_full_text=NA, included=NA)

# ST3 sheets
conc_for_sheet <- if (exists("conc_aug") && is.data.frame(conc_aug)) conc_aug else conc
sheets3 <- list(
  "Survival_Inputs"      = round_df3(surv_df),
  "Concordance_PerStudy" = round_df3(conc_for_sheet)
)
if (exists("loo_df")        && is.data.frame(loo_df)        && nrow(loo_df))        sheets3[["LeaveOneOut"]]    <- round_df3(loo_df)
if (exists("egger_summary") && is.data.frame(egger_summary) && nrow(egger_summary)) sheets3[["Egger"]]          <- round_df3(egger_summary)
if (exists("bau_df")        && is.data.frame(bau_df)        && nrow(bau_df))        sheets3[["Baujat"]]         <- round_df3(bau_df)
if (exists("mr_tbl")        && is.data.frame(mr_tbl)        && nrow(mr_tbl))        sheets3[["MetaRegression"]] <- round_df3(mr_tbl)

# ST4 sheets
ov_quips    <- if (nrow(rob_quips_overall))  rob_quips_overall  else tibble::tibble(study_id=character(), quips_overall=character())
ov_quadas   <- if (nrow(rob_quadas_overall)) rob_quadas_overall else tibble::tibble(study_id=character(), quadas_overall=character())
rob_overall <- dplyr::full_join(ov_quips, ov_quadas, by = "study_id")


if (!exists("search_sheet")) {
  search_sheet <- tibble::tibble(
    database = c(
      "MEDLINE (via PubMed)",
      "Cochrane CENTRAL",
      "Other sources"
    ),
    notes = c(
      "See Supplementary Methods S1 for full MEDLINE strategy.",
      "See Supplementary Methods S1 for full CENTRAL strategy.",
      "Other sources / handsearching; see Supplementary Methods S2."
    )
  )
}




if (!exists("prisma_sheet")) {
  prisma_sheet <- tibble::tibble(
    identified      = PRISMA_OVERRIDE$identified,
    auto_excluded   = PRISMA_OVERRIDE$auto_excluded,
    screened        = PRISMA_OVERRIDE$screened,
    excl_title_abs  = PRISMA_OVERRIDE$excl_title_abs,
    sought          = PRISMA_OVERRIDE$sought,
    not_retrieved   = PRISMA_OVERRIDE$not_retrieved,
    full_text       = PRISMA_OVERRIDE$full_text,
    excl_full_text  = PRISMA_OVERRIDE$excl_full_text,
    included        = PRISMA_OVERRIDE$included,
    manual          = PRISMA_OVERRIDE$manual
  )
}


mrd_dict <- if (exists("mrd") && is.data.frame(mrd)) tibble::tibble(
  name = names(mrd),
  type = vapply(mrd, function(x) class(x)[1], character(1)),
  non_missing = vapply(mrd, function(x) sum(!is.na(x)), integer(1))
) else tibble::tibble(name=character(), type=character(), non_missing=integer())

sheets4 <- list(
  "Search_Strategy_Notes" = search_sheet,
  "PRISMA_2020_Counts"    = prisma_sheet,
  "Risk_of_Bias_QUIPS"    = quips,
  "Risk_of_Bias_QUADAS2"  = quadas,
  "RoB_Overall_Summary"   = rob_overall,
  "Data_Dictionary"       = mrd_dict
)

# PRISMA-2020 + PRISMA-S (unchanged metadata)
SEARCH_DATE_LAST <- "2025-04-30"
SEARCH_RANGE     <- "2015-01-01 to 2025-04-30"
DATABASES        <- c("PubMed", "Cochrane CENTRAL")
GREY_SOURCES     <- c("Reference lists of included studies", "Major MM reviews", "Conference abstracts (if extractable)")
REGISTRATION     <- "Not prospectively registered (stated in Methods)"
PROTO_LINK       <- NA_character_

prisma2020 <- tibble::tribble(
  ~Section, ~Item, ~Checklist_item, ~Where_in_manuscript,
  "TITLE", 1, "Identify the report as a systematic review/meta-analysis.", "Title; Abstract",
  "ABSTRACT", 2, "Provide a structured abstract.", "Abstract",
  "INTRODUCTION", 3, "Rationale.", "Introduction",
  "INTRODUCTION", 4, "Objectives.", "Introduction (end)",
  "METHODS", 5, "Eligibility criteria (PICO).", "Methods: Inclusion/Exclusion",
  "METHODS", 6, "Information sources (databases, dates).", "Methods: Search Strategy",
  "METHODS", 7, "Full search strategies provided.", "Supplement (PRISMA-S)",
  "METHODS", 8, "Selection process; PRISMA flow.", "Methods: Extraction/Dedup; Figure 1",
  "METHODS", 9, "Data collection process.", "Methods: Data Extraction",
  "METHODS",10, "Data items (outcomes & definitions).", "Methods: Harmonization/Estimands",
  "METHODS",11, "Risk of bias assessment.", "Methods: Risk of Bias",
  "METHODS",12, "Effect measures (κ, log-odds, HR).", "Methods",
  "METHODS",13, "Synthesis methods (REML; Knapp–Hartung).", "Methods: Statistical Analysis",
  "METHODS",14, "Reporting bias assessment.", "Methods: Small-study effects",
  "METHODS",15, "Certainty assessment (if any).", "Not undertaken (stated)",
  "RESULTS",16, "Study selection (counts; flow).", "Results; Figure 1",
  "RESULTS",17, "Study characteristics.", "Results; Table 1",
  "RESULTS",18, "Risk of bias of studies.", "Results; SF2",
  "RESULTS",19, "Results of individual studies.", "Table 2; Figure 2A/2B; Figure 3A",
  "RESULTS",20, "Results of syntheses; heterogeneity.", "Results",
  "RESULTS",21, "Reporting biases explored.", "Figure 3B; ST2",
  "RESULTS",22, "Certainty of evidence reported.", "Not graded",
  "DISCUSSION",23, "Summary of main findings.", "Discussion",
  "DISCUSSION",24, "Limitations of evidence.", "Discussion",
  "DISCUSSION",25, "Limitations of review methods.", "Discussion",
  "DISCUSSION",26, "Implications.", "Discussion",
  "OTHER",27, "Registration, protocol, funding, data availability.",
  sprintf("Registration: %s; Protocol: %s; Data/code: GitHub on publication",
          REGISTRATION, ifelse(is.na(PROTO_LINK), "N/A", PROTO_LINK))
)

search_str_pubmed <- paste0(
  '(("Multiple Myeloma"[MeSH] OR "multiple myeloma"[tiab]) AND ',
  '("Neoplasm Residual"[MeSH] OR "minimal residual disease"[tiab] OR MRD[tiab]) AND ',
  '("Positron-Emission Tomography"[MeSH] OR PET[tiab] OR "PET-CT"[tiab] OR "FDG-PET"[tiab])) AND ',
  '(2015/01/01:2025/04/30[dp])'
)
search_str_central <- '("multiple myeloma" in Title/Abstract/Keyword) AND (MRD OR "minimal residual disease") AND (PET OR "PET-CT" OR "FDG-PET") in Trials (2015–2025)'

prismaS <- tibble::tribble(
  ~Item, ~Checklist_requirement, ~Reported_value,
  1, "Databases searched", paste(DATABASES, collapse = "; "),
  2, "Date ranges covered", SEARCH_RANGE,
  3, "Date last searched", SEARCH_DATE_LAST,
  4, "Full search strategy: PubMed",  search_str_pubmed,
  5, "Full search strategy: CENTRAL", search_str_central,
  6, "Limits/filters", "Humans; adults; peer-reviewed; English (if applied—state in Methods)",
  7, "Other sources", paste(GREY_SOURCES, collapse = "; "),
  8, "Deduplication workflow", "Reference manager + rule-based family dedup; reconciliation in extraction.",
  9, "Search updates", "Single time-point search (not updated).",
  10, "PRISMA flow provided", "Yes (Figure 1).",
  11, "Information specialist involvement", "Not applicable"
)

# ---------- assemble ALL sheets into ONE workbook ----------
all_sheets <- c(sheets3, sheets4, list("PRISMA_2020" = prisma2020, "PRISMA_S" = prismaS))
all_sheets <- sanitize_sheet_names(lapply(all_sheets, round_df3))

if (requireNamespace("writexl", quietly = TRUE)) {
  master_path <- here::here("tables","Supplementary_Tables_MASTER.xlsx")
  writexl::write_xlsx(all_sheets, master_path)
} else {
  message("writexl not installed; skipping MASTER workbook.")
}

## ---- master-clean, include=FALSE
if (exists("MASTER")) {
  MASTER <- dplyr::select(MASTER, -dplyr::any_of("Search Strategy Notes"))
}

# Legacy splits (disabled –  now only use the MASTER workbook)
if (FALSE && requireNamespace("writexl", quietly = TRUE)) {
  st3_path <- here::here("tables","Supplementary_Table_ST3_Survival_and_Meta.xlsx")
  st4_path <- here::here("tables","Supplementary_Table_ST4_Methods_Checklists.xlsx")
  if (length(sheets3)) writexl::write_xlsx(sanitize_sheet_names(lapply(sheets3, round_df3)), st3_path)
  writexl::write_xlsx(sanitize_sheet_names(lapply(sheets4, round_df3)), st4_path)

  if (knitr::is_html_output()) {
    knitr::asis_output('
    <style>.dl-btn{display:inline-block;padding:.45em .8em;margin:.2em;border-radius:4px;border:1px solid #ccc;background:#f7f7f7;color:#111}.dl-btn:hover{background:#eee}</style>')
    knitr::asis_output(sprintf(
      '<p><a class="dl-btn" href="%s" download>Download MASTER (xlsx)</a></p>',
      file.path("tables", "Supplementary_Tables_MASTER.xlsx")
    ))
  }
}


```





# Conceptual diagram

```{r concept-fig-show, echo=FALSE, results='asis', fig.cap=legend_for("Figure_4_Clinical_Pathway.png"), out.width="90%"}

suppressPackageStartupMessages({
  library(ggplot2); library(tibble); library(here); library(grid)
})

# New name to avoid any shadowing from earlier versions
fig_clinical_pathway_basic2 <- function(file = "Figure_4_Clinical_Pathway.png",
                                        width = 8, height = 5, dpi = 300) {

  nodes <- tibble::tribble(
    ~x,   ~y,   ~label,                                                       ~fill,
    0.25, 0.75, "Discordant pairs\n(MRD+/PET− or MRD−/PET+)",                 "#EDEBFE",
    0.75, 0.75, "Concordant dual-negative\n(MRD−/PET−)",                      "#E7F5ED",
    0.25, 0.30, "Consider escalation / additional imaging\nor alternative therapy", "#FFF4E6",
    0.75, 0.30, "Consider de-escalation / watchful waiting",                  "#E8F7FF"
  )

  arrows <- tibble::tribble(
    ~x,   ~y,   ~xend, ~yend,
     0.25, 0.66, 0.25, 0.39,
     0.75, 0.66, 0.75, 0.39
  )

  p <- ggplot() +
    geom_label(
      data = nodes,
      aes(x = x, y = y, label = label),
      label.size = 0.6, size = 3.2, fontface = "bold",
      label.r = unit(10, "pt"),
      fill = nodes$fill, color = "#455A64",
      label.padding = unit(6, "pt")
    ) +
    geom_segment(
      data = arrows, aes(x = x, y = y, xend = xend, yend = yend),
      arrow = arrow(length = unit(7, "pt")),
      linewidth = 0.6, color = "#455A64"
    ) +
    coord_cartesian(xlim = c(0, 1), ylim = c(0, 1), expand = FALSE, clip = "off") +
    theme_void() +
    labs(title = "Figure 4. Clinical pathway (concordance vs discordance)") +
    theme(plot.margin = margin(10, 10, 10, 10),
          plot.title = element_text(hjust = 0, face = "bold"))

  dir.create(here::here("figs"), showWarnings = FALSE, recursive = TRUE)
  out <- here::here("figs", file)
  ggplot2::ggsave(filename = out, plot = p, width = width, height = height, dpi = dpi, bg = "white")
  out
}

# Generate and show
outfile <- fig_clinical_pathway_basic2()
show_png("figs", basename(outfile))

```





# Download bundle

```{r bundles, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
# Helper: readable sizes
.hsize <- function(bytes){
  if (!is.finite(bytes)) return("0 B")
  units <- c("B","KB","MB","GB"); i <- max(1, min(4, floor(log(bytes, 1024))+1))
  sprintf("%.1f %s", bytes / (1024^(i-1)), units[i])
}

# Build a neat download link with size
.make_link <- function(path_abs, label){
  if (!file.exists(path_abs)) return(NULL)
  rel <- file.path("outputs", basename(path_abs))
  sz  <- .hsize(file.info(path_abs)$size)
  sprintf('<a class="dl-btn" href="%s" download>%s <span style="opacity:.7">(%s)</span></a>', rel, label, sz)
}

# Zip helper
.zip_files <- function(zip_path, files) {
  files <- unique(files[file.exists(files)])
  if (!length(files)) return(FALSE)

  root <- here::here()
  # relative paths for cleaner ZIP
  rel <- gsub(paste0("^", gsub("\\\\","/", root), "/?"), "", gsub("\\\\","/", files))

  dir.create(dirname(zip_path), recursive = TRUE, showWarnings = FALSE)
  ok <- FALSE
  if (requireNamespace("zip", quietly = TRUE)) {
    zip::zipr(zipfile = zip_path, files = rel, root = root, include_directories = FALSE)
    ok <- file.exists(zip_path)
  } else {
    old <- getwd(); on.exit(setwd(old), add = TRUE)
    if (requireNamespace("withr", quietly = TRUE)) { withr::local_dir(root) } else { old <- getwd(); on.exit(setwd(old), add = TRUE); setwd(root) }
    utils::zip(zipfile = zip_path, files = rel)
    ok <- file.exists(zip_path)
  }
  ok
}

# Gather artifacts
dir.create(here::here("outputs"), showWarnings = FALSE, recursive = TRUE)
fig_glob   <- c("\\.png$","\\.svg$","\\.html?$")
table_glob <- c("\\.csv$","\\.xlsx$")
fig_files   <- unlist(lapply(fig_glob,   function(p) list.files(here::here("figs"),   pattern = p, full.names = TRUE, ignore.case = TRUE)))
table_files <- unlist(lapply(table_glob, function(p) list.files(here::here("tables"), pattern = p, full.names = TRUE, ignore.case = TRUE)))
fig_files   <- unique(fig_files)
table_files <- unique(table_files)

# Create zips
zip_figs <- here::here("outputs","Supplementary_Figures.zip")
zip_tabs <- here::here("outputs","Supplementary_Tables.zip")
zip_all  <- here::here("outputs","Supplementary_Bundle.zip")

ok1 <- .zip_files(zip_figs, fig_files)
ok2 <- .zip_files(zip_tabs, table_files)
ok3 <- .zip_files(zip_all,  unique(c(fig_files, table_files)))

# Styles for buttons
if (knitr::is_html_output()) {
  knitr::asis_output('<style>.dl-btn{display:inline-block;padding:8px 12px;margin:6px;border:1px solid #ccc;border-radius:8px;text-decoration:none;font-weight:600;font-size:.95em;background:#f7f7f7;color:#111}.dl-btn:hover{background:#f5f5f5}</style>')
}

# Render links (single block)
if (knitr::is_html_output()) {
  links <- Filter(Negate(is.null), c(
    if (ok1) .make_link(zip_figs, "Supplementary Figures (ZIP)") else NULL,
    if (ok2) .make_link(zip_tabs, "Supplementary Tables (ZIP)")  else NULL,
    if (ok3) .make_link(zip_all,  "Complete Supplementary Bundle (ZIP)") else NULL
  ))
  if (length(links)) {
    knitr::asis_output(paste("<p>", paste(links, collapse = " &nbsp; "), "</p>"))
  } else {
    knitr::asis_output("<em>No artifacts found to bundle.</em>")
  }
} else {
  cat("Bundles:\n")
  if (ok1) cat("  ", normalizePath(zip_figs, mustWork = FALSE), "\n", sep = "")
  if (ok2) cat("  ", normalizePath(zip_tabs, mustWork = FALSE), "\n", sep = "")
  if (ok3) cat("  ", normalizePath(zip_all,  mustWork = FALSE), "\n", sep = "")
}

```

```{r}
export_lancet_bundles <- function(fig_list_named, out_dir = here::here("figs")) {
  dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)
  for (nm in names(fig_list_named)) {
    save_lancet_all(fig_list_named[[nm]], file_base = file.path(out_dir, nm),
                    layout = "onecol", height_mm = 120, png_dpi = 600)
  }
  invisible(out_dir)
}
```



# Summary

```{r summary, echo=FALSE}
# Initialize (optional but makes logic clearer)
if (!exists("pooled_kappa")) pooled_kappa <- NULL

# Try fast IVW first
if (is.null(pooled_kappa)) {
  if (exists("conc") && is.data.frame(conc) && all(c("Kappa","SE") %in% names(conc))) {
    keep <- with(conc, is.finite(Kappa) & is.finite(SE) & SE > 0)
    if (sum(keep, na.rm = TRUE) >= 2) {
      w   <- 1 / (conc$SE[keep]^2)
      est <- stats::weighted.mean(conc$Kappa[keep], w, na.rm = TRUE)
      se  <- sqrt(1 / sum(w, na.rm = TRUE))
      ci  <- est + c(-1.96, 1.96) * se
      pooled_kappa <- list(
        estimate = est,
        ci_l     = max(-1, ci[1]),
        ci_u     = min( 1, ci[2]),
        k        = sum(keep, na.rm = TRUE),
        method   = "IVW"
      )
    }
  }
}

# Fallback to REML (Knapp–Hartung) if IVW not available
if (is.null(pooled_kappa)) {
  if (exists("conc") && is.data.frame(conc) && all(c("Kappa","SE") %in% names(conc))) {
    keep <- with(conc, is.finite(Kappa) & is.finite(SE) & SE > 0)
    if (sum(keep, na.rm = TRUE) >= 2) {
      pk <- metafor::rma(yi = conc$Kappa[keep], sei = conc$SE[keep],
                         method = "REML", test = "knha")
      pooled_kappa <- list(
        estimate = as.numeric(pk$b),
        ci_l     = as.numeric(pk$ci.lb),
        ci_u     = as.numeric(pk$ci.ub),
        k        = sum(keep, na.rm = TRUE),
        method   = "REML (KnHa)"
      )
    }
  }
}


```

# Session Info

```{r echo=T}
sessionInfo()
```
